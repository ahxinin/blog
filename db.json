{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","path":"img/fluid.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/bg.jpg","path":"img/bg.jpg","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/icon.png","path":"img/icon.png","modified":1,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1706599764674},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"f6de7d0f898b0ea674a35c6eca0f5b2ae710d2c9","modified":1706600552967},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"0e7d455d9e004ff15d8924b7a0c35cea25ee5b1d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"ff9b0e1fb9dba665af2f1e4a577f8cb9e840464b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"26f9356fd6e84b5a88df6d9014378f41b65ba209","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"cb11b39f44ea069652c9647179606b6cecc98d50","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/es.yml","hash":"7112594259c88c04714be152af7fd377687dad40","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"2253e1bc61694b3bdc5e434ea2660d13d941b50e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/ru.yml","hash":"7dc78f22696649a4c68dc65a9b52d9a992fa82a0","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"3dd6d20f8d26585a7c154a8e59fe8d5d902f4c6a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"a556251cc50a5680578c03f1efbf252b1f4ab860","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"80d75936a1e3540d71aab96149bccdc771e175c5","modified":1706608703720},{"_id":"node_modules/hexo-theme-fluid/languages/zh-HK.yml","hash":"80ed400a7adaa92ea54fc7f5d534c9af795bed00","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"596d031dff3826ae8e4ffc8931fff28977b73247","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"33c3317cdcee062789de2336dd8d0cc7f86d3650","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"b84d575c7b7f778b4cb64e89ad3d0aed4a896820","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"163bee643e6a38912d3ae70923c83c48d57222e7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"f099161b738a16a32253f42085b5444f902018ed","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"13859726c27b6c79b5876ec174176d0f9c1ee164","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"7c1f44005849791feae4abaa10fae4cb983d3277","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"7e0023474128fbe4d68c467704c41f1712432415","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"ed5007a3feb8f14d3d2843271bfb298eb0c56219","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"9d686364c4d16a1a9219471623af452035c5b966","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"1cac32ec4579aaf7b9fa39d317497331d4c5e1dd","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"9bf0d357a607a282f3b9cb04525a4df0cc2a8b76","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/archive-list.ejs","hash":"7520fbf91f762207c2ab06b2c293235cd5b23905","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-list.ejs","hash":"f8d2f1907450e61968e6d54443e9be8138196a77","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-chains.ejs","hash":"18309584aab83bc4deb20723ebad832149dd2e24","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments.ejs","hash":"d707c47b2638c94e489bc43d4cfd098b7c58447f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/css.ejs","hash":"85f6e051550907681ab4ed2e268ac8f6e9ebf931","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/head.ejs","hash":"7b7b1d098726e86687a15fe3d520d178577ffcae","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"79de5a379b28cad759a49048351c7f6b8915bd7d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/markdown-plugins.ejs","hash":"fc4bdf7de0cf1a66d0e5e4fba1b31d6f7ed49468","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/index-generator.js","hash":"9159fc22fa84a7b605dd15fe4104f01fe9c71147","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header.ejs","hash":"0d5e397d30051e5fbabe7b47cfd1f1e6a5820af1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/default-injects.js","hash":"b2013ae8e189cd07ebc8a2ff48a78e153345210f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer.ejs","hash":"10ccfb8eef4e16182183c9a3e175c90d5b6397d3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"d3e75f53c59674d171309e50702954671f31f1a4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"82bb06686158ebe160a631c79f156cd4fde35656","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"9ac5ddad06e9b0e6015ce531430018182a4bc0fa","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/engine.js","hash":"d3a231d106795ce99cb0bc77eb65f9ae44515933","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/date.js","hash":"9bda6382f61b40a20c24af466fe10c8366ebb74c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"8e67b522c47aa250860e3fe2c733f1f958a506c0","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/import.js","hash":"ca53e8dbf7d44cfd372cfa79ac60f35a7d5b0076","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/injects.js","hash":"1ad2ae6b11bd8806ee7dd6eb7140d8b54a95d613","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/scope.js","hash":"d41d9d658fcb54964b388598e996747aadb85b0f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"966689d7c5e4320008285395fbaa2751f6209be5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"4d48c424e47ff9a17a563167ea5f480890267adf","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"0857aa86db2a711ae5c77218a9e3fa686d0e87b1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/fold.js","hash":"73e4fd12ce3e47981479391ed354b7d9d3279f70","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"e3b456a079e5dc0032473b516c865b20f83d2c26","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/crypto.js","hash":"ae4ad8a188ef5b3fa6818b01629fc962b3de8551","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"33b57e4decdc5e75c518859f168c8ba80b2c665b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/resolve.js","hash":"8c4a8b62aa8608f12f1e9046231dff04859dc3e9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/scripts.ejs","hash":"da5810785105e5075861593c7ac22c7aa9665a72","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/search.ejs","hash":"70e1c929e084ca8a2648cedabf29b372511ea2b8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","hash":"a9efc52a646a9e585439c768557e3e3c9e3326dc","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"c5939d14065d38c86e16d1642e154dde5a23e830","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","hash":"45695ef75c31a4aa57324dd408b7e2327a337018","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"855ae5fe229c51afa57f7645f6997a27a705d7e4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"5891534506b959a2f559f29e122baa3eb9159d93","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/giscus.ejs","hash":"95f8b866b158eff9352c381c243b332a155a5110","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/discuss.ejs","hash":"98d065b58ce06b7d18bff3c974e96fa0f34ae03a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/twikoo.ejs","hash":"d84bcb5ccd78470a60c067fc914ac0ac67ac8777","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/utterances.ejs","hash":"c7ccf7f28308334a6da6f5425b141a24b5eca0e2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/waline.ejs","hash":"12727da7cf3ac83443270f550be4d1c06135b52b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/valine.ejs","hash":"19ba937553dddd317f827d682661a1066a7b1f30","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/beian.ejs","hash":"4fb9b5dd3f3e41a586d6af44e5069afe7c81fff2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/statistics.ejs","hash":"454d8dd4c39f9494ebeb03ca0746f5bc122af76a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/navigation.ejs","hash":"37d750428772d7c71ba36ce0c2540780d90fadea","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/anchorjs.ejs","hash":"40181442d3a2b8734783a0ad7caf2d2522e3f2ab","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/analytics.ejs","hash":"4f68c80bd1395e2f6d11e373116e54de11cb62e8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/code-widget.ejs","hash":"3a505cba37942badf62a56bbb8b605b72af330aa","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/fancybox.ejs","hash":"9d1ea2a46b8c8ad8c168594d578f40764818ef13","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/banner.ejs","hash":"e07757b59e7b89eea213d0e595cb5932f812fd32","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/encrypt.ejs","hash":"0fff24cf5bf99fbe5c56c292e2eac4a89bf29db4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/mermaid.ejs","hash":"03ac02762f801970d1c4e73d6ec8d4c503780e50","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/math.ejs","hash":"dcbf9a381ee76f2f1f75fcbc22c50a502ec85023","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/highlight.ejs","hash":"7529dd215b09d3557804333942377b9e20fa554e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/moment.ejs","hash":"4ff3fb1b60ccc95a0af3bbdbd0757fedefc088b5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/typed.ejs","hash":"f345374885cd6a334f09a11f59c443b5d577c06c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/copyright.ejs","hash":"529f3069742b3d338c769ba2d836e7f3c342a09d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/category-bar.ejs","hash":"8772bce97ed297e7a88523f4e939ed6436c22f87","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-bottom.ejs","hash":"375974ec017696e294dc12469fb0ae257800dc2d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"c19ac8050b82c3676b0332a56099ccfcc36d9d52","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"ef474d1fa5bbafc52619ced0f9dc7eaf2affb363","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-left.ejs","hash":"9992c99b3eb728ad195970e1b84d665f2c8691c4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-top.ejs","hash":"ce6e9f578f4faa45840abddf8f46af3f4b69c177","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/toc.ejs","hash":"635a89060fbf72eeda066fc4bd0a97462f069417","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"bd8376e1cf7892dc2daa58f2f443574be559fdbf","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"a5fe1deccb73b5f578797dbb11038efc15f63ce8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"7c944c43b2ece5dd84859bd9d1fe955d13427387","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-right.ejs","hash":"d5fcc9b60e02f869a29a8c17a16a6028ecc1e6d8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/injects.js","hash":"5ae4b07204683e54b5a1b74e931702bbce2ac23e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"4ed5f0ae105ef4c7dd92eaf652ceda176c38e502","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"643284c567665f96915f0b64e59934dda315f74d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"c475e6681546d30350eaed11f23081ecae80c375","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-bar.styl","hash":"cc6df43fef6bb3efecbfdd8b9e467424a1dea581","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"85492ef64d7e5f70f0f7e46d570bbc911e686d7e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"411a3fa3f924a87e00ff04d18b5c83283b049a4d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-chain.styl","hash":"0cdf7ef50dfd0669d3b257821384ff31cd81b7c9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-list.styl","hash":"7edfe1b571ecca7d08f5f4dbcf76f4ffdcfbf0b5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/print.styl","hash":"166afbc596ea4b552bad7290ec372d25ec34db7b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/highlight.styl","hash":"4df764d298fe556e501db4afc2b05686fe6ebcfb","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"5c7f2044e3f1da05a3229537c06bd879836f8d6e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"25fb6fa4c783b847c632584c49a7e1593cdb2f5d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-page.styl","hash":"cd432a6411ccac7df47e6a300fb1a872cfc763e7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/comment.styl","hash":"780f3788e7357bcd3f3262d781cb91bb53976a93","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/markdown.styl","hash":"1e3d3a82721e7c10bcfcecec6d81cf2979039452","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"e0cebda4a6f499aff75e71417d88caa7ceb13b94","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"7a0bd629bc234fc75e3cc8e3715ffada92f09e73","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-tag.styl","hash":"c96d36aa8fe20f0c3c1a29ee2473cd8064b10f73","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"4397037fc3f0033dbe546c33cd9dbdabd8cb1632","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"26f71a9cd60d96bb0cb5bbdf58150b8e524d9707","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"b66ab013f0f37d724a149b85b3c7432afcf460ad","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"c4459248c66ea1326feed021179b847ae91d465f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"2caaca71dd1ff63d583099ed817677dd267b457e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"5d225357b4a58d46118e6616377168336ed44cb2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/modal.styl","hash":"adf6c1e5c8e1fb41c77ce6e2258001df61245aa2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"f0e429a27fa8a7658fcbddbb4d4dbe4afa12499a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"8bb1b68e5f3552cb48c2ffa31edbc53646a8fb4c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"0cf2f2bb44f456150d428016675d5876a9d2e2aa","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/toc.styl","hash":"9e7452aa2372153f25d7a4675c9d36d281a65d24","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":499162500000},{"_id":"source/.DS_Store","hash":"804c8af483e5d29e60025fa284abdf9a51d611d5","modified":1706608495456},{"_id":"public/local-search.xml","hash":"d41d8ef9e5a8100d702224a565aa1891e556d432","modified":1706603496821},{"_id":"public/archives/index.html","hash":"549e8423991bc9ef89dc485eb6c2c4ed25f6c1e3","modified":1706665658208},{"_id":"public/archives/2024/index.html","hash":"98fd7717a7e5ee323627cb4944016048a850a00f","modified":1706665658208},{"_id":"public/archives/2024/01/index.html","hash":"64d1890742e30b83bf5f19e5942ad8f1089c574c","modified":1706665658208},{"_id":"public/404.html","hash":"fd087c8590549ac171f98645eea59db79e1f4bd6","modified":1706665658208},{"_id":"public/tags/index.html","hash":"c19680554e24c634e507a270778962e59c82eea6","modified":1706665658208},{"_id":"public/index.html","hash":"ff7a2958bca6f02d2fdc8dfbfffe95a8b1571fb4","modified":1706665658208},{"_id":"public/links/index.html","hash":"26d6714ac3ff64f63a5e8e768e46f3ebf56b40d2","modified":1706665658208},{"_id":"public/2024/01/30/hello-world/index.html","hash":"13e2ce71bae69c184d02ae3f390829675625c0ef","modified":1706601000145},{"_id":"public/categories/index.html","hash":"a783d3a764e40f46d4a27903a749cdd4613288af","modified":1706665658208},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1706601000145},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1706601000145},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1706601000145},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1706601000145},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1706601000145},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1706601000145},{"_id":"public/css/highlight-dark.css","hash":"902294bada4323c0f51502d67cba8c3a0298952f","modified":1706601000145},{"_id":"public/css/highlight.css","hash":"04d4ddbb5e1d1007447c2fe293ee05aae9b9563e","modified":1706601000145},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1706601000145},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1706601000145},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1706601000145},{"_id":"public/js/color-schema.js","hash":"c5939d14065d38c86e16d1642e154dde5a23e830","modified":1706601000145},{"_id":"public/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":1706601000145},{"_id":"public/js/events.js","hash":"5891534506b959a2f559f29e122baa3eb9159d93","modified":1706601000145},{"_id":"public/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":1706601000145},{"_id":"public/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":1706601000145},{"_id":"public/css/main.css","hash":"7d7590cfe0261084ad357d5f51cb14d13db826d8","modified":1706601000145},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1706601000145},{"_id":"public/hello-world.html","hash":"d4b0387e31c3d302f6e14fa90ef06753f7ae988c","modified":1706608511657},{"_id":"source/_posts/Elasticsearch Client 进阶使用.md","hash":"8fe8d4a2e735ec6f0d396d80985aae41fb194af8","modified":1706608936474},{"_id":"source/_posts/Elasticsearch Java API Client 8.x使用方式.md","hash":"cef518cebad731eda3d5d9677bd6c03bd23667f3","modified":1706608930183},{"_id":"source/_posts/Elasticsearch写入速度优化[翻译版].md","hash":"e5569833dbf94be2eb719decea4fd7d976c5f315","modified":1706608916153},{"_id":"source/_posts/Elasticsearch搜索优化[翻译版].md","hash":"93dc7aa9aff155fefabe3c45911c859f694dfb87","modified":1706608923353},{"_id":"source/_posts/Redis实战之搞懂Redisson分布式锁机制.md","hash":"2d97d15cb7ccf9a09f8ea900bd88b179017482ac","modified":1706608903309},{"_id":"source/_posts/高性能MySQL的实现策略.md","hash":"5291c5133e31cd612a9f31183e71865c55c9236d","modified":1706608942414},{"_id":"node_modules/hexo-theme-fluid/source/.DS_Store","hash":"60b465f6d8e91ee52a5d95e130f180a00b8bb0e3","modified":1706608683147},{"_id":"node_modules/hexo-theme-fluid/.DS_Store","hash":"f7cb20a45cbf18194ea4f32577ff83e53049f325","modified":1706608683146},{"_id":"node_modules/hexo-theme-fluid/source/img/bg.jpeg","hash":"f43d4c3f7807d5483d791dd95da6615f72a2ebd8","modified":1706604117480},{"_id":"public/archives/2023/index.html","hash":"f0339f5de9b97d8844dfeeb4f2974691ec8eb351","modified":1706665658208},{"_id":"public/archives/2023/03/index.html","hash":"4a15d46968d4111ba59c0b850fc812eb2174821c","modified":1706665658208},{"_id":"public/archives/2023/04/index.html","hash":"f795bbe46761cb194e2a9d966c8869d3515cbd6d","modified":1706665658208},{"_id":"public/archives/2023/05/index.html","hash":"0dfe628c6b8ab82432913fa05c450da8faeebf16","modified":1706665658208},{"_id":"public/categories/随笔/index.html","hash":"7c46d0d29b368277bccd5b3fdf758d570de3d80d","modified":1706608511657},{"_id":"public/pages/3fe7f9/index.html","hash":"74d895d814e0ece2cbbbddbe962dea2d8c445e7d","modified":1706608511657},{"_id":"public/pages/3fe7f10k/index.html","hash":"c55ef115b592782a938b391fdfc5de2873c53f7a","modified":1706608511657},{"_id":"public/pages/3fe7f8/index.html","hash":"22cd15024c80cff8879f92af06a483acee63ac1b","modified":1706608511657},{"_id":"public/pages/3fe7f7/index.html","hash":"810ae37a39d1a30740836c57336d94fd5ccb3580","modified":1706608511657},{"_id":"public/pages/3fe7f11/index.html","hash":"ad48729ffde519f0061a1b4b08629314641df995","modified":1706608511657},{"_id":"public/pages/3fe7f10/index.html","hash":"377198ab8269f00e1efab2765e66df8a1e2e1d9b","modified":1706608511657},{"_id":"public/img/bg.jpeg","hash":"f43d4c3f7807d5483d791dd95da6615f72a2ebd8","modified":1706608511657},{"_id":"node_modules/hexo-theme-fluid/source/img/bg.jpg","hash":"66ed9057bfc35bcf3cbc98a791de9ada175b1ef8","modified":1705277111000},{"_id":"node_modules/hexo-theme-fluid/source/img/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1706608805654},{"_id":"public/Redis实战之搞懂Redisson分布式锁机制.html","hash":"ab0ae058e6cb1d31ae1a9a184005abcbdeaa616a","modified":1706665658208},{"_id":"public/Elasticsearch搜索优化[翻译版].html","hash":"dfe069b5ea3fd7ca78b0a4bb6b7db7d54bcd3bd4","modified":1706665658208},{"_id":"public/Elasticsearch写入速度优化[翻译版].html","hash":"fb6c92402c5b8ae7b98a2026674d709e52256163","modified":1706665658208},{"_id":"public/Elasticsearch Client 进阶使用.html","hash":"11fc90dd0e65affaaa9dd9a34a89d921f61c20b0","modified":1706665658208},{"_id":"public/Elasticsearch Java API Client 8.x使用方式.html","hash":"72990ab600c744d7da10f321bcfabef9cb93d0e0","modified":1706665658208},{"_id":"public/高性能MySQL的实现策略.html","hash":"18baafebe1926241ce8484b405f76aa6449f79b5","modified":1706665658208},{"_id":"public/img/bg.jpg","hash":"66ed9057bfc35bcf3cbc98a791de9ada175b1ef8","modified":1706608964923},{"_id":"node_modules/hexo-theme-fluid/source/img/icon.png","hash":"f1bb70612a13eed0e24112dea782af2910b46212","modified":1706665552080},{"_id":"public/img/icon.png","hash":"f1bb70612a13eed0e24112dea782af2910b46212","modified":1706665658208}],"Category":[{"name":"随笔","_id":"cls06n7q30002iocq7t7u1prt"}],"Data":[],"Page":[],"Post":[{"title":"Elasticsearch Client 进阶使用","date":"2023-04-13T16:00:00.000Z","_content":"\n在上一篇文章中，我们介绍了Elasticsearch java  client的一些基本用法，为了达到生产级别的使用标准，下面介绍一些进阶的用法。\n\n## 1.客户端tcp连接超时\n\n在我们创建客户端时，实际上创建的是`RestClient`，而底层使用的是`apache`的`HttpClient`，在创建后长时间无操作时这个连接可能会被关闭，此时客户端并不知晓，直接使用就会提示下文中的错误。再次请求又是正常的，因为客户端会重新创建连接。\n\n```Java\njava.net.SocketTimeoutException: 30,000 milliseconds timeout on connection http-outgoing-6 [ACTIVE]\n  at org.elasticsearch.client.RestClient.extractAndWrapCause(RestClient.java:915)\n  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:300)\n  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:288)\n  at co.elastic.clients.transport.rest_client.RestClientTransport.performRequest(RestClientTransport.java:147)\n  at co.elastic.clients.elasticsearch.ElasticsearchClient.search(ElasticsearchClient.java:1833)\nCaused by: java.net.SocketTimeoutException: 30,000 milliseconds timeout on connection http-outgoing-6 [ACTIVE]\n  at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.timeout(HttpAsyncRequestExecutor.java:381)\n  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:92)\n  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:39)\n  at org.apache.http.impl.nio.reactor.AbstractIODispatch.timeout(AbstractIODispatch.java:175)\n  at org.apache.http.impl.nio.reactor.BaseIOReactor.sessionTimedOut(BaseIOReactor.java:263)\n  at org.apache.http.impl.nio.reactor.AbstractIOReactor.timeoutCheck(AbstractIOReactor.java:492)\n  at org.apache.http.impl.nio.reactor.BaseIOReactor.validate(BaseIOReactor.java:213)\n  at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:280)\n  at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)\n  at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588)\n  at java.lang.Thread.run(Thread.java:748)\n```\n\n这个问题在Github的官方Issues上面也有相关的讨论：[https://github.com/elastic/elasticsearch/issues/65213](https://github.com/elastic/elasticsearch/issues/65213)\n\n解决问题的关键在于让连接能够保持`tcp keepalive`，有两种方案：\n\n方案一：在客户端中显式的开启`keepalive`选项\n\n```Java\nRestClient httpClient = RestClient.builder(new HttpHost(hostName, port))\n    .setHttpClientConfigCallback(hc -> hc\n        .setDefaultIOReactorConfig(IOReactorConfig.custom().setSoKeepAlive(true).build())\n     ).build();\n```\n\n另外，还需要设置系统层面的`tcp keepalive`探测时间，默认值7200s太长可能会被主动关闭，建议修改为300s，默认配置如下：\n\n```Bash\nnet.ipv4.tcp_keepalive_time = 7200\nnet.ipv4.tcp_keepalive_intvl = 75\nnet.ipv4.tcp_keepalive_probes = 9\n```\n\n方案二：在客户端设置`keepalive`策略，在超过指定时间后由客户端自行关闭，使用时再重新创建\n\n```Java\nRestClient httpClient = RestClient.builder(new HttpHost(hostName, port))\n    .setHttpClientConfigCallback(hc -> hc\n            .setKeepAliveStrategy((response, context) -> Duration.ofMinutes(5).toMillis()))\n    .build();\n```\n\n## 2.聚合统计\n\n在Elasticsearch中Aggregation 分为3种类型：\n\n- Metric: 计算类型，对字段进行计算平均值、求和等；\n- Bucket: 分组统计，根据字段或者范围将文档分组到桶中进行统计；\n- Pipeline：对聚合结果再次进行聚合统计；\n\n在分组统计中有2个参数需要特别关注：Size、Shard size。官方文档：[https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html)\n\nSize：在使用`terms`对字段进行分桶时，默认值返回top 10文档，即只有10个统计结果，通过设置size的大小可以返回所需大小，最大值不超过` search.max_buckets `。\n```Java\nMultiTermsAggregation aggregation = MultiTermsAggregation.of(s -> s.terms(\n    MultiTermLookup.of(t->t.field(\"product\")),\n    MultiTermLookup.of(t->t.field(\"user\"))\n).size(100));\n\n```\nShard size：在上一篇文章中，我们介绍过Elasticsearch的查询过程，需要从每个分片获取结果后，再由协调节点进行合并排序。由于数据分布不均匀的缘故，如果每个分片只获取`size`大小的文档，可能会出现统计偏差。\n\nElasticsearch的解决方案是获取比所需更多的文档，在一定程度上避免这个问题，也就是`Shard size`参数的用途。默认值：`Shard size = size * 1.5 + 10`，在数据偏斜严重的情况下，可以适当调大这个参数，当然也意味着更多的性能损耗。\n\n## 3.数据快照\n\n之前我们介绍过`search_after` 能够实现深度分页功能，而在一些大批量数据导出的场景下，通常需要保持数据游标不变来导出完整的数据，类似于快照的功能。而这就需要用到 `point in time (PIT) `。\n\n```Java\n//获取pit id\nOpenPointInTimeRequest openRequest = OpenPointInTimeRequest.of(o -> o\n    .index(getIndex())\n    .keepAlive(Time.of(t->t.time(\"10m\"))));\nOpenPointInTimeResponse openResponse = elasticsearchClient.openPointInTime(openRequest);\n\n//查询数据\nSearchRequest searchRequest = new SearchRequest.Builder()\n    .size(pageSize)\n    .sort(sortOptions)\n    .pit(p -> p.id(params.getPit()));\n    .build();\nelasticsearchClient.search(searchRequest);    \n    \n//关闭pit\nClosePointInTimeRequest closeRequest = ClosePointInTimeRequest.of(c -> c.id(pit));\nelasticsearchClient.closePointInTime(closeRequest);\n\n```\n\n## 4.获取搜索结果数量\n\n在默认情况下`search`接口返回的`hits size`最大值是10000，如果需要获取实际的结果总数，需要开启`TrackHits`\n\n```Java\nSearchRequest searchRequest = new SearchRequest.Builder()\n    .trackTotalHits(TrackHits.of(t->t.enabled(true)));\n    .build();\nelasticsearchClient.search(searchRequest);    \n```\n\n## 5.并发写入\n\n一般情况下，Elasticsearch数据的写入会通过mq来进行触发，理论上可以通过mq的有序性来控制并发写入导致的数据覆盖问题，现实情况中考虑到性能、可靠性，较少采用这种方式。\n\n方案一：增加version数据版本字段，通过CAS操作来实现乐观锁；\n\n方案二：使用分布式锁，确保同一时间单个文档只有一个线程在执行更新操作，重试操作可以由mq来实现；\n\n## 6.数据库事务\n\n假设你正在使用Elasticsearch存储订单数据，在业务代码中的执行步骤如下：\n\n- 更新MySQL中订单表数据；\n- 发送订单变更的mq通知；\n- 消费mq消息，从MySQL读取最新的数据写入Elasticsearch；\n\n在运行一段时间后，你可能会发现Elasticsearch的数据与MySQL不一致，不是最新的版本；仔细分析上述过程会发现一个问题，在执行第2步操作时第1步的数据事务还没提交完成，将导致第3读取的不是最新数据。提供一种解决问题的思路，在事务提交完成后再发送mq消息。\n\n```Java\nTransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){\n    @Override\n    public void afterCommit() {\n        //发送mq\n    }\n});\n```\n今天就先写到这里，你学\"废\"了吗。","source":"_posts/Elasticsearch Client 进阶使用.md","raw":"---\ntitle: Elasticsearch Client 进阶使用\ndate: 2023-04-14\n---\n\n在上一篇文章中，我们介绍了Elasticsearch java  client的一些基本用法，为了达到生产级别的使用标准，下面介绍一些进阶的用法。\n\n## 1.客户端tcp连接超时\n\n在我们创建客户端时，实际上创建的是`RestClient`，而底层使用的是`apache`的`HttpClient`，在创建后长时间无操作时这个连接可能会被关闭，此时客户端并不知晓，直接使用就会提示下文中的错误。再次请求又是正常的，因为客户端会重新创建连接。\n\n```Java\njava.net.SocketTimeoutException: 30,000 milliseconds timeout on connection http-outgoing-6 [ACTIVE]\n  at org.elasticsearch.client.RestClient.extractAndWrapCause(RestClient.java:915)\n  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:300)\n  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:288)\n  at co.elastic.clients.transport.rest_client.RestClientTransport.performRequest(RestClientTransport.java:147)\n  at co.elastic.clients.elasticsearch.ElasticsearchClient.search(ElasticsearchClient.java:1833)\nCaused by: java.net.SocketTimeoutException: 30,000 milliseconds timeout on connection http-outgoing-6 [ACTIVE]\n  at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.timeout(HttpAsyncRequestExecutor.java:381)\n  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:92)\n  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:39)\n  at org.apache.http.impl.nio.reactor.AbstractIODispatch.timeout(AbstractIODispatch.java:175)\n  at org.apache.http.impl.nio.reactor.BaseIOReactor.sessionTimedOut(BaseIOReactor.java:263)\n  at org.apache.http.impl.nio.reactor.AbstractIOReactor.timeoutCheck(AbstractIOReactor.java:492)\n  at org.apache.http.impl.nio.reactor.BaseIOReactor.validate(BaseIOReactor.java:213)\n  at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:280)\n  at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)\n  at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588)\n  at java.lang.Thread.run(Thread.java:748)\n```\n\n这个问题在Github的官方Issues上面也有相关的讨论：[https://github.com/elastic/elasticsearch/issues/65213](https://github.com/elastic/elasticsearch/issues/65213)\n\n解决问题的关键在于让连接能够保持`tcp keepalive`，有两种方案：\n\n方案一：在客户端中显式的开启`keepalive`选项\n\n```Java\nRestClient httpClient = RestClient.builder(new HttpHost(hostName, port))\n    .setHttpClientConfigCallback(hc -> hc\n        .setDefaultIOReactorConfig(IOReactorConfig.custom().setSoKeepAlive(true).build())\n     ).build();\n```\n\n另外，还需要设置系统层面的`tcp keepalive`探测时间，默认值7200s太长可能会被主动关闭，建议修改为300s，默认配置如下：\n\n```Bash\nnet.ipv4.tcp_keepalive_time = 7200\nnet.ipv4.tcp_keepalive_intvl = 75\nnet.ipv4.tcp_keepalive_probes = 9\n```\n\n方案二：在客户端设置`keepalive`策略，在超过指定时间后由客户端自行关闭，使用时再重新创建\n\n```Java\nRestClient httpClient = RestClient.builder(new HttpHost(hostName, port))\n    .setHttpClientConfigCallback(hc -> hc\n            .setKeepAliveStrategy((response, context) -> Duration.ofMinutes(5).toMillis()))\n    .build();\n```\n\n## 2.聚合统计\n\n在Elasticsearch中Aggregation 分为3种类型：\n\n- Metric: 计算类型，对字段进行计算平均值、求和等；\n- Bucket: 分组统计，根据字段或者范围将文档分组到桶中进行统计；\n- Pipeline：对聚合结果再次进行聚合统计；\n\n在分组统计中有2个参数需要特别关注：Size、Shard size。官方文档：[https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html)\n\nSize：在使用`terms`对字段进行分桶时，默认值返回top 10文档，即只有10个统计结果，通过设置size的大小可以返回所需大小，最大值不超过` search.max_buckets `。\n```Java\nMultiTermsAggregation aggregation = MultiTermsAggregation.of(s -> s.terms(\n    MultiTermLookup.of(t->t.field(\"product\")),\n    MultiTermLookup.of(t->t.field(\"user\"))\n).size(100));\n\n```\nShard size：在上一篇文章中，我们介绍过Elasticsearch的查询过程，需要从每个分片获取结果后，再由协调节点进行合并排序。由于数据分布不均匀的缘故，如果每个分片只获取`size`大小的文档，可能会出现统计偏差。\n\nElasticsearch的解决方案是获取比所需更多的文档，在一定程度上避免这个问题，也就是`Shard size`参数的用途。默认值：`Shard size = size * 1.5 + 10`，在数据偏斜严重的情况下，可以适当调大这个参数，当然也意味着更多的性能损耗。\n\n## 3.数据快照\n\n之前我们介绍过`search_after` 能够实现深度分页功能，而在一些大批量数据导出的场景下，通常需要保持数据游标不变来导出完整的数据，类似于快照的功能。而这就需要用到 `point in time (PIT) `。\n\n```Java\n//获取pit id\nOpenPointInTimeRequest openRequest = OpenPointInTimeRequest.of(o -> o\n    .index(getIndex())\n    .keepAlive(Time.of(t->t.time(\"10m\"))));\nOpenPointInTimeResponse openResponse = elasticsearchClient.openPointInTime(openRequest);\n\n//查询数据\nSearchRequest searchRequest = new SearchRequest.Builder()\n    .size(pageSize)\n    .sort(sortOptions)\n    .pit(p -> p.id(params.getPit()));\n    .build();\nelasticsearchClient.search(searchRequest);    \n    \n//关闭pit\nClosePointInTimeRequest closeRequest = ClosePointInTimeRequest.of(c -> c.id(pit));\nelasticsearchClient.closePointInTime(closeRequest);\n\n```\n\n## 4.获取搜索结果数量\n\n在默认情况下`search`接口返回的`hits size`最大值是10000，如果需要获取实际的结果总数，需要开启`TrackHits`\n\n```Java\nSearchRequest searchRequest = new SearchRequest.Builder()\n    .trackTotalHits(TrackHits.of(t->t.enabled(true)));\n    .build();\nelasticsearchClient.search(searchRequest);    \n```\n\n## 5.并发写入\n\n一般情况下，Elasticsearch数据的写入会通过mq来进行触发，理论上可以通过mq的有序性来控制并发写入导致的数据覆盖问题，现实情况中考虑到性能、可靠性，较少采用这种方式。\n\n方案一：增加version数据版本字段，通过CAS操作来实现乐观锁；\n\n方案二：使用分布式锁，确保同一时间单个文档只有一个线程在执行更新操作，重试操作可以由mq来实现；\n\n## 6.数据库事务\n\n假设你正在使用Elasticsearch存储订单数据，在业务代码中的执行步骤如下：\n\n- 更新MySQL中订单表数据；\n- 发送订单变更的mq通知；\n- 消费mq消息，从MySQL读取最新的数据写入Elasticsearch；\n\n在运行一段时间后，你可能会发现Elasticsearch的数据与MySQL不一致，不是最新的版本；仔细分析上述过程会发现一个问题，在执行第2步操作时第1步的数据事务还没提交完成，将导致第3读取的不是最新数据。提供一种解决问题的思路，在事务提交完成后再发送mq消息。\n\n```Java\nTransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){\n    @Override\n    public void afterCommit() {\n        //发送mq\n    }\n});\n```\n今天就先写到这里，你学\"废\"了吗。","slug":"Elasticsearch Client 进阶使用","published":1,"updated":"2024-01-30T10:02:16.474Z","_id":"cls06n7py0000iocqb3be3o2t","comments":1,"layout":"post","photos":[],"content":"<p>在上一篇文章中，我们介绍了Elasticsearch java  client的一些基本用法，为了达到生产级别的使用标准，下面介绍一些进阶的用法。</p>\n<h2 id=\"1-客户端tcp连接超时\"><a href=\"#1-客户端tcp连接超时\" class=\"headerlink\" title=\"1.客户端tcp连接超时\"></a>1.客户端tcp连接超时</h2><p>在我们创建客户端时，实际上创建的是<code>RestClient</code>，而底层使用的是<code>apache</code>的<code>HttpClient</code>，在创建后长时间无操作时这个连接可能会被关闭，此时客户端并不知晓，直接使用就会提示下文中的错误。再次请求又是正常的，因为客户端会重新创建连接。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\">java.net.SocketTimeoutException: <span class=\"hljs-number\">30</span>,<span class=\"hljs-number\">000</span> milliseconds timeout on connection http-outgoing-<span class=\"hljs-number\">6</span> [ACTIVE]<br>  at org.elasticsearch.client.RestClient.extractAndWrapCause(RestClient.java:<span class=\"hljs-number\">915</span>)<br>  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:<span class=\"hljs-number\">300</span>)<br>  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:<span class=\"hljs-number\">288</span>)<br>  at co.elastic.clients.transport.rest_client.RestClientTransport.performRequest(RestClientTransport.java:<span class=\"hljs-number\">147</span>)<br>  at co.elastic.clients.elasticsearch.ElasticsearchClient.search(ElasticsearchClient.java:<span class=\"hljs-number\">1833</span>)<br>Caused by: java.net.SocketTimeoutException: <span class=\"hljs-number\">30</span>,<span class=\"hljs-number\">000</span> milliseconds timeout on connection http-outgoing-<span class=\"hljs-number\">6</span> [ACTIVE]<br>  at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.timeout(HttpAsyncRequestExecutor.java:<span class=\"hljs-number\">381</span>)<br>  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:<span class=\"hljs-number\">92</span>)<br>  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:<span class=\"hljs-number\">39</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractIODispatch.timeout(AbstractIODispatch.java:<span class=\"hljs-number\">175</span>)<br>  at org.apache.http.impl.nio.reactor.BaseIOReactor.sessionTimedOut(BaseIOReactor.java:<span class=\"hljs-number\">263</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractIOReactor.timeoutCheck(AbstractIOReactor.java:<span class=\"hljs-number\">492</span>)<br>  at org.apache.http.impl.nio.reactor.BaseIOReactor.validate(BaseIOReactor.java:<span class=\"hljs-number\">213</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:<span class=\"hljs-number\">280</span>)<br>  at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:<span class=\"hljs-number\">104</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:<span class=\"hljs-number\">588</span>)<br>  at java.lang.Thread.run(Thread.java:<span class=\"hljs-number\">748</span>)<br></code></pre></td></tr></table></figure>\n\n<p>这个问题在Github的官方Issues上面也有相关的讨论：<a href=\"https://github.com/elastic/elasticsearch/issues/65213\">https://github.com/elastic/elasticsearch/issues/65213</a></p>\n<p>解决问题的关键在于让连接能够保持<code>tcp keepalive</code>，有两种方案：</p>\n<p>方案一：在客户端中显式的开启<code>keepalive</code>选项</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">RestClient</span> <span class=\"hljs-variable\">httpClient</span> <span class=\"hljs-operator\">=</span> RestClient.builder(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">HttpHost</span>(hostName, port))<br>    .setHttpClientConfigCallback(hc -&gt; hc<br>        .setDefaultIOReactorConfig(IOReactorConfig.custom().setSoKeepAlive(<span class=\"hljs-literal\">true</span>).build())<br>     ).build();<br></code></pre></td></tr></table></figure>\n\n<p>另外，还需要设置系统层面的<code>tcp keepalive</code>探测时间，默认值7200s太长可能会被主动关闭，建议修改为300s，默认配置如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Bash\">net.ipv4.tcp_keepalive_time = 7200<br>net.ipv4.tcp_keepalive_intvl = 75<br>net.ipv4.tcp_keepalive_probes = 9<br></code></pre></td></tr></table></figure>\n\n<p>方案二：在客户端设置<code>keepalive</code>策略，在超过指定时间后由客户端自行关闭，使用时再重新创建</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">RestClient</span> <span class=\"hljs-variable\">httpClient</span> <span class=\"hljs-operator\">=</span> RestClient.builder(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">HttpHost</span>(hostName, port))<br>    .setHttpClientConfigCallback(hc -&gt; hc<br>            .setKeepAliveStrategy((response, context) -&gt; Duration.ofMinutes(<span class=\"hljs-number\">5</span>).toMillis()))<br>    .build();<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-聚合统计\"><a href=\"#2-聚合统计\" class=\"headerlink\" title=\"2.聚合统计\"></a>2.聚合统计</h2><p>在Elasticsearch中Aggregation 分为3种类型：</p>\n<ul>\n<li>Metric: 计算类型，对字段进行计算平均值、求和等；</li>\n<li>Bucket: 分组统计，根据字段或者范围将文档分组到桶中进行统计；</li>\n<li>Pipeline：对聚合结果再次进行聚合统计；</li>\n</ul>\n<p>在分组统计中有2个参数需要特别关注：Size、Shard size。官方文档：<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html\">https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html</a></p>\n<p>Size：在使用<code>terms</code>对字段进行分桶时，默认值返回top 10文档，即只有10个统计结果，通过设置size的大小可以返回所需大小，最大值不超过<code>search.max_buckets</code>。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">MultiTermsAggregation</span> <span class=\"hljs-variable\">aggregation</span> <span class=\"hljs-operator\">=</span> MultiTermsAggregation.of(s -&gt; s.terms(<br>    MultiTermLookup.of(t-&gt;t.field(<span class=\"hljs-string\">&quot;product&quot;</span>)),<br>    MultiTermLookup.of(t-&gt;t.field(<span class=\"hljs-string\">&quot;user&quot;</span>))<br>).size(<span class=\"hljs-number\">100</span>));<br><br></code></pre></td></tr></table></figure>\n<p>Shard size：在上一篇文章中，我们介绍过Elasticsearch的查询过程，需要从每个分片获取结果后，再由协调节点进行合并排序。由于数据分布不均匀的缘故，如果每个分片只获取<code>size</code>大小的文档，可能会出现统计偏差。</p>\n<p>Elasticsearch的解决方案是获取比所需更多的文档，在一定程度上避免这个问题，也就是<code>Shard size</code>参数的用途。默认值：<code>Shard size = size * 1.5 + 10</code>，在数据偏斜严重的情况下，可以适当调大这个参数，当然也意味着更多的性能损耗。</p>\n<h2 id=\"3-数据快照\"><a href=\"#3-数据快照\" class=\"headerlink\" title=\"3.数据快照\"></a>3.数据快照</h2><p>之前我们介绍过<code>search_after</code> 能够实现深度分页功能，而在一些大批量数据导出的场景下，通常需要保持数据游标不变来导出完整的数据，类似于快照的功能。而这就需要用到 <code>point in time (PIT) </code>。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-comment\">//获取pit id</span><br><span class=\"hljs-type\">OpenPointInTimeRequest</span> <span class=\"hljs-variable\">openRequest</span> <span class=\"hljs-operator\">=</span> OpenPointInTimeRequest.of(o -&gt; o<br>    .index(getIndex())<br>    .keepAlive(Time.of(t-&gt;t.time(<span class=\"hljs-string\">&quot;10m&quot;</span>))));<br><span class=\"hljs-type\">OpenPointInTimeResponse</span> <span class=\"hljs-variable\">openResponse</span> <span class=\"hljs-operator\">=</span> elasticsearchClient.openPointInTime(openRequest);<br><br><span class=\"hljs-comment\">//查询数据</span><br><span class=\"hljs-type\">SearchRequest</span> <span class=\"hljs-variable\">searchRequest</span> <span class=\"hljs-operator\">=</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">SearchRequest</span>.Builder()<br>    .size(pageSize)<br>    .sort(sortOptions)<br>    .pit(p -&gt; p.id(params.getPit()));<br>    .build();<br>elasticsearchClient.search(searchRequest);    <br>    <br><span class=\"hljs-comment\">//关闭pit</span><br><span class=\"hljs-type\">ClosePointInTimeRequest</span> <span class=\"hljs-variable\">closeRequest</span> <span class=\"hljs-operator\">=</span> ClosePointInTimeRequest.of(c -&gt; c.id(pit));<br>elasticsearchClient.closePointInTime(closeRequest);<br><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4-获取搜索结果数量\"><a href=\"#4-获取搜索结果数量\" class=\"headerlink\" title=\"4.获取搜索结果数量\"></a>4.获取搜索结果数量</h2><p>在默认情况下<code>search</code>接口返回的<code>hits size</code>最大值是10000，如果需要获取实际的结果总数，需要开启<code>TrackHits</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">SearchRequest</span> <span class=\"hljs-variable\">searchRequest</span> <span class=\"hljs-operator\">=</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">SearchRequest</span>.Builder()<br>    .trackTotalHits(TrackHits.of(t-&gt;t.enabled(<span class=\"hljs-literal\">true</span>)));<br>    .build();<br>elasticsearchClient.search(searchRequest);    <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-并发写入\"><a href=\"#5-并发写入\" class=\"headerlink\" title=\"5.并发写入\"></a>5.并发写入</h2><p>一般情况下，Elasticsearch数据的写入会通过mq来进行触发，理论上可以通过mq的有序性来控制并发写入导致的数据覆盖问题，现实情况中考虑到性能、可靠性，较少采用这种方式。</p>\n<p>方案一：增加version数据版本字段，通过CAS操作来实现乐观锁；</p>\n<p>方案二：使用分布式锁，确保同一时间单个文档只有一个线程在执行更新操作，重试操作可以由mq来实现；</p>\n<h2 id=\"6-数据库事务\"><a href=\"#6-数据库事务\" class=\"headerlink\" title=\"6.数据库事务\"></a>6.数据库事务</h2><p>假设你正在使用Elasticsearch存储订单数据，在业务代码中的执行步骤如下：</p>\n<ul>\n<li>更新MySQL中订单表数据；</li>\n<li>发送订单变更的mq通知；</li>\n<li>消费mq消息，从MySQL读取最新的数据写入Elasticsearch；</li>\n</ul>\n<p>在运行一段时间后，你可能会发现Elasticsearch的数据与MySQL不一致，不是最新的版本；仔细分析上述过程会发现一个问题，在执行第2步操作时第1步的数据事务还没提交完成，将导致第3读取的不是最新数据。提供一种解决问题的思路，在事务提交完成后再发送mq消息。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\">TransactionSynchronizationManager.registerSynchronization(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">TransactionSynchronizationAdapter</span>()&#123;<br>    <span class=\"hljs-meta\">@Override</span><br>    <span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title function_\">afterCommit</span><span class=\"hljs-params\">()</span> &#123;<br>        <span class=\"hljs-comment\">//发送mq</span><br>    &#125;<br>&#125;);<br></code></pre></td></tr></table></figure>\n<p>今天就先写到这里，你学”废”了吗。</p>\n","excerpt":"","more":"<p>在上一篇文章中，我们介绍了Elasticsearch java  client的一些基本用法，为了达到生产级别的使用标准，下面介绍一些进阶的用法。</p>\n<h2 id=\"1-客户端tcp连接超时\"><a href=\"#1-客户端tcp连接超时\" class=\"headerlink\" title=\"1.客户端tcp连接超时\"></a>1.客户端tcp连接超时</h2><p>在我们创建客户端时，实际上创建的是<code>RestClient</code>，而底层使用的是<code>apache</code>的<code>HttpClient</code>，在创建后长时间无操作时这个连接可能会被关闭，此时客户端并不知晓，直接使用就会提示下文中的错误。再次请求又是正常的，因为客户端会重新创建连接。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\">java.net.SocketTimeoutException: <span class=\"hljs-number\">30</span>,<span class=\"hljs-number\">000</span> milliseconds timeout on connection http-outgoing-<span class=\"hljs-number\">6</span> [ACTIVE]<br>  at org.elasticsearch.client.RestClient.extractAndWrapCause(RestClient.java:<span class=\"hljs-number\">915</span>)<br>  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:<span class=\"hljs-number\">300</span>)<br>  at org.elasticsearch.client.RestClient.performRequest(RestClient.java:<span class=\"hljs-number\">288</span>)<br>  at co.elastic.clients.transport.rest_client.RestClientTransport.performRequest(RestClientTransport.java:<span class=\"hljs-number\">147</span>)<br>  at co.elastic.clients.elasticsearch.ElasticsearchClient.search(ElasticsearchClient.java:<span class=\"hljs-number\">1833</span>)<br>Caused by: java.net.SocketTimeoutException: <span class=\"hljs-number\">30</span>,<span class=\"hljs-number\">000</span> milliseconds timeout on connection http-outgoing-<span class=\"hljs-number\">6</span> [ACTIVE]<br>  at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.timeout(HttpAsyncRequestExecutor.java:<span class=\"hljs-number\">381</span>)<br>  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:<span class=\"hljs-number\">92</span>)<br>  at org.apache.http.impl.nio.client.InternalIODispatch.onTimeout(InternalIODispatch.java:<span class=\"hljs-number\">39</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractIODispatch.timeout(AbstractIODispatch.java:<span class=\"hljs-number\">175</span>)<br>  at org.apache.http.impl.nio.reactor.BaseIOReactor.sessionTimedOut(BaseIOReactor.java:<span class=\"hljs-number\">263</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractIOReactor.timeoutCheck(AbstractIOReactor.java:<span class=\"hljs-number\">492</span>)<br>  at org.apache.http.impl.nio.reactor.BaseIOReactor.validate(BaseIOReactor.java:<span class=\"hljs-number\">213</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:<span class=\"hljs-number\">280</span>)<br>  at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:<span class=\"hljs-number\">104</span>)<br>  at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:<span class=\"hljs-number\">588</span>)<br>  at java.lang.Thread.run(Thread.java:<span class=\"hljs-number\">748</span>)<br></code></pre></td></tr></table></figure>\n\n<p>这个问题在Github的官方Issues上面也有相关的讨论：<a href=\"https://github.com/elastic/elasticsearch/issues/65213\">https://github.com/elastic/elasticsearch/issues/65213</a></p>\n<p>解决问题的关键在于让连接能够保持<code>tcp keepalive</code>，有两种方案：</p>\n<p>方案一：在客户端中显式的开启<code>keepalive</code>选项</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">RestClient</span> <span class=\"hljs-variable\">httpClient</span> <span class=\"hljs-operator\">=</span> RestClient.builder(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">HttpHost</span>(hostName, port))<br>    .setHttpClientConfigCallback(hc -&gt; hc<br>        .setDefaultIOReactorConfig(IOReactorConfig.custom().setSoKeepAlive(<span class=\"hljs-literal\">true</span>).build())<br>     ).build();<br></code></pre></td></tr></table></figure>\n\n<p>另外，还需要设置系统层面的<code>tcp keepalive</code>探测时间，默认值7200s太长可能会被主动关闭，建议修改为300s，默认配置如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Bash\">net.ipv4.tcp_keepalive_time = 7200<br>net.ipv4.tcp_keepalive_intvl = 75<br>net.ipv4.tcp_keepalive_probes = 9<br></code></pre></td></tr></table></figure>\n\n<p>方案二：在客户端设置<code>keepalive</code>策略，在超过指定时间后由客户端自行关闭，使用时再重新创建</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">RestClient</span> <span class=\"hljs-variable\">httpClient</span> <span class=\"hljs-operator\">=</span> RestClient.builder(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">HttpHost</span>(hostName, port))<br>    .setHttpClientConfigCallback(hc -&gt; hc<br>            .setKeepAliveStrategy((response, context) -&gt; Duration.ofMinutes(<span class=\"hljs-number\">5</span>).toMillis()))<br>    .build();<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-聚合统计\"><a href=\"#2-聚合统计\" class=\"headerlink\" title=\"2.聚合统计\"></a>2.聚合统计</h2><p>在Elasticsearch中Aggregation 分为3种类型：</p>\n<ul>\n<li>Metric: 计算类型，对字段进行计算平均值、求和等；</li>\n<li>Bucket: 分组统计，根据字段或者范围将文档分组到桶中进行统计；</li>\n<li>Pipeline：对聚合结果再次进行聚合统计；</li>\n</ul>\n<p>在分组统计中有2个参数需要特别关注：Size、Shard size。官方文档：<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html\">https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html</a></p>\n<p>Size：在使用<code>terms</code>对字段进行分桶时，默认值返回top 10文档，即只有10个统计结果，通过设置size的大小可以返回所需大小，最大值不超过<code>search.max_buckets</code>。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">MultiTermsAggregation</span> <span class=\"hljs-variable\">aggregation</span> <span class=\"hljs-operator\">=</span> MultiTermsAggregation.of(s -&gt; s.terms(<br>    MultiTermLookup.of(t-&gt;t.field(<span class=\"hljs-string\">&quot;product&quot;</span>)),<br>    MultiTermLookup.of(t-&gt;t.field(<span class=\"hljs-string\">&quot;user&quot;</span>))<br>).size(<span class=\"hljs-number\">100</span>));<br><br></code></pre></td></tr></table></figure>\n<p>Shard size：在上一篇文章中，我们介绍过Elasticsearch的查询过程，需要从每个分片获取结果后，再由协调节点进行合并排序。由于数据分布不均匀的缘故，如果每个分片只获取<code>size</code>大小的文档，可能会出现统计偏差。</p>\n<p>Elasticsearch的解决方案是获取比所需更多的文档，在一定程度上避免这个问题，也就是<code>Shard size</code>参数的用途。默认值：<code>Shard size = size * 1.5 + 10</code>，在数据偏斜严重的情况下，可以适当调大这个参数，当然也意味着更多的性能损耗。</p>\n<h2 id=\"3-数据快照\"><a href=\"#3-数据快照\" class=\"headerlink\" title=\"3.数据快照\"></a>3.数据快照</h2><p>之前我们介绍过<code>search_after</code> 能够实现深度分页功能，而在一些大批量数据导出的场景下，通常需要保持数据游标不变来导出完整的数据，类似于快照的功能。而这就需要用到 <code>point in time (PIT) </code>。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-comment\">//获取pit id</span><br><span class=\"hljs-type\">OpenPointInTimeRequest</span> <span class=\"hljs-variable\">openRequest</span> <span class=\"hljs-operator\">=</span> OpenPointInTimeRequest.of(o -&gt; o<br>    .index(getIndex())<br>    .keepAlive(Time.of(t-&gt;t.time(<span class=\"hljs-string\">&quot;10m&quot;</span>))));<br><span class=\"hljs-type\">OpenPointInTimeResponse</span> <span class=\"hljs-variable\">openResponse</span> <span class=\"hljs-operator\">=</span> elasticsearchClient.openPointInTime(openRequest);<br><br><span class=\"hljs-comment\">//查询数据</span><br><span class=\"hljs-type\">SearchRequest</span> <span class=\"hljs-variable\">searchRequest</span> <span class=\"hljs-operator\">=</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">SearchRequest</span>.Builder()<br>    .size(pageSize)<br>    .sort(sortOptions)<br>    .pit(p -&gt; p.id(params.getPit()));<br>    .build();<br>elasticsearchClient.search(searchRequest);    <br>    <br><span class=\"hljs-comment\">//关闭pit</span><br><span class=\"hljs-type\">ClosePointInTimeRequest</span> <span class=\"hljs-variable\">closeRequest</span> <span class=\"hljs-operator\">=</span> ClosePointInTimeRequest.of(c -&gt; c.id(pit));<br>elasticsearchClient.closePointInTime(closeRequest);<br><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4-获取搜索结果数量\"><a href=\"#4-获取搜索结果数量\" class=\"headerlink\" title=\"4.获取搜索结果数量\"></a>4.获取搜索结果数量</h2><p>在默认情况下<code>search</code>接口返回的<code>hits size</code>最大值是10000，如果需要获取实际的结果总数，需要开启<code>TrackHits</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\"><span class=\"hljs-type\">SearchRequest</span> <span class=\"hljs-variable\">searchRequest</span> <span class=\"hljs-operator\">=</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">SearchRequest</span>.Builder()<br>    .trackTotalHits(TrackHits.of(t-&gt;t.enabled(<span class=\"hljs-literal\">true</span>)));<br>    .build();<br>elasticsearchClient.search(searchRequest);    <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-并发写入\"><a href=\"#5-并发写入\" class=\"headerlink\" title=\"5.并发写入\"></a>5.并发写入</h2><p>一般情况下，Elasticsearch数据的写入会通过mq来进行触发，理论上可以通过mq的有序性来控制并发写入导致的数据覆盖问题，现实情况中考虑到性能、可靠性，较少采用这种方式。</p>\n<p>方案一：增加version数据版本字段，通过CAS操作来实现乐观锁；</p>\n<p>方案二：使用分布式锁，确保同一时间单个文档只有一个线程在执行更新操作，重试操作可以由mq来实现；</p>\n<h2 id=\"6-数据库事务\"><a href=\"#6-数据库事务\" class=\"headerlink\" title=\"6.数据库事务\"></a>6.数据库事务</h2><p>假设你正在使用Elasticsearch存储订单数据，在业务代码中的执行步骤如下：</p>\n<ul>\n<li>更新MySQL中订单表数据；</li>\n<li>发送订单变更的mq通知；</li>\n<li>消费mq消息，从MySQL读取最新的数据写入Elasticsearch；</li>\n</ul>\n<p>在运行一段时间后，你可能会发现Elasticsearch的数据与MySQL不一致，不是最新的版本；仔细分析上述过程会发现一个问题，在执行第2步操作时第1步的数据事务还没提交完成，将导致第3读取的不是最新数据。提供一种解决问题的思路，在事务提交完成后再发送mq消息。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs Java\">TransactionSynchronizationManager.registerSynchronization(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">TransactionSynchronizationAdapter</span>()&#123;<br>    <span class=\"hljs-meta\">@Override</span><br>    <span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title function_\">afterCommit</span><span class=\"hljs-params\">()</span> &#123;<br>        <span class=\"hljs-comment\">//发送mq</span><br>    &#125;<br>&#125;);<br></code></pre></td></tr></table></figure>\n<p>今天就先写到这里，你学”废”了吗。</p>\n"},{"title":"Elasticsearch写入速度优化[翻译版]","date":"2023-04-30T16:00:00.000Z","_content":"\n在上一篇文章中提到了学习英语需要用起来，假期尝试对Elasticsearch文档进行了翻译，最终成果如下。\n\n原文链接：[https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html)\n\n### 1.使用批处理请求接口（bulk requests）\n\n批处理接口的性能要远优于单文档写入接口。为了确定批处理最适合的大小，基准测试应该基于单节点、单分片。首先尝试一次写入100个文档，然后加大到200个、400个，以此类推。每次跑基准测试时将写入数量加倍。当写入速度趋于平稳时，说明已经达到了单次写入的最适合批次大小。在同等情况下，文档数量不宜过多。值得注意的是，大数据量的批处理请求在并发高时，会加大集群的内存压力，因此需要尽量避免一次请求超过几十兆的数据量，就算是效率更高。\n\n### 2.使用多线程实现写入数据\n\n单线程发送批处理请求，并不能最大化Elasticsearch集群的写入效率。为了集群资源的最大化利用，你应该使用多线程来进行处理。除了更好的利用集群资源，还能够降低数据同步的成本。\n\n当出现 `TOO_MANY_REQUESTS (429)` 返回码（在Java客户端是 `EsRejectedExecutionException` 异常）时，说明 Elasticsearch 无法承载当前的写入速率。此时，你需要降低写入的速率，最好能够使用指数级的降级策略。\n\n和批处理大小类似，确定并发线程数量只能通过不断的测试。测试方式是通过逐步增加线程数量，直到 I/0 或者 CPU资源达到饱和为止。\n\n### 3.不设置或者增大刷新间隔\n\n通过 `refresh` 操作，数据才能被搜索到，执行成本较高，当数据正在写入时，频繁的 `refresh` 会影响写入速度。\n\n默认情况下，Elasticsearch每秒刷新一次索引，但是只有在最近30s内收到一次或者多次搜索请求时才会生效。\n\n如果你的搜索请求量非常小(例如，5分钟内少于一次)，或者想要优化写入速度，有相应的配置可以进行支持。默认情况是这没有搜索执行时，可以自动优化批量写入速度。可以通过设置刷新间隔参数来显式的进行设置。\n\n另一方面，如果你的索引有比较稳定的请求流量，Elasticsearch将默认每秒刷新一次数据。如果你能够接受文档从写入完成到可以被搜索到有较大的延迟时间，可以将\n\n`index.refresh_interval` 参数设置为一比较大的值，例如30s，可以改善文档写入速度。\n\n### 4.在初始化时不开启备份\n\n如果你有大批量的数据想要一次性导入到Elasticsearch，将 `index.number_of_replicas` 参数设置为0将有利于提升写入速度。缺少备份意味着存在数据丢失的风险，所以很重要的一点是，在其他地方有存储这份数据以便在意外的情况下可以进行重试操作。一旦数据初始化工作完成，可以将`index.number_of_replicas` 参数恢复为原始值。\n\n如果index.refresh_interval 参数是配置在索引上的，在初始化数据的场景下不进行设置，在初始化完成后恢复原始值，将会是一个很有帮助的特性。\n\n### 5.关闭swapping\n\n你应该通过关闭操作系统的swapping的功能，来确保Java进程的内存不会被超额使用。\n\n### 6.留足文件系统内存\n\n文件系统内存用于数据的 I/O 操作。你应该确保运行Elasticsearch的机器上至少有一半的内存可以被文件系统内存使用。\n\n### 7.使用自增ID\n\n当写入一份带有id属性的文档时，Elasticsearch需要检查在同一个分片上是否已经存在具有相同id的文档，而这个操作随着文档数量的增加将耗费更多的时间。使用自增id，Elasticsearch可以跳过检查的这一步，加快写入速度。\n\n### 8.使用更快的硬件\n\n如果数据写入达到了I/O瓶颈，可以考虑增加文件系统的内存或者使用更快的存储设备。Elasticsearch在创建单个文件时是使用顺序写入。然而，并发写入多个文件时，会涉及到随机读和顺序读操作，因此SSD要比机械硬盘有更好的性能。\n\n通过设置RAID 0磁盘阵列，将索引分布着多个SSD磁盘上。这样会增加失败的风险，当任一SSD磁盘毁坏了索引数据时。然而，常用的权衡利弊的做法是，将单个分片的性能提升到极致，然后通过副本的方式在其他分片上设置冗余数据，来解决任意节点失败的情况。为了更加保险，可以通过设置快照的方式来进行备份数据。\n\n### 9.写入的缓存大小\n\n如果你的节点在进行大量数据写入，确保 indices.memory.index_buffer_size 参数足够大到每个分片有最多512M的`indexing buffer`（超过这个值写入性能不会有明显的改善）。Elasticsearch将这个设置（java heap的百分比或者具体的数值）作为共享内存提供给所有活跃的分片使用。更加活跃的分片会占用更多的内存。\n\n默认值10%通常上足够的，例如，jvm内存设置为10G，index buffer就上1G了，足够2个分片进行大量数据的写入。\n\n### 10.使用多集群实现读写分离\n\n在单个集群中，读写需要竞争资源。设置2个集群，通过跨集群复制将数据从一个集群复制到另外一个，将查询请求都路由到从索引，查询操作将不会占用主索引节点的资源了。\n\n### 11.避免热点问题\n\n当节点资源、分片、请求不均衡时可能会出现热点问题。Elasticsearch通过跨节点来同步集群状态，热点问题将引发集群能力的退化。\n\n### 12.其他优化策略\n\n在磁盘的使用方面也有很多可以提升写入速度的策略。","source":"_posts/Elasticsearch写入速度优化[翻译版].md","raw":"---\ntitle: Elasticsearch写入速度优化[翻译版]\ndate: 2023-05-01\n---\n\n在上一篇文章中提到了学习英语需要用起来，假期尝试对Elasticsearch文档进行了翻译，最终成果如下。\n\n原文链接：[https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html)\n\n### 1.使用批处理请求接口（bulk requests）\n\n批处理接口的性能要远优于单文档写入接口。为了确定批处理最适合的大小，基准测试应该基于单节点、单分片。首先尝试一次写入100个文档，然后加大到200个、400个，以此类推。每次跑基准测试时将写入数量加倍。当写入速度趋于平稳时，说明已经达到了单次写入的最适合批次大小。在同等情况下，文档数量不宜过多。值得注意的是，大数据量的批处理请求在并发高时，会加大集群的内存压力，因此需要尽量避免一次请求超过几十兆的数据量，就算是效率更高。\n\n### 2.使用多线程实现写入数据\n\n单线程发送批处理请求，并不能最大化Elasticsearch集群的写入效率。为了集群资源的最大化利用，你应该使用多线程来进行处理。除了更好的利用集群资源，还能够降低数据同步的成本。\n\n当出现 `TOO_MANY_REQUESTS (429)` 返回码（在Java客户端是 `EsRejectedExecutionException` 异常）时，说明 Elasticsearch 无法承载当前的写入速率。此时，你需要降低写入的速率，最好能够使用指数级的降级策略。\n\n和批处理大小类似，确定并发线程数量只能通过不断的测试。测试方式是通过逐步增加线程数量，直到 I/0 或者 CPU资源达到饱和为止。\n\n### 3.不设置或者增大刷新间隔\n\n通过 `refresh` 操作，数据才能被搜索到，执行成本较高，当数据正在写入时，频繁的 `refresh` 会影响写入速度。\n\n默认情况下，Elasticsearch每秒刷新一次索引，但是只有在最近30s内收到一次或者多次搜索请求时才会生效。\n\n如果你的搜索请求量非常小(例如，5分钟内少于一次)，或者想要优化写入速度，有相应的配置可以进行支持。默认情况是这没有搜索执行时，可以自动优化批量写入速度。可以通过设置刷新间隔参数来显式的进行设置。\n\n另一方面，如果你的索引有比较稳定的请求流量，Elasticsearch将默认每秒刷新一次数据。如果你能够接受文档从写入完成到可以被搜索到有较大的延迟时间，可以将\n\n`index.refresh_interval` 参数设置为一比较大的值，例如30s，可以改善文档写入速度。\n\n### 4.在初始化时不开启备份\n\n如果你有大批量的数据想要一次性导入到Elasticsearch，将 `index.number_of_replicas` 参数设置为0将有利于提升写入速度。缺少备份意味着存在数据丢失的风险，所以很重要的一点是，在其他地方有存储这份数据以便在意外的情况下可以进行重试操作。一旦数据初始化工作完成，可以将`index.number_of_replicas` 参数恢复为原始值。\n\n如果index.refresh_interval 参数是配置在索引上的，在初始化数据的场景下不进行设置，在初始化完成后恢复原始值，将会是一个很有帮助的特性。\n\n### 5.关闭swapping\n\n你应该通过关闭操作系统的swapping的功能，来确保Java进程的内存不会被超额使用。\n\n### 6.留足文件系统内存\n\n文件系统内存用于数据的 I/O 操作。你应该确保运行Elasticsearch的机器上至少有一半的内存可以被文件系统内存使用。\n\n### 7.使用自增ID\n\n当写入一份带有id属性的文档时，Elasticsearch需要检查在同一个分片上是否已经存在具有相同id的文档，而这个操作随着文档数量的增加将耗费更多的时间。使用自增id，Elasticsearch可以跳过检查的这一步，加快写入速度。\n\n### 8.使用更快的硬件\n\n如果数据写入达到了I/O瓶颈，可以考虑增加文件系统的内存或者使用更快的存储设备。Elasticsearch在创建单个文件时是使用顺序写入。然而，并发写入多个文件时，会涉及到随机读和顺序读操作，因此SSD要比机械硬盘有更好的性能。\n\n通过设置RAID 0磁盘阵列，将索引分布着多个SSD磁盘上。这样会增加失败的风险，当任一SSD磁盘毁坏了索引数据时。然而，常用的权衡利弊的做法是，将单个分片的性能提升到极致，然后通过副本的方式在其他分片上设置冗余数据，来解决任意节点失败的情况。为了更加保险，可以通过设置快照的方式来进行备份数据。\n\n### 9.写入的缓存大小\n\n如果你的节点在进行大量数据写入，确保 indices.memory.index_buffer_size 参数足够大到每个分片有最多512M的`indexing buffer`（超过这个值写入性能不会有明显的改善）。Elasticsearch将这个设置（java heap的百分比或者具体的数值）作为共享内存提供给所有活跃的分片使用。更加活跃的分片会占用更多的内存。\n\n默认值10%通常上足够的，例如，jvm内存设置为10G，index buffer就上1G了，足够2个分片进行大量数据的写入。\n\n### 10.使用多集群实现读写分离\n\n在单个集群中，读写需要竞争资源。设置2个集群，通过跨集群复制将数据从一个集群复制到另外一个，将查询请求都路由到从索引，查询操作将不会占用主索引节点的资源了。\n\n### 11.避免热点问题\n\n当节点资源、分片、请求不均衡时可能会出现热点问题。Elasticsearch通过跨节点来同步集群状态，热点问题将引发集群能力的退化。\n\n### 12.其他优化策略\n\n在磁盘的使用方面也有很多可以提升写入速度的策略。","slug":"Elasticsearch写入速度优化[翻译版]","published":1,"updated":"2024-01-30T10:01:56.153Z","_id":"cls06n7q20001iocqho7f35l5","comments":1,"layout":"post","photos":[],"content":"<p>在上一篇文章中提到了学习英语需要用起来，假期尝试对Elasticsearch文档进行了翻译，最终成果如下。</p>\n<p>原文链接：<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html\">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html</a></p>\n<h3 id=\"1-使用批处理请求接口（bulk-requests）\"><a href=\"#1-使用批处理请求接口（bulk-requests）\" class=\"headerlink\" title=\"1.使用批处理请求接口（bulk requests）\"></a>1.使用批处理请求接口（bulk requests）</h3><p>批处理接口的性能要远优于单文档写入接口。为了确定批处理最适合的大小，基准测试应该基于单节点、单分片。首先尝试一次写入100个文档，然后加大到200个、400个，以此类推。每次跑基准测试时将写入数量加倍。当写入速度趋于平稳时，说明已经达到了单次写入的最适合批次大小。在同等情况下，文档数量不宜过多。值得注意的是，大数据量的批处理请求在并发高时，会加大集群的内存压力，因此需要尽量避免一次请求超过几十兆的数据量，就算是效率更高。</p>\n<h3 id=\"2-使用多线程实现写入数据\"><a href=\"#2-使用多线程实现写入数据\" class=\"headerlink\" title=\"2.使用多线程实现写入数据\"></a>2.使用多线程实现写入数据</h3><p>单线程发送批处理请求，并不能最大化Elasticsearch集群的写入效率。为了集群资源的最大化利用，你应该使用多线程来进行处理。除了更好的利用集群资源，还能够降低数据同步的成本。</p>\n<p>当出现 <code>TOO_MANY_REQUESTS (429)</code> 返回码（在Java客户端是 <code>EsRejectedExecutionException</code> 异常）时，说明 Elasticsearch 无法承载当前的写入速率。此时，你需要降低写入的速率，最好能够使用指数级的降级策略。</p>\n<p>和批处理大小类似，确定并发线程数量只能通过不断的测试。测试方式是通过逐步增加线程数量，直到 I&#x2F;0 或者 CPU资源达到饱和为止。</p>\n<h3 id=\"3-不设置或者增大刷新间隔\"><a href=\"#3-不设置或者增大刷新间隔\" class=\"headerlink\" title=\"3.不设置或者增大刷新间隔\"></a>3.不设置或者增大刷新间隔</h3><p>通过 <code>refresh</code> 操作，数据才能被搜索到，执行成本较高，当数据正在写入时，频繁的 <code>refresh</code> 会影响写入速度。</p>\n<p>默认情况下，Elasticsearch每秒刷新一次索引，但是只有在最近30s内收到一次或者多次搜索请求时才会生效。</p>\n<p>如果你的搜索请求量非常小(例如，5分钟内少于一次)，或者想要优化写入速度，有相应的配置可以进行支持。默认情况是这没有搜索执行时，可以自动优化批量写入速度。可以通过设置刷新间隔参数来显式的进行设置。</p>\n<p>另一方面，如果你的索引有比较稳定的请求流量，Elasticsearch将默认每秒刷新一次数据。如果你能够接受文档从写入完成到可以被搜索到有较大的延迟时间，可以将</p>\n<p><code>index.refresh_interval</code> 参数设置为一比较大的值，例如30s，可以改善文档写入速度。</p>\n<h3 id=\"4-在初始化时不开启备份\"><a href=\"#4-在初始化时不开启备份\" class=\"headerlink\" title=\"4.在初始化时不开启备份\"></a>4.在初始化时不开启备份</h3><p>如果你有大批量的数据想要一次性导入到Elasticsearch，将 <code>index.number_of_replicas</code> 参数设置为0将有利于提升写入速度。缺少备份意味着存在数据丢失的风险，所以很重要的一点是，在其他地方有存储这份数据以便在意外的情况下可以进行重试操作。一旦数据初始化工作完成，可以将<code>index.number_of_replicas</code> 参数恢复为原始值。</p>\n<p>如果index.refresh_interval 参数是配置在索引上的，在初始化数据的场景下不进行设置，在初始化完成后恢复原始值，将会是一个很有帮助的特性。</p>\n<h3 id=\"5-关闭swapping\"><a href=\"#5-关闭swapping\" class=\"headerlink\" title=\"5.关闭swapping\"></a>5.关闭swapping</h3><p>你应该通过关闭操作系统的swapping的功能，来确保Java进程的内存不会被超额使用。</p>\n<h3 id=\"6-留足文件系统内存\"><a href=\"#6-留足文件系统内存\" class=\"headerlink\" title=\"6.留足文件系统内存\"></a>6.留足文件系统内存</h3><p>文件系统内存用于数据的 I&#x2F;O 操作。你应该确保运行Elasticsearch的机器上至少有一半的内存可以被文件系统内存使用。</p>\n<h3 id=\"7-使用自增ID\"><a href=\"#7-使用自增ID\" class=\"headerlink\" title=\"7.使用自增ID\"></a>7.使用自增ID</h3><p>当写入一份带有id属性的文档时，Elasticsearch需要检查在同一个分片上是否已经存在具有相同id的文档，而这个操作随着文档数量的增加将耗费更多的时间。使用自增id，Elasticsearch可以跳过检查的这一步，加快写入速度。</p>\n<h3 id=\"8-使用更快的硬件\"><a href=\"#8-使用更快的硬件\" class=\"headerlink\" title=\"8.使用更快的硬件\"></a>8.使用更快的硬件</h3><p>如果数据写入达到了I&#x2F;O瓶颈，可以考虑增加文件系统的内存或者使用更快的存储设备。Elasticsearch在创建单个文件时是使用顺序写入。然而，并发写入多个文件时，会涉及到随机读和顺序读操作，因此SSD要比机械硬盘有更好的性能。</p>\n<p>通过设置RAID 0磁盘阵列，将索引分布着多个SSD磁盘上。这样会增加失败的风险，当任一SSD磁盘毁坏了索引数据时。然而，常用的权衡利弊的做法是，将单个分片的性能提升到极致，然后通过副本的方式在其他分片上设置冗余数据，来解决任意节点失败的情况。为了更加保险，可以通过设置快照的方式来进行备份数据。</p>\n<h3 id=\"9-写入的缓存大小\"><a href=\"#9-写入的缓存大小\" class=\"headerlink\" title=\"9.写入的缓存大小\"></a>9.写入的缓存大小</h3><p>如果你的节点在进行大量数据写入，确保 indices.memory.index_buffer_size 参数足够大到每个分片有最多512M的<code>indexing buffer</code>（超过这个值写入性能不会有明显的改善）。Elasticsearch将这个设置（java heap的百分比或者具体的数值）作为共享内存提供给所有活跃的分片使用。更加活跃的分片会占用更多的内存。</p>\n<p>默认值10%通常上足够的，例如，jvm内存设置为10G，index buffer就上1G了，足够2个分片进行大量数据的写入。</p>\n<h3 id=\"10-使用多集群实现读写分离\"><a href=\"#10-使用多集群实现读写分离\" class=\"headerlink\" title=\"10.使用多集群实现读写分离\"></a>10.使用多集群实现读写分离</h3><p>在单个集群中，读写需要竞争资源。设置2个集群，通过跨集群复制将数据从一个集群复制到另外一个，将查询请求都路由到从索引，查询操作将不会占用主索引节点的资源了。</p>\n<h3 id=\"11-避免热点问题\"><a href=\"#11-避免热点问题\" class=\"headerlink\" title=\"11.避免热点问题\"></a>11.避免热点问题</h3><p>当节点资源、分片、请求不均衡时可能会出现热点问题。Elasticsearch通过跨节点来同步集群状态，热点问题将引发集群能力的退化。</p>\n<h3 id=\"12-其他优化策略\"><a href=\"#12-其他优化策略\" class=\"headerlink\" title=\"12.其他优化策略\"></a>12.其他优化策略</h3><p>在磁盘的使用方面也有很多可以提升写入速度的策略。</p>\n","excerpt":"","more":"<p>在上一篇文章中提到了学习英语需要用起来，假期尝试对Elasticsearch文档进行了翻译，最终成果如下。</p>\n<p>原文链接：<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html\">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html</a></p>\n<h3 id=\"1-使用批处理请求接口（bulk-requests）\"><a href=\"#1-使用批处理请求接口（bulk-requests）\" class=\"headerlink\" title=\"1.使用批处理请求接口（bulk requests）\"></a>1.使用批处理请求接口（bulk requests）</h3><p>批处理接口的性能要远优于单文档写入接口。为了确定批处理最适合的大小，基准测试应该基于单节点、单分片。首先尝试一次写入100个文档，然后加大到200个、400个，以此类推。每次跑基准测试时将写入数量加倍。当写入速度趋于平稳时，说明已经达到了单次写入的最适合批次大小。在同等情况下，文档数量不宜过多。值得注意的是，大数据量的批处理请求在并发高时，会加大集群的内存压力，因此需要尽量避免一次请求超过几十兆的数据量，就算是效率更高。</p>\n<h3 id=\"2-使用多线程实现写入数据\"><a href=\"#2-使用多线程实现写入数据\" class=\"headerlink\" title=\"2.使用多线程实现写入数据\"></a>2.使用多线程实现写入数据</h3><p>单线程发送批处理请求，并不能最大化Elasticsearch集群的写入效率。为了集群资源的最大化利用，你应该使用多线程来进行处理。除了更好的利用集群资源，还能够降低数据同步的成本。</p>\n<p>当出现 <code>TOO_MANY_REQUESTS (429)</code> 返回码（在Java客户端是 <code>EsRejectedExecutionException</code> 异常）时，说明 Elasticsearch 无法承载当前的写入速率。此时，你需要降低写入的速率，最好能够使用指数级的降级策略。</p>\n<p>和批处理大小类似，确定并发线程数量只能通过不断的测试。测试方式是通过逐步增加线程数量，直到 I&#x2F;0 或者 CPU资源达到饱和为止。</p>\n<h3 id=\"3-不设置或者增大刷新间隔\"><a href=\"#3-不设置或者增大刷新间隔\" class=\"headerlink\" title=\"3.不设置或者增大刷新间隔\"></a>3.不设置或者增大刷新间隔</h3><p>通过 <code>refresh</code> 操作，数据才能被搜索到，执行成本较高，当数据正在写入时，频繁的 <code>refresh</code> 会影响写入速度。</p>\n<p>默认情况下，Elasticsearch每秒刷新一次索引，但是只有在最近30s内收到一次或者多次搜索请求时才会生效。</p>\n<p>如果你的搜索请求量非常小(例如，5分钟内少于一次)，或者想要优化写入速度，有相应的配置可以进行支持。默认情况是这没有搜索执行时，可以自动优化批量写入速度。可以通过设置刷新间隔参数来显式的进行设置。</p>\n<p>另一方面，如果你的索引有比较稳定的请求流量，Elasticsearch将默认每秒刷新一次数据。如果你能够接受文档从写入完成到可以被搜索到有较大的延迟时间，可以将</p>\n<p><code>index.refresh_interval</code> 参数设置为一比较大的值，例如30s，可以改善文档写入速度。</p>\n<h3 id=\"4-在初始化时不开启备份\"><a href=\"#4-在初始化时不开启备份\" class=\"headerlink\" title=\"4.在初始化时不开启备份\"></a>4.在初始化时不开启备份</h3><p>如果你有大批量的数据想要一次性导入到Elasticsearch，将 <code>index.number_of_replicas</code> 参数设置为0将有利于提升写入速度。缺少备份意味着存在数据丢失的风险，所以很重要的一点是，在其他地方有存储这份数据以便在意外的情况下可以进行重试操作。一旦数据初始化工作完成，可以将<code>index.number_of_replicas</code> 参数恢复为原始值。</p>\n<p>如果index.refresh_interval 参数是配置在索引上的，在初始化数据的场景下不进行设置，在初始化完成后恢复原始值，将会是一个很有帮助的特性。</p>\n<h3 id=\"5-关闭swapping\"><a href=\"#5-关闭swapping\" class=\"headerlink\" title=\"5.关闭swapping\"></a>5.关闭swapping</h3><p>你应该通过关闭操作系统的swapping的功能，来确保Java进程的内存不会被超额使用。</p>\n<h3 id=\"6-留足文件系统内存\"><a href=\"#6-留足文件系统内存\" class=\"headerlink\" title=\"6.留足文件系统内存\"></a>6.留足文件系统内存</h3><p>文件系统内存用于数据的 I&#x2F;O 操作。你应该确保运行Elasticsearch的机器上至少有一半的内存可以被文件系统内存使用。</p>\n<h3 id=\"7-使用自增ID\"><a href=\"#7-使用自增ID\" class=\"headerlink\" title=\"7.使用自增ID\"></a>7.使用自增ID</h3><p>当写入一份带有id属性的文档时，Elasticsearch需要检查在同一个分片上是否已经存在具有相同id的文档，而这个操作随着文档数量的增加将耗费更多的时间。使用自增id，Elasticsearch可以跳过检查的这一步，加快写入速度。</p>\n<h3 id=\"8-使用更快的硬件\"><a href=\"#8-使用更快的硬件\" class=\"headerlink\" title=\"8.使用更快的硬件\"></a>8.使用更快的硬件</h3><p>如果数据写入达到了I&#x2F;O瓶颈，可以考虑增加文件系统的内存或者使用更快的存储设备。Elasticsearch在创建单个文件时是使用顺序写入。然而，并发写入多个文件时，会涉及到随机读和顺序读操作，因此SSD要比机械硬盘有更好的性能。</p>\n<p>通过设置RAID 0磁盘阵列，将索引分布着多个SSD磁盘上。这样会增加失败的风险，当任一SSD磁盘毁坏了索引数据时。然而，常用的权衡利弊的做法是，将单个分片的性能提升到极致，然后通过副本的方式在其他分片上设置冗余数据，来解决任意节点失败的情况。为了更加保险，可以通过设置快照的方式来进行备份数据。</p>\n<h3 id=\"9-写入的缓存大小\"><a href=\"#9-写入的缓存大小\" class=\"headerlink\" title=\"9.写入的缓存大小\"></a>9.写入的缓存大小</h3><p>如果你的节点在进行大量数据写入，确保 indices.memory.index_buffer_size 参数足够大到每个分片有最多512M的<code>indexing buffer</code>（超过这个值写入性能不会有明显的改善）。Elasticsearch将这个设置（java heap的百分比或者具体的数值）作为共享内存提供给所有活跃的分片使用。更加活跃的分片会占用更多的内存。</p>\n<p>默认值10%通常上足够的，例如，jvm内存设置为10G，index buffer就上1G了，足够2个分片进行大量数据的写入。</p>\n<h3 id=\"10-使用多集群实现读写分离\"><a href=\"#10-使用多集群实现读写分离\" class=\"headerlink\" title=\"10.使用多集群实现读写分离\"></a>10.使用多集群实现读写分离</h3><p>在单个集群中，读写需要竞争资源。设置2个集群，通过跨集群复制将数据从一个集群复制到另外一个，将查询请求都路由到从索引，查询操作将不会占用主索引节点的资源了。</p>\n<h3 id=\"11-避免热点问题\"><a href=\"#11-避免热点问题\" class=\"headerlink\" title=\"11.避免热点问题\"></a>11.避免热点问题</h3><p>当节点资源、分片、请求不均衡时可能会出现热点问题。Elasticsearch通过跨节点来同步集群状态，热点问题将引发集群能力的退化。</p>\n<h3 id=\"12-其他优化策略\"><a href=\"#12-其他优化策略\" class=\"headerlink\" title=\"12.其他优化策略\"></a>12.其他优化策略</h3><p>在磁盘的使用方面也有很多可以提升写入速度的策略。</p>\n"},{"title":"Elasticsearch Java API Client 8.x使用方式","date":"2023-03-30T16:00:00.000Z","_content":"\n### 客户端的变化\n众所周知，Elasticsearch是基于Lucene的，提供了更高层次的封装、分布式方面的扩展，以及REST API来方便使用，我们先来看看java client的变化：\n\n![](/img_convert/2.png)\n从图中可以看成，在8.x版本中，Elasticsearch提供了全新的Java API Client，用来代替之前广为使用的High Level Client，根据官网说法两者并无关联；而更具有灵活性和偏向底层的Low Level Client依旧在迭代，提供给用户更多的选择。\n\n### 快速开始\n话不多说，直接开始，Java API Client依赖于JSON来进行数据格式化，支持Jackson或者JSON-B库，引入相应maven依赖。\n\n``` \n<dependency>\n  <groupId>co.elastic.clients</groupId>\n\t<artifactId>elasticsearch-java</artifactId>\n\t<version>8.6.2</version>\n</dependency>\n\n<dependency>\n  <groupId>com.fasterxml.jackson.core</groupId>\n  <artifactId>jackson-databind</artifactId>\n  <version>2.12.3</version>\n</dependency>\n\n<dependency>\n  <groupId>jakarta.json</groupId>\n  <artifactId>jakarta.json-api</artifactId>\n  <version>2.0.1</version>\n</dependency>\n```\n\n下一步连接Elasticsearch服务端：\n\n```\n@Component\npublic class ElasticsearchConfig {\n\n    @Bean\n    public ElasticsearchClient elasticsearchClient(){\n        BasicCredentialsProvider credentialsProvider = new BasicCredentialsProvider();\n        credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(userName, password));\n\n        RestClient httpClient = RestClient.builder(new HttpHost(hostName, port))\n            .setHttpClientConfigCallback(hc -> hc.setDefaultCredentialsProvider(credentialsProvider))\n            .build();\n\n        ElasticsearchTransport transport = new RestClientTransport(httpClient, new JacksonJsonpMapper());\n        return new ElasticsearchClient(transport);\n    }\n}\n```\n在这里创建的是一个同步的客户端，Java API Client还支持创建异步的客户端：ElasticsearchAsyncClient，返回的是一个标准的 CompletableFuture，按需选择。另外我们还可以看到，创建对象时使用了构造器模式，以及lambda表达式，这两种方式使得代码更加简洁和高效。\n\n### JakartaEE\n补充一点额外内容，JSON-B库的全称是Jakarta JSON Binding，是用于Java对象与JSON消息相互转换的标准绑定层，来源于Jakarta EE。\n而Jakarta EE并不是什么新鲜技术，它的前身是Java EE。之所以改名称，是因为2017年Oracle宣布开源Java EE并将项目移交给Eclipse基金会时，提出来的要求，导致改名事件。现阶段一般都在使用类似于SpringBoot的框架，Java EE的存在感就更弱了，这里就不再扩展了。\n\n### 写入文档\nJava API Client支持写入bean对象，或者直接写入JSON格式数据，其中bean对象会被自动映射为JSON。\n\n```\npublic void index() throws IOException {\n    Order order = new Order(1L, \"test product\", 233L);\n\n    IndexRequest<Order> request = IndexRequest.of(i -> i\n        .index(\"order-index\")\n        .id(String.valueOf(order.getId()))\n        .document(order)\n        .version(1L)\n    );\n\n    IndexResponse indexResponse = elasticsearchClient.index(request);\n    log.info(\"indexResponse:{}\", indexResponse.toString());\n}\n```\n构建一个order对象后，使用其ID作为主键，写入到名为\"order-index\"的索引之中，同时通过version参数指定了数据版本号，来进行并发控制。\n\n### 搜索文档\n以产品名称、价格作为搜索条件，来看看具体的实现：\n\n```\npublic void search() throws IOException {\n    String keyword = \"apple\";\n    Long maxPrice = 100L;\n\n    Query byProduct = MatchQuery.of(m -> m\n        .field(\"product\")\n        .query(keyword)\n    )._toQuery();\n\n    Query byMaxPrice = RangeQuery.of(r -> r\n        .field(\"price\")\n        .gte(JsonData.of(maxPrice))\n    )._toQuery();\n    \n    SortOptions sortOptions = SortOptions.of(s -> s\n        .field(FieldSort.of(f->f\n            .field(\"id\")\n            .order(SortOrder.Desc))\n        )\n    );\n\n    SearchResponse<Order> response = elasticsearchClient.search(s -> s\n        .index(\"order-index\")\n        .query(q -> q\n            .bool(b -> b\n                .must(byProduct)\n                .must(byMaxPrice)\n            )\n        )\n        .from(0)\n        .size(10), \n        Order.class\n    );\n\n    List<Hit<Order>> hits = response.hits().hits();\n    hits.forEach(hit -> {\n        Order order = hit.source();\n        List<FieldValue> sortList = hit.sort();\n    });\n}\n```\n### 深度分页\n在搜索文档的实现中，指定了from和size参数，目的的为了实现分页效果；其中from是游标位置，size是返回数据量大小，类似于MySQL的limit功能。当from过大时Elasticsearch会返回一个错误：\n`Result window is too large, from + size must be less than or equal to: [10000]`\n\n分析这个错误，需要从搜索的实现原理来入手。在客户端请求到达协调节点后，会从各个分片的数据节点获取数据，因为数据分布不均匀的关系，例如在查询第2页的10条数据时，需要从每个节点都获取20条数据，进行排序来避免数据遗漏。\n\n![](/img_convert/3.png)\n\n在之前的版本中，Elasticsearch经常会出现的一个问题是查询1W条以后的数据会非常慢，也就是因为这个原因，解决办法是使用Scroll API，使用快照的思路实现。在最新版中，这种方式已经不再推荐使用，取而待之的是search_after参数。\n\n```\nelasticsearchClient.search(s -> s\n    .index(\"order-index\")\n    .searchAfter(FieldValue.of(1878133432))\n    .sort(sortOptions)\n    .size(20),\n    Order.class\n);\n```\n### 聚合功能\nElasticsearch中聚合常见的应用场景是实现类似于MySQL的sum、count、group by功能，来看一个多参数group by的实现。\n\n```\npublic void aggregation() throws IOException {\n    MultiTermsAggregation aggregation = MultiTermsAggregation.of(s -> s.terms(\n        MultiTermLookup.of(t->t.field(\"product\")),\n        MultiTermLookup.of(t->t.field(\"user\"))\n    ));\n\n    Aggregation priceAggregation = Aggregation.of(s -> s.sum(AggregationBuilders.sum().field(\"price\").build()));\n    Aggregation idAggregation = Aggregation.of(s -> s.valueCount(ValueCountAggregation.of(v -> v.field(\"id\"))));\n\n    Aggregation aggs = Aggregation.of(s -> s\n        .multiTerms(aggregation)\n        .aggregations(\"price\", priceAggregation)\n        .aggregations(\"id\", idAggregation)\n    );\n\n    SearchRequest searchRequest = new SearchRequest.Builder()\n        .index(\"order-index\")\n        .aggregations(\"aggs\", aggs)\n        .build();\n    SearchResponse<Void> searchResponse = elasticsearchClient.search(searchRequest, Void.class);\n    Aggregate aggregate = searchResponse.aggregations().get(\"aggs\");\n    Buckets<MultiTermsBucket> buckets = aggregate.multiTerms().buckets();\n    buckets.array().forEach(bu -> {\n        String product = bu.key().get(0).stringValue();\n        String user = bu.key().get(1).stringValue();\n\n        double totalPrice = bu.aggregations().get(\"price\").sum().value();;\n        double totalNum = bu.aggregations().get(\"id\").valueCount().value();\n    });\n}\n```\n\n\n\n","source":"_posts/Elasticsearch Java API Client 8.x使用方式.md","raw":"---\ntitle: Elasticsearch Java API Client 8.x使用方式\ndate: 2023-03-31\n---\n\n### 客户端的变化\n众所周知，Elasticsearch是基于Lucene的，提供了更高层次的封装、分布式方面的扩展，以及REST API来方便使用，我们先来看看java client的变化：\n\n![](/img_convert/2.png)\n从图中可以看成，在8.x版本中，Elasticsearch提供了全新的Java API Client，用来代替之前广为使用的High Level Client，根据官网说法两者并无关联；而更具有灵活性和偏向底层的Low Level Client依旧在迭代，提供给用户更多的选择。\n\n### 快速开始\n话不多说，直接开始，Java API Client依赖于JSON来进行数据格式化，支持Jackson或者JSON-B库，引入相应maven依赖。\n\n``` \n<dependency>\n  <groupId>co.elastic.clients</groupId>\n\t<artifactId>elasticsearch-java</artifactId>\n\t<version>8.6.2</version>\n</dependency>\n\n<dependency>\n  <groupId>com.fasterxml.jackson.core</groupId>\n  <artifactId>jackson-databind</artifactId>\n  <version>2.12.3</version>\n</dependency>\n\n<dependency>\n  <groupId>jakarta.json</groupId>\n  <artifactId>jakarta.json-api</artifactId>\n  <version>2.0.1</version>\n</dependency>\n```\n\n下一步连接Elasticsearch服务端：\n\n```\n@Component\npublic class ElasticsearchConfig {\n\n    @Bean\n    public ElasticsearchClient elasticsearchClient(){\n        BasicCredentialsProvider credentialsProvider = new BasicCredentialsProvider();\n        credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(userName, password));\n\n        RestClient httpClient = RestClient.builder(new HttpHost(hostName, port))\n            .setHttpClientConfigCallback(hc -> hc.setDefaultCredentialsProvider(credentialsProvider))\n            .build();\n\n        ElasticsearchTransport transport = new RestClientTransport(httpClient, new JacksonJsonpMapper());\n        return new ElasticsearchClient(transport);\n    }\n}\n```\n在这里创建的是一个同步的客户端，Java API Client还支持创建异步的客户端：ElasticsearchAsyncClient，返回的是一个标准的 CompletableFuture，按需选择。另外我们还可以看到，创建对象时使用了构造器模式，以及lambda表达式，这两种方式使得代码更加简洁和高效。\n\n### JakartaEE\n补充一点额外内容，JSON-B库的全称是Jakarta JSON Binding，是用于Java对象与JSON消息相互转换的标准绑定层，来源于Jakarta EE。\n而Jakarta EE并不是什么新鲜技术，它的前身是Java EE。之所以改名称，是因为2017年Oracle宣布开源Java EE并将项目移交给Eclipse基金会时，提出来的要求，导致改名事件。现阶段一般都在使用类似于SpringBoot的框架，Java EE的存在感就更弱了，这里就不再扩展了。\n\n### 写入文档\nJava API Client支持写入bean对象，或者直接写入JSON格式数据，其中bean对象会被自动映射为JSON。\n\n```\npublic void index() throws IOException {\n    Order order = new Order(1L, \"test product\", 233L);\n\n    IndexRequest<Order> request = IndexRequest.of(i -> i\n        .index(\"order-index\")\n        .id(String.valueOf(order.getId()))\n        .document(order)\n        .version(1L)\n    );\n\n    IndexResponse indexResponse = elasticsearchClient.index(request);\n    log.info(\"indexResponse:{}\", indexResponse.toString());\n}\n```\n构建一个order对象后，使用其ID作为主键，写入到名为\"order-index\"的索引之中，同时通过version参数指定了数据版本号，来进行并发控制。\n\n### 搜索文档\n以产品名称、价格作为搜索条件，来看看具体的实现：\n\n```\npublic void search() throws IOException {\n    String keyword = \"apple\";\n    Long maxPrice = 100L;\n\n    Query byProduct = MatchQuery.of(m -> m\n        .field(\"product\")\n        .query(keyword)\n    )._toQuery();\n\n    Query byMaxPrice = RangeQuery.of(r -> r\n        .field(\"price\")\n        .gte(JsonData.of(maxPrice))\n    )._toQuery();\n    \n    SortOptions sortOptions = SortOptions.of(s -> s\n        .field(FieldSort.of(f->f\n            .field(\"id\")\n            .order(SortOrder.Desc))\n        )\n    );\n\n    SearchResponse<Order> response = elasticsearchClient.search(s -> s\n        .index(\"order-index\")\n        .query(q -> q\n            .bool(b -> b\n                .must(byProduct)\n                .must(byMaxPrice)\n            )\n        )\n        .from(0)\n        .size(10), \n        Order.class\n    );\n\n    List<Hit<Order>> hits = response.hits().hits();\n    hits.forEach(hit -> {\n        Order order = hit.source();\n        List<FieldValue> sortList = hit.sort();\n    });\n}\n```\n### 深度分页\n在搜索文档的实现中，指定了from和size参数，目的的为了实现分页效果；其中from是游标位置，size是返回数据量大小，类似于MySQL的limit功能。当from过大时Elasticsearch会返回一个错误：\n`Result window is too large, from + size must be less than or equal to: [10000]`\n\n分析这个错误，需要从搜索的实现原理来入手。在客户端请求到达协调节点后，会从各个分片的数据节点获取数据，因为数据分布不均匀的关系，例如在查询第2页的10条数据时，需要从每个节点都获取20条数据，进行排序来避免数据遗漏。\n\n![](/img_convert/3.png)\n\n在之前的版本中，Elasticsearch经常会出现的一个问题是查询1W条以后的数据会非常慢，也就是因为这个原因，解决办法是使用Scroll API，使用快照的思路实现。在最新版中，这种方式已经不再推荐使用，取而待之的是search_after参数。\n\n```\nelasticsearchClient.search(s -> s\n    .index(\"order-index\")\n    .searchAfter(FieldValue.of(1878133432))\n    .sort(sortOptions)\n    .size(20),\n    Order.class\n);\n```\n### 聚合功能\nElasticsearch中聚合常见的应用场景是实现类似于MySQL的sum、count、group by功能，来看一个多参数group by的实现。\n\n```\npublic void aggregation() throws IOException {\n    MultiTermsAggregation aggregation = MultiTermsAggregation.of(s -> s.terms(\n        MultiTermLookup.of(t->t.field(\"product\")),\n        MultiTermLookup.of(t->t.field(\"user\"))\n    ));\n\n    Aggregation priceAggregation = Aggregation.of(s -> s.sum(AggregationBuilders.sum().field(\"price\").build()));\n    Aggregation idAggregation = Aggregation.of(s -> s.valueCount(ValueCountAggregation.of(v -> v.field(\"id\"))));\n\n    Aggregation aggs = Aggregation.of(s -> s\n        .multiTerms(aggregation)\n        .aggregations(\"price\", priceAggregation)\n        .aggregations(\"id\", idAggregation)\n    );\n\n    SearchRequest searchRequest = new SearchRequest.Builder()\n        .index(\"order-index\")\n        .aggregations(\"aggs\", aggs)\n        .build();\n    SearchResponse<Void> searchResponse = elasticsearchClient.search(searchRequest, Void.class);\n    Aggregate aggregate = searchResponse.aggregations().get(\"aggs\");\n    Buckets<MultiTermsBucket> buckets = aggregate.multiTerms().buckets();\n    buckets.array().forEach(bu -> {\n        String product = bu.key().get(0).stringValue();\n        String user = bu.key().get(1).stringValue();\n\n        double totalPrice = bu.aggregations().get(\"price\").sum().value();;\n        double totalNum = bu.aggregations().get(\"id\").valueCount().value();\n    });\n}\n```\n\n\n\n","slug":"Elasticsearch Java API Client 8.x使用方式","published":1,"updated":"2024-01-30T10:02:10.183Z","_id":"cls06n7q50003iocqcbf1fyei","comments":1,"layout":"post","photos":[],"content":"<h3 id=\"客户端的变化\"><a href=\"#客户端的变化\" class=\"headerlink\" title=\"客户端的变化\"></a>客户端的变化</h3><p>众所周知，Elasticsearch是基于Lucene的，提供了更高层次的封装、分布式方面的扩展，以及REST API来方便使用，我们先来看看java client的变化：</p>\n<p><img src=\"/img_convert/2.png\"><br>从图中可以看成，在8.x版本中，Elasticsearch提供了全新的Java API Client，用来代替之前广为使用的High Level Client，根据官网说法两者并无关联；而更具有灵活性和偏向底层的Low Level Client依旧在迭代，提供给用户更多的选择。</p>\n<h3 id=\"快速开始\"><a href=\"#快速开始\" class=\"headerlink\" title=\"快速开始\"></a>快速开始</h3><p>话不多说，直接开始，Java API Client依赖于JSON来进行数据格式化，支持Jackson或者JSON-B库，引入相应maven依赖。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>co.elastic.clients<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>elasticsearch-java<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>8.6.2<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span><br><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>jackson-databind<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>2.12.3<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span><br><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>jakarta.json<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>jakarta.json-api<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>2.0.1<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>下一步连接Elasticsearch服务端：</p>\n<figure class=\"highlight haxe\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs haxe\"><span class=\"hljs-meta\">@Component</span><br><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title class_\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ElasticsearchConfig</span> </span>&#123;<br><br>    <span class=\"hljs-meta\">@Bean</span><br>    <span class=\"hljs-keyword\">public</span> ElasticsearchClient elasticsearchClient()&#123;<br>        BasicCredentialsProvider credentialsProvider = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">BasicCredentialsProvider</span>();<br>        credentialsProvider.setCredentials(AuthScope.ANY, <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">UsernamePasswordCredentials</span>(userName, password));<br><br>        RestClient httpClient = RestClient.builder(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">HttpHost</span>(hostName, port))<br>            .setHttpClientConfigCallback(hc -&gt; hc.setDefaultCredentialsProvider(credentialsProvider))<br>            .build();<br><br>        ElasticsearchTransport transport = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">RestClientTransport</span>(httpClient, <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">JacksonJsonpMapper</span>());<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">ElasticsearchClient</span>(transport);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>在这里创建的是一个同步的客户端，Java API Client还支持创建异步的客户端：ElasticsearchAsyncClient，返回的是一个标准的 CompletableFuture，按需选择。另外我们还可以看到，创建对象时使用了构造器模式，以及lambda表达式，这两种方式使得代码更加简洁和高效。</p>\n<h3 id=\"JakartaEE\"><a href=\"#JakartaEE\" class=\"headerlink\" title=\"JakartaEE\"></a>JakartaEE</h3><p>补充一点额外内容，JSON-B库的全称是Jakarta JSON Binding，是用于Java对象与JSON消息相互转换的标准绑定层，来源于Jakarta EE。<br>而Jakarta EE并不是什么新鲜技术，它的前身是Java EE。之所以改名称，是因为2017年Oracle宣布开源Java EE并将项目移交给Eclipse基金会时，提出来的要求，导致改名事件。现阶段一般都在使用类似于SpringBoot的框架，Java EE的存在感就更弱了，这里就不再扩展了。</p>\n<h3 id=\"写入文档\"><a href=\"#写入文档\" class=\"headerlink\" title=\"写入文档\"></a>写入文档</h3><p>Java API Client支持写入bean对象，或者直接写入JSON格式数据，其中bean对象会被自动映射为JSON。</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-built_in\">public</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-keyword\">index</span>() throws IOException &#123;<br>    <span class=\"hljs-keyword\">Order</span> <span class=\"hljs-keyword\">order</span> = <span class=\"hljs-built_in\">new</span> <span class=\"hljs-keyword\">Order</span>(<span class=\"hljs-number\">1</span>L, &quot;test product&quot;, <span class=\"hljs-number\">233</span>L);<br><br>    IndexRequest&lt;<span class=\"hljs-keyword\">Order</span>&gt; request = IndexRequest.<span class=\"hljs-keyword\">of</span>(i -&gt; i<br>        .<span class=\"hljs-keyword\">index</span>(&quot;order-index&quot;)<br>        .id(String.valueOf(<span class=\"hljs-keyword\">order</span>.getId()))<br>        .document(<span class=\"hljs-keyword\">order</span>)<br>        .version(<span class=\"hljs-number\">1</span>L)<br>    );<br><br>    IndexResponse indexResponse = elasticsearchClient.<span class=\"hljs-keyword\">index</span>(request);<br>    <span class=\"hljs-keyword\">log</span>.<span class=\"hljs-keyword\">info</span>(&quot;indexResponse:&#123;&#125;&quot;, indexResponse.toString());<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>构建一个order对象后，使用其ID作为主键，写入到名为”order-index”的索引之中，同时通过version参数指定了数据版本号，来进行并发控制。</p>\n<h3 id=\"搜索文档\"><a href=\"#搜索文档\" class=\"headerlink\" title=\"搜索文档\"></a>搜索文档</h3><p>以产品名称、价格作为搜索条件，来看看具体的实现：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-built_in\">public</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-keyword\">search</span>() throws IOException &#123;<br>    String keyword = &quot;apple&quot;;<br>    Long maxPrice = <span class=\"hljs-number\">100</span>L;<br><br>    Query byProduct = MatchQuery.<span class=\"hljs-keyword\">of</span>(m -&gt; m<br>        .field(&quot;product&quot;)<br>        .query(keyword)<br>    )._toQuery();<br><br>    Query byMaxPrice = RangeQuery.<span class=\"hljs-keyword\">of</span>(r -&gt; r<br>        .field(&quot;price&quot;)<br>        .gte(JsonData.<span class=\"hljs-keyword\">of</span>(maxPrice))<br>    )._toQuery();<br>    <br>    SortOptions sortOptions = SortOptions.<span class=\"hljs-keyword\">of</span>(s -&gt; s<br>        .field(FieldSort.<span class=\"hljs-keyword\">of</span>(f-&gt;f<br>            .field(&quot;id&quot;)<br>            .<span class=\"hljs-keyword\">order</span>(SortOrder.<span class=\"hljs-keyword\">Desc</span>))<br>        )<br>    );<br><br>    SearchResponse&lt;<span class=\"hljs-keyword\">Order</span>&gt; response = elasticsearchClient.<span class=\"hljs-keyword\">search</span>(s -&gt; s<br>        .<span class=\"hljs-keyword\">index</span>(&quot;order-index&quot;)<br>        .query(q -&gt; q<br>            .bool(b -&gt; b<br>                .must(byProduct)<br>                .must(byMaxPrice)<br>            )<br>        )<br>        .<span class=\"hljs-keyword\">from</span>(<span class=\"hljs-number\">0</span>)<br>        .size(<span class=\"hljs-number\">10</span>), <br>        <span class=\"hljs-keyword\">Order</span>.<span class=\"hljs-keyword\">class</span><br>    );<br><br>    List&lt;Hit&lt;<span class=\"hljs-keyword\">Order</span>&gt;&gt; hits = response.hits().hits();<br>    hits.<span class=\"hljs-keyword\">forEach</span>(hit -&gt; &#123;<br>        <span class=\"hljs-keyword\">Order</span> <span class=\"hljs-keyword\">order</span> = hit.source();<br>        List&lt;FieldValue&gt; sortList = hit.sort();<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"深度分页\"><a href=\"#深度分页\" class=\"headerlink\" title=\"深度分页\"></a>深度分页</h3><p>在搜索文档的实现中，指定了from和size参数，目的的为了实现分页效果；其中from是游标位置，size是返回数据量大小，类似于MySQL的limit功能。当from过大时Elasticsearch会返回一个错误：<br><code>Result window is too large, from + size must be less than or equal to: [10000]</code></p>\n<p>分析这个错误，需要从搜索的实现原理来入手。在客户端请求到达协调节点后，会从各个分片的数据节点获取数据，因为数据分布不均匀的关系，例如在查询第2页的10条数据时，需要从每个节点都获取20条数据，进行排序来避免数据遗漏。</p>\n<p><img src=\"/img_convert/3.png\"></p>\n<p>在之前的版本中，Elasticsearch经常会出现的一个问题是查询1W条以后的数据会非常慢，也就是因为这个原因，解决办法是使用Scroll API，使用快照的思路实现。在最新版中，这种方式已经不再推荐使用，取而待之的是search_after参数。</p>\n<figure class=\"highlight less\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs less\"><span class=\"hljs-selector-tag\">elasticsearchClient</span><span class=\"hljs-selector-class\">.search</span>(s -&gt; s<br>    .<span class=\"hljs-built_in\">index</span>(<span class=\"hljs-string\">&quot;order-index&quot;</span>)<br>    .<span class=\"hljs-built_in\">searchAfter</span>(FieldValue.<span class=\"hljs-built_in\">of</span>(<span class=\"hljs-number\">1878133432</span>))<br>    .<span class=\"hljs-built_in\">sort</span>(sortOptions)<br>    .<span class=\"hljs-built_in\">size</span>(<span class=\"hljs-number\">20</span>),<br>    Order.class<br>);<br></code></pre></td></tr></table></figure>\n<h3 id=\"聚合功能\"><a href=\"#聚合功能\" class=\"headerlink\" title=\"聚合功能\"></a>聚合功能</h3><p>Elasticsearch中聚合常见的应用场景是实现类似于MySQL的sum、count、group by功能，来看一个多参数group by的实现。</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-built_in\">public</span> <span class=\"hljs-type\">void</span> aggregation() throws IOException &#123;<br>    MultiTermsAggregation aggregation = MultiTermsAggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s.terms(<br>        MultiTermLookup.<span class=\"hljs-keyword\">of</span>(t-&gt;t.field(&quot;product&quot;)),<br>        MultiTermLookup.<span class=\"hljs-keyword\">of</span>(t-&gt;t.field(&quot;user&quot;))<br>    ));<br><br>    Aggregation priceAggregation = Aggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s.sum(AggregationBuilders.sum().field(&quot;price&quot;).build()));<br>    Aggregation idAggregation = Aggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s.valueCount(ValueCountAggregation.<span class=\"hljs-keyword\">of</span>(v -&gt; v.field(&quot;id&quot;))));<br><br>    Aggregation aggs = Aggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s<br>        .multiTerms(aggregation)<br>        .aggregations(&quot;price&quot;, priceAggregation)<br>        .aggregations(&quot;id&quot;, idAggregation)<br>    );<br><br>    SearchRequest searchRequest = <span class=\"hljs-built_in\">new</span> SearchRequest.Builder()<br>        .<span class=\"hljs-keyword\">index</span>(&quot;order-index&quot;)<br>        .aggregations(&quot;aggs&quot;, aggs)<br>        .build();<br>    SearchResponse&lt;<span class=\"hljs-type\">Void</span>&gt; searchResponse = elasticsearchClient.<span class=\"hljs-keyword\">search</span>(searchRequest, <span class=\"hljs-type\">Void</span>.<span class=\"hljs-keyword\">class</span>);<br>    <span class=\"hljs-keyword\">Aggregate</span> <span class=\"hljs-keyword\">aggregate</span> = searchResponse.aggregations().<span class=\"hljs-keyword\">get</span>(&quot;aggs&quot;);<br>    Buckets&lt;MultiTermsBucket&gt; buckets = <span class=\"hljs-keyword\">aggregate</span>.multiTerms().buckets();<br>    buckets.<span class=\"hljs-keyword\">array</span>().<span class=\"hljs-keyword\">forEach</span>(bu -&gt; &#123;<br>        String product = bu.key().<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-number\">0</span>).stringValue();<br>        String <span class=\"hljs-keyword\">user</span> = bu.key().<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-number\">1</span>).stringValue();<br><br>        <span class=\"hljs-type\">double</span> totalPrice = bu.aggregations().<span class=\"hljs-keyword\">get</span>(&quot;price&quot;).sum().<span class=\"hljs-keyword\">value</span>();;<br>        <span class=\"hljs-type\">double</span> totalNum = bu.aggregations().<span class=\"hljs-keyword\">get</span>(&quot;id&quot;).valueCount().<span class=\"hljs-keyword\">value</span>();<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n\n","excerpt":"","more":"<h3 id=\"客户端的变化\"><a href=\"#客户端的变化\" class=\"headerlink\" title=\"客户端的变化\"></a>客户端的变化</h3><p>众所周知，Elasticsearch是基于Lucene的，提供了更高层次的封装、分布式方面的扩展，以及REST API来方便使用，我们先来看看java client的变化：</p>\n<p><img src=\"/img_convert/2.png\"><br>从图中可以看成，在8.x版本中，Elasticsearch提供了全新的Java API Client，用来代替之前广为使用的High Level Client，根据官网说法两者并无关联；而更具有灵活性和偏向底层的Low Level Client依旧在迭代，提供给用户更多的选择。</p>\n<h3 id=\"快速开始\"><a href=\"#快速开始\" class=\"headerlink\" title=\"快速开始\"></a>快速开始</h3><p>话不多说，直接开始，Java API Client依赖于JSON来进行数据格式化，支持Jackson或者JSON-B库，引入相应maven依赖。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>co.elastic.clients<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>elasticsearch-java<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>8.6.2<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span><br><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>jackson-databind<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>2.12.3<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span><br><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>jakarta.json<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>jakarta.json-api<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>2.0.1<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>下一步连接Elasticsearch服务端：</p>\n<figure class=\"highlight haxe\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs haxe\"><span class=\"hljs-meta\">@Component</span><br><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title class_\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ElasticsearchConfig</span> </span>&#123;<br><br>    <span class=\"hljs-meta\">@Bean</span><br>    <span class=\"hljs-keyword\">public</span> ElasticsearchClient elasticsearchClient()&#123;<br>        BasicCredentialsProvider credentialsProvider = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">BasicCredentialsProvider</span>();<br>        credentialsProvider.setCredentials(AuthScope.ANY, <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">UsernamePasswordCredentials</span>(userName, password));<br><br>        RestClient httpClient = RestClient.builder(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">HttpHost</span>(hostName, port))<br>            .setHttpClientConfigCallback(hc -&gt; hc.setDefaultCredentialsProvider(credentialsProvider))<br>            .build();<br><br>        ElasticsearchTransport transport = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">RestClientTransport</span>(httpClient, <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">JacksonJsonpMapper</span>());<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">ElasticsearchClient</span>(transport);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>在这里创建的是一个同步的客户端，Java API Client还支持创建异步的客户端：ElasticsearchAsyncClient，返回的是一个标准的 CompletableFuture，按需选择。另外我们还可以看到，创建对象时使用了构造器模式，以及lambda表达式，这两种方式使得代码更加简洁和高效。</p>\n<h3 id=\"JakartaEE\"><a href=\"#JakartaEE\" class=\"headerlink\" title=\"JakartaEE\"></a>JakartaEE</h3><p>补充一点额外内容，JSON-B库的全称是Jakarta JSON Binding，是用于Java对象与JSON消息相互转换的标准绑定层，来源于Jakarta EE。<br>而Jakarta EE并不是什么新鲜技术，它的前身是Java EE。之所以改名称，是因为2017年Oracle宣布开源Java EE并将项目移交给Eclipse基金会时，提出来的要求，导致改名事件。现阶段一般都在使用类似于SpringBoot的框架，Java EE的存在感就更弱了，这里就不再扩展了。</p>\n<h3 id=\"写入文档\"><a href=\"#写入文档\" class=\"headerlink\" title=\"写入文档\"></a>写入文档</h3><p>Java API Client支持写入bean对象，或者直接写入JSON格式数据，其中bean对象会被自动映射为JSON。</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-built_in\">public</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-keyword\">index</span>() throws IOException &#123;<br>    <span class=\"hljs-keyword\">Order</span> <span class=\"hljs-keyword\">order</span> = <span class=\"hljs-built_in\">new</span> <span class=\"hljs-keyword\">Order</span>(<span class=\"hljs-number\">1</span>L, &quot;test product&quot;, <span class=\"hljs-number\">233</span>L);<br><br>    IndexRequest&lt;<span class=\"hljs-keyword\">Order</span>&gt; request = IndexRequest.<span class=\"hljs-keyword\">of</span>(i -&gt; i<br>        .<span class=\"hljs-keyword\">index</span>(&quot;order-index&quot;)<br>        .id(String.valueOf(<span class=\"hljs-keyword\">order</span>.getId()))<br>        .document(<span class=\"hljs-keyword\">order</span>)<br>        .version(<span class=\"hljs-number\">1</span>L)<br>    );<br><br>    IndexResponse indexResponse = elasticsearchClient.<span class=\"hljs-keyword\">index</span>(request);<br>    <span class=\"hljs-keyword\">log</span>.<span class=\"hljs-keyword\">info</span>(&quot;indexResponse:&#123;&#125;&quot;, indexResponse.toString());<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>构建一个order对象后，使用其ID作为主键，写入到名为”order-index”的索引之中，同时通过version参数指定了数据版本号，来进行并发控制。</p>\n<h3 id=\"搜索文档\"><a href=\"#搜索文档\" class=\"headerlink\" title=\"搜索文档\"></a>搜索文档</h3><p>以产品名称、价格作为搜索条件，来看看具体的实现：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-built_in\">public</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-keyword\">search</span>() throws IOException &#123;<br>    String keyword = &quot;apple&quot;;<br>    Long maxPrice = <span class=\"hljs-number\">100</span>L;<br><br>    Query byProduct = MatchQuery.<span class=\"hljs-keyword\">of</span>(m -&gt; m<br>        .field(&quot;product&quot;)<br>        .query(keyword)<br>    )._toQuery();<br><br>    Query byMaxPrice = RangeQuery.<span class=\"hljs-keyword\">of</span>(r -&gt; r<br>        .field(&quot;price&quot;)<br>        .gte(JsonData.<span class=\"hljs-keyword\">of</span>(maxPrice))<br>    )._toQuery();<br>    <br>    SortOptions sortOptions = SortOptions.<span class=\"hljs-keyword\">of</span>(s -&gt; s<br>        .field(FieldSort.<span class=\"hljs-keyword\">of</span>(f-&gt;f<br>            .field(&quot;id&quot;)<br>            .<span class=\"hljs-keyword\">order</span>(SortOrder.<span class=\"hljs-keyword\">Desc</span>))<br>        )<br>    );<br><br>    SearchResponse&lt;<span class=\"hljs-keyword\">Order</span>&gt; response = elasticsearchClient.<span class=\"hljs-keyword\">search</span>(s -&gt; s<br>        .<span class=\"hljs-keyword\">index</span>(&quot;order-index&quot;)<br>        .query(q -&gt; q<br>            .bool(b -&gt; b<br>                .must(byProduct)<br>                .must(byMaxPrice)<br>            )<br>        )<br>        .<span class=\"hljs-keyword\">from</span>(<span class=\"hljs-number\">0</span>)<br>        .size(<span class=\"hljs-number\">10</span>), <br>        <span class=\"hljs-keyword\">Order</span>.<span class=\"hljs-keyword\">class</span><br>    );<br><br>    List&lt;Hit&lt;<span class=\"hljs-keyword\">Order</span>&gt;&gt; hits = response.hits().hits();<br>    hits.<span class=\"hljs-keyword\">forEach</span>(hit -&gt; &#123;<br>        <span class=\"hljs-keyword\">Order</span> <span class=\"hljs-keyword\">order</span> = hit.source();<br>        List&lt;FieldValue&gt; sortList = hit.sort();<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"深度分页\"><a href=\"#深度分页\" class=\"headerlink\" title=\"深度分页\"></a>深度分页</h3><p>在搜索文档的实现中，指定了from和size参数，目的的为了实现分页效果；其中from是游标位置，size是返回数据量大小，类似于MySQL的limit功能。当from过大时Elasticsearch会返回一个错误：<br><code>Result window is too large, from + size must be less than or equal to: [10000]</code></p>\n<p>分析这个错误，需要从搜索的实现原理来入手。在客户端请求到达协调节点后，会从各个分片的数据节点获取数据，因为数据分布不均匀的关系，例如在查询第2页的10条数据时，需要从每个节点都获取20条数据，进行排序来避免数据遗漏。</p>\n<p><img src=\"/img_convert/3.png\"></p>\n<p>在之前的版本中，Elasticsearch经常会出现的一个问题是查询1W条以后的数据会非常慢，也就是因为这个原因，解决办法是使用Scroll API，使用快照的思路实现。在最新版中，这种方式已经不再推荐使用，取而待之的是search_after参数。</p>\n<figure class=\"highlight less\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs less\"><span class=\"hljs-selector-tag\">elasticsearchClient</span><span class=\"hljs-selector-class\">.search</span>(s -&gt; s<br>    .<span class=\"hljs-built_in\">index</span>(<span class=\"hljs-string\">&quot;order-index&quot;</span>)<br>    .<span class=\"hljs-built_in\">searchAfter</span>(FieldValue.<span class=\"hljs-built_in\">of</span>(<span class=\"hljs-number\">1878133432</span>))<br>    .<span class=\"hljs-built_in\">sort</span>(sortOptions)<br>    .<span class=\"hljs-built_in\">size</span>(<span class=\"hljs-number\">20</span>),<br>    Order.class<br>);<br></code></pre></td></tr></table></figure>\n<h3 id=\"聚合功能\"><a href=\"#聚合功能\" class=\"headerlink\" title=\"聚合功能\"></a>聚合功能</h3><p>Elasticsearch中聚合常见的应用场景是实现类似于MySQL的sum、count、group by功能，来看一个多参数group by的实现。</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-built_in\">public</span> <span class=\"hljs-type\">void</span> aggregation() throws IOException &#123;<br>    MultiTermsAggregation aggregation = MultiTermsAggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s.terms(<br>        MultiTermLookup.<span class=\"hljs-keyword\">of</span>(t-&gt;t.field(&quot;product&quot;)),<br>        MultiTermLookup.<span class=\"hljs-keyword\">of</span>(t-&gt;t.field(&quot;user&quot;))<br>    ));<br><br>    Aggregation priceAggregation = Aggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s.sum(AggregationBuilders.sum().field(&quot;price&quot;).build()));<br>    Aggregation idAggregation = Aggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s.valueCount(ValueCountAggregation.<span class=\"hljs-keyword\">of</span>(v -&gt; v.field(&quot;id&quot;))));<br><br>    Aggregation aggs = Aggregation.<span class=\"hljs-keyword\">of</span>(s -&gt; s<br>        .multiTerms(aggregation)<br>        .aggregations(&quot;price&quot;, priceAggregation)<br>        .aggregations(&quot;id&quot;, idAggregation)<br>    );<br><br>    SearchRequest searchRequest = <span class=\"hljs-built_in\">new</span> SearchRequest.Builder()<br>        .<span class=\"hljs-keyword\">index</span>(&quot;order-index&quot;)<br>        .aggregations(&quot;aggs&quot;, aggs)<br>        .build();<br>    SearchResponse&lt;<span class=\"hljs-type\">Void</span>&gt; searchResponse = elasticsearchClient.<span class=\"hljs-keyword\">search</span>(searchRequest, <span class=\"hljs-type\">Void</span>.<span class=\"hljs-keyword\">class</span>);<br>    <span class=\"hljs-keyword\">Aggregate</span> <span class=\"hljs-keyword\">aggregate</span> = searchResponse.aggregations().<span class=\"hljs-keyword\">get</span>(&quot;aggs&quot;);<br>    Buckets&lt;MultiTermsBucket&gt; buckets = <span class=\"hljs-keyword\">aggregate</span>.multiTerms().buckets();<br>    buckets.<span class=\"hljs-keyword\">array</span>().<span class=\"hljs-keyword\">forEach</span>(bu -&gt; &#123;<br>        String product = bu.key().<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-number\">0</span>).stringValue();<br>        String <span class=\"hljs-keyword\">user</span> = bu.key().<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-number\">1</span>).stringValue();<br><br>        <span class=\"hljs-type\">double</span> totalPrice = bu.aggregations().<span class=\"hljs-keyword\">get</span>(&quot;price&quot;).sum().<span class=\"hljs-keyword\">value</span>();;<br>        <span class=\"hljs-type\">double</span> totalNum = bu.aggregations().<span class=\"hljs-keyword\">get</span>(&quot;id&quot;).valueCount().<span class=\"hljs-keyword\">value</span>();<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n\n"},{"title":"Elasticsearch写入速度优化[翻译版]","date":"2023-05-15T16:00:00.000Z","_content":"\n在上一篇文章中翻译了索引写入，接下来看看索引的查询有哪些优化手段。\n\n原文链接：[https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html)\n\n### 1.增加文件系统缓存\n\nElasticsearch严重依赖文件系统缓存来加快查询速度。一般来说，至少需要保留一半的可用内存给文件系统，以便Elasticsearch在物理内存中保留索引热点数据。\n\n### 2.使用更快的硬件\n\n如果搜索遇到了I/O瓶颈，考虑增加文件系统缓存或者使用更快的存储设备。每次查询涉及随机读和顺序读的混合操作，跨越多个文件，而且每个分片上可能有多个搜索的并发请求，因SSD磁盘比普通硬盘性能更佳。\n\n本地磁盘比网络云盘更加高效，因为配置更加简单而且可以避免频繁的网络通信。经过优化配置，网络云盘有时也能达到所期望的性能。通过真实负载下的基准测试，来确定优化参数是否生效。如果不能达到你所期望的效果，可以联系你的存储供应商来解决问题。\n\n如果你的搜索遇到的是CPU瓶颈，可以考虑增加速度更快的CPU。\n\n### 3.文档结构化\n\n文档结构越简单搜索成本越低。\n\n在实际使用中，应当避免文档关联。嵌套结构`nested`可能导致查询速度慢上好几倍，父子文档`parent-child`关联的查询速度可能要慢几百倍。如果可以使用非规范化文档来规避关联关系，查询速度可以得到显著的提升。\n\n### 4.只搜索必要的字段\n\n当`query_string` 或者 `multi_match` 包含的字段越多时，搜索速度就会越慢。改善多字段查询速度的通用技巧，是在写入文档时将多个字段的内容复制到一个字段中，在搜索搜索时只需要查询这个字段。使用文档结构的`copy-to` 指令就可以自动完成，无需修改源文档。下面的例子关于如何改善电影索引的搜索性能，把需要查询的电影名称、情节都放到`name_and_plot`字段中。\n\n```SQL\nPUT movies\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name_and_plot\": {\n        \"type\": \"text\"\n      },\n      \"name\": {\n        \"type\": \"text\",\n        \"copy_to\": \"name_and_plot\"\n      },\n      \"plot\": {\n        \"type\": \"text\",\n        \"copy_to\": \"name_and_plot\"\n      }\n    }\n  }\n}\n```\n\n\n\n### 5.预索引数据\n\n在搜索和数据存储优化方面需要取得一个平衡。比如说，如果你所有的文档都有一个 `price`字段，大多数查询使用了固定范围内的`range` 聚合查询，你可以将 `terms`聚合查询的结果存储到新的索引中，来加快查询效率。\n\n例如，文档如下所示：\n\n```SQL\nPUT index/_doc/1\n{\n  \"designation\": \"spoon\",\n  \"price\": 13\n}\n```\n\n搜索请求：\n\n```SQL\nGET index/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"ranges\": [\n          { \"to\": 10 },\n          { \"from\": 10, \"to\": 100 },\n          { \"from\": 100 }\n        ]\n      }\n    }\n  }\n}\n```\n\n文档在写入时可以填充到`price_range`字段中，使用`keyword`字段类型：\n\n```SQL\nPUT index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"price_range\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n\nPUT index/_doc/1\n{\n  \"designation\": \"spoon\",\n  \"price\": 13,\n  \"price_range\": \"10-100\"\n}\n```\n\n然后在搜索时，可以对新的字段进行聚合来代替对`price`字段进行聚合：\n\n```SQL\nGET index/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"terms\": {\n        \"field\": \"price_range\"\n      }\n    }\n  }\n}\n```\n\n### 6.唯一标记使用 keword字段类型\n\n不是所有的数字都应该使用 `numeric` 字段类型。Elasticsearch对数字类型进行了优化，例如`integer` 或者 `long`，在`range`查询场景下。然而，`keyword`类型在`term` 和 `term-level`查询中表现更好。\n\n唯一标记，例如ISBN或者产品id，很少使用范围查询，却经常使用`term-level`查询。\n\n以下情况可以考虑将数字类型的唯一标记存储为keyword类型：\n\n- 唯一标记不会用于范围查询；\n- 更看重搜索性能。keyword字段类型上的term查询比数字类型要快许多；\n\n如果你不确定使用哪种方式，可以使用`multi-field`来同存储keywrod和数字类型。\n\n### 7.避免使用脚本\n\n如果可能，避免使用基于脚本的排序、聚合，以及用脚本计算评分。\n\n### 8.搜索近似时间\n\n使用`now`条件来搜索时间字段通常没有缓存，因为匹配的条件一直在变化。然而使用近似时间在条件查询中经常上适用的，而且可以更好的利用查询缓存。\n\n例如下面的查询：\n\n\n```SQL\nPUT index/_doc/1\n{\n  \"my_date\": \"2016-05-11T16:30:55.328Z\"\n}\n\nGET index/_search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"range\": {\n          \"my_date\": {\n            \"gte\": \"now-1h\",\n            \"lte\": \"now\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n可以进行如下替换：\n\n```SQL\nGET index/_search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"range\": {\n          \"my_date\": {\n            \"gte\": \"now-1h/m\",\n            \"lte\": \"now/m\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n在这个例子中我们使用了分钟近似值，如果当前时间是`16:31:29` ，`my_date`字段的范围查询将返回所有从`15:31:00`到`16:31:59`时间段内的数据。如果同一时间好几个用户的查询条件包含这个范围，查询缓存能够加快查询速度。近似查询的范围越长，缓存的效果越明显，但是需要注意过度的近似值可能会破坏用户体验。\n\n### 9.强制合并只读索引\n\n强制合并为一个段对只读索引来说是有益的。在时间线索引中比较常见的场景：只有当前时间的索引会新增数据，历史索引是只读的。分片被强制合并为一个段，可以让查询更加简单和有效。\n\n### 10.预热全局序号\n\n全局序号是用来优化聚合的一种数据结构。他们作为字段缓存的一部分会在`JVM`中延迟计算和存储。作为分桶查询中被频繁使用的字段，你可以让`Elasticsearch`在请求到达前实例化和缓存。这个操作应该谨慎使用，因为他会占用更多内存使得`refresh`变长。这个选项可以在已经创建的索引上动态设置，通过修改`eager global ordinals` 参数：\n\n```SQL\nPUT index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"foo\": {\n        \"type\": \"keyword\",\n        \"eager_global_ordinals\": true\n      }\n    }\n  }\n}\n```\n\n### 11.预热文件系统缓存\n\n如果运行`Elasticsearch`的机器重启了，文件系统缓存会被清空，因此操作系统需要花费一些时间来加载热点索引缓存数据到内存，以便加快查询速度。你可以明确的告诉操作系统哪些文件需要提前加载到缓存中，通过`index.store.preload` 参数来进行指定。\n\n### 12.使用索引排序来加快连接速度\n\n索引排序在加快连接速度方面很有效，代价是文档写入会变慢。\n\n### 13.使用preference来优化缓存使用\n\n有多种缓存可以用来加快查询速度，诸如文件系统缓存、请求缓存、查询缓存。这些缓存大多是在节点层面的，意味着如果你连续发起2次相同的请求，有一个或者多个副本而且所有了负载策略，根据默认的路由算法，2次请求会分配到不同的分片节点，节点层面的缓存无法有效利用。\n\n由于搜索程序的用户会一个接着一个的发起类似的查询请求，比如说为了分析索引索引的子集，使用偏好值来标记当前用户或者请求能够帮助优化缓存的使用。\n\n### 14.副本或许可以提升吞吐量\n\n除了弹性扩展，副本还能提升吞吐量。例如你有一个单一分片索引和三个节点，你需要将副本数量设置为2，这样总共3份副本让每个节点都能充分利用。\n\n现在假设你有2个分片索引和2个节点。第一种情况，副本数量设置为0，意味着每个节点有一个分片。第二种情况副本数量设置为1，意味着每个节点有2个分片。哪种情况能够有更好的查询性能呢？通常情况下，节点的分片数量越少的方案更优。因为能够给每个分片更多的文件系统缓存，而文件系统缓存可能是`Elasticsearch`最有效的优化策略。与此同时，需要注意物副本的方案在单节点失败情况下的风险，需要权衡吞吐量和可用性。\n\n因此分片数量设置为多少比较合适？如果你的集群有`num_nodes`个节点，总共有`num_primaries`个主分片，你期望同时可以应对最多`max_failures`个节点失败的状况，正确的副本数量结算方式为：`max(max_failures, ceil(num_nodes / num_primaries) - 1)`\n\n### 15.使用Search Profiler优化查询\n\n`Profile API`提供了查询和聚合在每一步处理耗时的详细信息。\n\n在`Kibana`上使用` Search Profiler`可以清楚直观的看到分析结果，以及如何优化查询和减轻负载压力。\n\n因为`Profile API`在查询上增加了大量开销，返回的结果适用于了解各个查询阶段的相对耗时。不代表实际的处理时间。\n\n### 16.使用index_phrases加快短语查询\n\n`text`字段有一个`index_phrases`选项来索引2-shingles，能够被短语查询自动应用，在没有`slop`的情况下。如果你的案例中有大量的短语查询，可以显著的加快查询速度。\n\n### 17.使用index_prefixes来加快前缀查询\n\ntext字段有一个index_prefixes选项来索引前缀，在前缀查询条件中能够被自动的应用。如果你的案例中有大量的前缀查询，可以显著的加快查询速度。\n\n### 18.使用constant_keyword来加快过滤速度\n\n有一个通用规则，过滤查询的耗时基本上是匹配文档数量的一个函数。假设你有一个包含骑行的索引。有大量的自行车数据，许多查询上基于过滤条件：`cycle_type: bicycle`。这个常见的过滤会很耗时，因为匹配到了大量的文档。有一个简单的方法来避免运行此类查询，把自行车移动他自己的索引中，查询这个索引来代替过滤查询。\n\n不幸的是这样会使客户端的逻辑变得复杂，而这正是`constant_keyword`发挥作用的地方。通过在bicycles索引上将`cycle_type`字段类型设置为`constant_keyword`，值设置为`bicycle`，客户端依然可以运行和之前单片索引上一样的查询语句，Elasticsearch会在bicycles索引上忽略条件为`cycle_type`并且值为`bicycle`的过滤条件，返回正确的结果。\n\n索引结构如下所示：\n\n```SQL\nPUT bicycles\n{\n  \"mappings\": {\n    \"properties\": {\n      \"cycle_type\": {\n        \"type\": \"constant_keyword\",\n        \"value\": \"bicycle\"\n      },\n      \"name\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPUT other_cycles\n{\n  \"mappings\": {\n    \"properties\": {\n      \"cycle_type\": {\n        \"type\": \"keyword\"\n      },\n      \"name\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n```\n\n我们将索引一分为二，一个仅包含自行车，一辆一个包含其他车辆：独轮车、三轮车等等。在查询时，我们需要查询所有的索引，但是不需要修改查询语句。\n\n```SQL\nGET bicycles,other_cycles/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n          \"description\": \"dutch\"\n        }\n      },\n      \"filter\": {\n        \"term\": {\n          \"cycle_type\": \"bicycle\"\n        }\n      }\n    }\n  }\n}\n```\n\n在`bicycles`索引中，Elasticsearch会忽略`cycle_type`过滤条件将查询请求重写如下：\n\n```SQL\nGET bicycles,other_cycles/_search\n{\n  \"query\": {\n    \"match\": {\n      \"description\": \"dutch\"\n    }\n  }\n}\n```\n\n在`other_cycles`索引，Elasticsearch会快速的发现在`cycle_type`中不包含`bicycle`，返回无匹配结果。\n\n这是一个非常有效的手段，将通用的查询字符内容放在专属索引里面。这个方法也适用于多字段，例如你需要追踪每个骑行工具的颜色，你的`bicycles`索引中大部分都是黑色的自行车，你可以将他分为`bicycles-black`和`bicycles-other-colors`索引。\n\n`constant_keyword`不属于严格意义上的索引优化：更像是将客户端的逻辑查询路由到指定的索引上。但是`constant_keyword`使其透明化，将查询和索引结果解耦来优化性能。","source":"_posts/Elasticsearch搜索优化[翻译版].md","raw":"---\ntitle: Elasticsearch写入速度优化[翻译版]\ndate: 2023-05-16\n---\n\n在上一篇文章中翻译了索引写入，接下来看看索引的查询有哪些优化手段。\n\n原文链接：[https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html)\n\n### 1.增加文件系统缓存\n\nElasticsearch严重依赖文件系统缓存来加快查询速度。一般来说，至少需要保留一半的可用内存给文件系统，以便Elasticsearch在物理内存中保留索引热点数据。\n\n### 2.使用更快的硬件\n\n如果搜索遇到了I/O瓶颈，考虑增加文件系统缓存或者使用更快的存储设备。每次查询涉及随机读和顺序读的混合操作，跨越多个文件，而且每个分片上可能有多个搜索的并发请求，因SSD磁盘比普通硬盘性能更佳。\n\n本地磁盘比网络云盘更加高效，因为配置更加简单而且可以避免频繁的网络通信。经过优化配置，网络云盘有时也能达到所期望的性能。通过真实负载下的基准测试，来确定优化参数是否生效。如果不能达到你所期望的效果，可以联系你的存储供应商来解决问题。\n\n如果你的搜索遇到的是CPU瓶颈，可以考虑增加速度更快的CPU。\n\n### 3.文档结构化\n\n文档结构越简单搜索成本越低。\n\n在实际使用中，应当避免文档关联。嵌套结构`nested`可能导致查询速度慢上好几倍，父子文档`parent-child`关联的查询速度可能要慢几百倍。如果可以使用非规范化文档来规避关联关系，查询速度可以得到显著的提升。\n\n### 4.只搜索必要的字段\n\n当`query_string` 或者 `multi_match` 包含的字段越多时，搜索速度就会越慢。改善多字段查询速度的通用技巧，是在写入文档时将多个字段的内容复制到一个字段中，在搜索搜索时只需要查询这个字段。使用文档结构的`copy-to` 指令就可以自动完成，无需修改源文档。下面的例子关于如何改善电影索引的搜索性能，把需要查询的电影名称、情节都放到`name_and_plot`字段中。\n\n```SQL\nPUT movies\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name_and_plot\": {\n        \"type\": \"text\"\n      },\n      \"name\": {\n        \"type\": \"text\",\n        \"copy_to\": \"name_and_plot\"\n      },\n      \"plot\": {\n        \"type\": \"text\",\n        \"copy_to\": \"name_and_plot\"\n      }\n    }\n  }\n}\n```\n\n\n\n### 5.预索引数据\n\n在搜索和数据存储优化方面需要取得一个平衡。比如说，如果你所有的文档都有一个 `price`字段，大多数查询使用了固定范围内的`range` 聚合查询，你可以将 `terms`聚合查询的结果存储到新的索引中，来加快查询效率。\n\n例如，文档如下所示：\n\n```SQL\nPUT index/_doc/1\n{\n  \"designation\": \"spoon\",\n  \"price\": 13\n}\n```\n\n搜索请求：\n\n```SQL\nGET index/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"ranges\": [\n          { \"to\": 10 },\n          { \"from\": 10, \"to\": 100 },\n          { \"from\": 100 }\n        ]\n      }\n    }\n  }\n}\n```\n\n文档在写入时可以填充到`price_range`字段中，使用`keyword`字段类型：\n\n```SQL\nPUT index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"price_range\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n\nPUT index/_doc/1\n{\n  \"designation\": \"spoon\",\n  \"price\": 13,\n  \"price_range\": \"10-100\"\n}\n```\n\n然后在搜索时，可以对新的字段进行聚合来代替对`price`字段进行聚合：\n\n```SQL\nGET index/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"terms\": {\n        \"field\": \"price_range\"\n      }\n    }\n  }\n}\n```\n\n### 6.唯一标记使用 keword字段类型\n\n不是所有的数字都应该使用 `numeric` 字段类型。Elasticsearch对数字类型进行了优化，例如`integer` 或者 `long`，在`range`查询场景下。然而，`keyword`类型在`term` 和 `term-level`查询中表现更好。\n\n唯一标记，例如ISBN或者产品id，很少使用范围查询，却经常使用`term-level`查询。\n\n以下情况可以考虑将数字类型的唯一标记存储为keyword类型：\n\n- 唯一标记不会用于范围查询；\n- 更看重搜索性能。keyword字段类型上的term查询比数字类型要快许多；\n\n如果你不确定使用哪种方式，可以使用`multi-field`来同存储keywrod和数字类型。\n\n### 7.避免使用脚本\n\n如果可能，避免使用基于脚本的排序、聚合，以及用脚本计算评分。\n\n### 8.搜索近似时间\n\n使用`now`条件来搜索时间字段通常没有缓存，因为匹配的条件一直在变化。然而使用近似时间在条件查询中经常上适用的，而且可以更好的利用查询缓存。\n\n例如下面的查询：\n\n\n```SQL\nPUT index/_doc/1\n{\n  \"my_date\": \"2016-05-11T16:30:55.328Z\"\n}\n\nGET index/_search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"range\": {\n          \"my_date\": {\n            \"gte\": \"now-1h\",\n            \"lte\": \"now\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n可以进行如下替换：\n\n```SQL\nGET index/_search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"range\": {\n          \"my_date\": {\n            \"gte\": \"now-1h/m\",\n            \"lte\": \"now/m\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n在这个例子中我们使用了分钟近似值，如果当前时间是`16:31:29` ，`my_date`字段的范围查询将返回所有从`15:31:00`到`16:31:59`时间段内的数据。如果同一时间好几个用户的查询条件包含这个范围，查询缓存能够加快查询速度。近似查询的范围越长，缓存的效果越明显，但是需要注意过度的近似值可能会破坏用户体验。\n\n### 9.强制合并只读索引\n\n强制合并为一个段对只读索引来说是有益的。在时间线索引中比较常见的场景：只有当前时间的索引会新增数据，历史索引是只读的。分片被强制合并为一个段，可以让查询更加简单和有效。\n\n### 10.预热全局序号\n\n全局序号是用来优化聚合的一种数据结构。他们作为字段缓存的一部分会在`JVM`中延迟计算和存储。作为分桶查询中被频繁使用的字段，你可以让`Elasticsearch`在请求到达前实例化和缓存。这个操作应该谨慎使用，因为他会占用更多内存使得`refresh`变长。这个选项可以在已经创建的索引上动态设置，通过修改`eager global ordinals` 参数：\n\n```SQL\nPUT index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"foo\": {\n        \"type\": \"keyword\",\n        \"eager_global_ordinals\": true\n      }\n    }\n  }\n}\n```\n\n### 11.预热文件系统缓存\n\n如果运行`Elasticsearch`的机器重启了，文件系统缓存会被清空，因此操作系统需要花费一些时间来加载热点索引缓存数据到内存，以便加快查询速度。你可以明确的告诉操作系统哪些文件需要提前加载到缓存中，通过`index.store.preload` 参数来进行指定。\n\n### 12.使用索引排序来加快连接速度\n\n索引排序在加快连接速度方面很有效，代价是文档写入会变慢。\n\n### 13.使用preference来优化缓存使用\n\n有多种缓存可以用来加快查询速度，诸如文件系统缓存、请求缓存、查询缓存。这些缓存大多是在节点层面的，意味着如果你连续发起2次相同的请求，有一个或者多个副本而且所有了负载策略，根据默认的路由算法，2次请求会分配到不同的分片节点，节点层面的缓存无法有效利用。\n\n由于搜索程序的用户会一个接着一个的发起类似的查询请求，比如说为了分析索引索引的子集，使用偏好值来标记当前用户或者请求能够帮助优化缓存的使用。\n\n### 14.副本或许可以提升吞吐量\n\n除了弹性扩展，副本还能提升吞吐量。例如你有一个单一分片索引和三个节点，你需要将副本数量设置为2，这样总共3份副本让每个节点都能充分利用。\n\n现在假设你有2个分片索引和2个节点。第一种情况，副本数量设置为0，意味着每个节点有一个分片。第二种情况副本数量设置为1，意味着每个节点有2个分片。哪种情况能够有更好的查询性能呢？通常情况下，节点的分片数量越少的方案更优。因为能够给每个分片更多的文件系统缓存，而文件系统缓存可能是`Elasticsearch`最有效的优化策略。与此同时，需要注意物副本的方案在单节点失败情况下的风险，需要权衡吞吐量和可用性。\n\n因此分片数量设置为多少比较合适？如果你的集群有`num_nodes`个节点，总共有`num_primaries`个主分片，你期望同时可以应对最多`max_failures`个节点失败的状况，正确的副本数量结算方式为：`max(max_failures, ceil(num_nodes / num_primaries) - 1)`\n\n### 15.使用Search Profiler优化查询\n\n`Profile API`提供了查询和聚合在每一步处理耗时的详细信息。\n\n在`Kibana`上使用` Search Profiler`可以清楚直观的看到分析结果，以及如何优化查询和减轻负载压力。\n\n因为`Profile API`在查询上增加了大量开销，返回的结果适用于了解各个查询阶段的相对耗时。不代表实际的处理时间。\n\n### 16.使用index_phrases加快短语查询\n\n`text`字段有一个`index_phrases`选项来索引2-shingles，能够被短语查询自动应用，在没有`slop`的情况下。如果你的案例中有大量的短语查询，可以显著的加快查询速度。\n\n### 17.使用index_prefixes来加快前缀查询\n\ntext字段有一个index_prefixes选项来索引前缀，在前缀查询条件中能够被自动的应用。如果你的案例中有大量的前缀查询，可以显著的加快查询速度。\n\n### 18.使用constant_keyword来加快过滤速度\n\n有一个通用规则，过滤查询的耗时基本上是匹配文档数量的一个函数。假设你有一个包含骑行的索引。有大量的自行车数据，许多查询上基于过滤条件：`cycle_type: bicycle`。这个常见的过滤会很耗时，因为匹配到了大量的文档。有一个简单的方法来避免运行此类查询，把自行车移动他自己的索引中，查询这个索引来代替过滤查询。\n\n不幸的是这样会使客户端的逻辑变得复杂，而这正是`constant_keyword`发挥作用的地方。通过在bicycles索引上将`cycle_type`字段类型设置为`constant_keyword`，值设置为`bicycle`，客户端依然可以运行和之前单片索引上一样的查询语句，Elasticsearch会在bicycles索引上忽略条件为`cycle_type`并且值为`bicycle`的过滤条件，返回正确的结果。\n\n索引结构如下所示：\n\n```SQL\nPUT bicycles\n{\n  \"mappings\": {\n    \"properties\": {\n      \"cycle_type\": {\n        \"type\": \"constant_keyword\",\n        \"value\": \"bicycle\"\n      },\n      \"name\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPUT other_cycles\n{\n  \"mappings\": {\n    \"properties\": {\n      \"cycle_type\": {\n        \"type\": \"keyword\"\n      },\n      \"name\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n```\n\n我们将索引一分为二，一个仅包含自行车，一辆一个包含其他车辆：独轮车、三轮车等等。在查询时，我们需要查询所有的索引，但是不需要修改查询语句。\n\n```SQL\nGET bicycles,other_cycles/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n          \"description\": \"dutch\"\n        }\n      },\n      \"filter\": {\n        \"term\": {\n          \"cycle_type\": \"bicycle\"\n        }\n      }\n    }\n  }\n}\n```\n\n在`bicycles`索引中，Elasticsearch会忽略`cycle_type`过滤条件将查询请求重写如下：\n\n```SQL\nGET bicycles,other_cycles/_search\n{\n  \"query\": {\n    \"match\": {\n      \"description\": \"dutch\"\n    }\n  }\n}\n```\n\n在`other_cycles`索引，Elasticsearch会快速的发现在`cycle_type`中不包含`bicycle`，返回无匹配结果。\n\n这是一个非常有效的手段，将通用的查询字符内容放在专属索引里面。这个方法也适用于多字段，例如你需要追踪每个骑行工具的颜色，你的`bicycles`索引中大部分都是黑色的自行车，你可以将他分为`bicycles-black`和`bicycles-other-colors`索引。\n\n`constant_keyword`不属于严格意义上的索引优化：更像是将客户端的逻辑查询路由到指定的索引上。但是`constant_keyword`使其透明化，将查询和索引结果解耦来优化性能。","slug":"Elasticsearch搜索优化[翻译版]","published":1,"updated":"2024-01-30T10:02:03.353Z","_id":"cls06n7q60004iocq6mkqclus","comments":1,"layout":"post","photos":[],"content":"<p>在上一篇文章中翻译了索引写入，接下来看看索引的查询有哪些优化手段。</p>\n<p>原文链接：<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html\">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html</a></p>\n<h3 id=\"1-增加文件系统缓存\"><a href=\"#1-增加文件系统缓存\" class=\"headerlink\" title=\"1.增加文件系统缓存\"></a>1.增加文件系统缓存</h3><p>Elasticsearch严重依赖文件系统缓存来加快查询速度。一般来说，至少需要保留一半的可用内存给文件系统，以便Elasticsearch在物理内存中保留索引热点数据。</p>\n<h3 id=\"2-使用更快的硬件\"><a href=\"#2-使用更快的硬件\" class=\"headerlink\" title=\"2.使用更快的硬件\"></a>2.使用更快的硬件</h3><p>如果搜索遇到了I&#x2F;O瓶颈，考虑增加文件系统缓存或者使用更快的存储设备。每次查询涉及随机读和顺序读的混合操作，跨越多个文件，而且每个分片上可能有多个搜索的并发请求，因SSD磁盘比普通硬盘性能更佳。</p>\n<p>本地磁盘比网络云盘更加高效，因为配置更加简单而且可以避免频繁的网络通信。经过优化配置，网络云盘有时也能达到所期望的性能。通过真实负载下的基准测试，来确定优化参数是否生效。如果不能达到你所期望的效果，可以联系你的存储供应商来解决问题。</p>\n<p>如果你的搜索遇到的是CPU瓶颈，可以考虑增加速度更快的CPU。</p>\n<h3 id=\"3-文档结构化\"><a href=\"#3-文档结构化\" class=\"headerlink\" title=\"3.文档结构化\"></a>3.文档结构化</h3><p>文档结构越简单搜索成本越低。</p>\n<p>在实际使用中，应当避免文档关联。嵌套结构<code>nested</code>可能导致查询速度慢上好几倍，父子文档<code>parent-child</code>关联的查询速度可能要慢几百倍。如果可以使用非规范化文档来规避关联关系，查询速度可以得到显著的提升。</p>\n<h3 id=\"4-只搜索必要的字段\"><a href=\"#4-只搜索必要的字段\" class=\"headerlink\" title=\"4.只搜索必要的字段\"></a>4.只搜索必要的字段</h3><p>当<code>query_string</code> 或者 <code>multi_match</code> 包含的字段越多时，搜索速度就会越慢。改善多字段查询速度的通用技巧，是在写入文档时将多个字段的内容复制到一个字段中，在搜索搜索时只需要查询这个字段。使用文档结构的<code>copy-to</code> 指令就可以自动完成，无需修改源文档。下面的例子关于如何改善电影索引的搜索性能，把需要查询的电影名称、情节都放到<code>name_and_plot</code>字段中。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT movies<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;name_and_plot&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;<br>      &#125;,<br>      &quot;name&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;,<br>        &quot;copy_to&quot;: &quot;name_and_plot&quot;<br>      &#125;,<br>      &quot;plot&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;,<br>        &quot;copy_to&quot;: &quot;name_and_plot&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"5-预索引数据\"><a href=\"#5-预索引数据\" class=\"headerlink\" title=\"5.预索引数据\"></a>5.预索引数据</h3><p>在搜索和数据存储优化方面需要取得一个平衡。比如说，如果你所有的文档都有一个 <code>price</code>字段，大多数查询使用了固定范围内的<code>range</code> 聚合查询，你可以将 <code>terms</code>聚合查询的结果存储到新的索引中，来加快查询效率。</p>\n<p>例如，文档如下所示：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<span class=\"hljs-operator\">/</span>_doc<span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span><br>&#123;<br>  &quot;designation&quot;: &quot;spoon&quot;,<br>  &quot;price&quot;: <span class=\"hljs-number\">13</span><br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>搜索请求：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;aggs&quot;: &#123;<br>    &quot;price_ranges&quot;: &#123;<br>      &quot;range&quot;: &#123;<br>        &quot;field&quot;: &quot;price&quot;,<br>        &quot;ranges&quot;: [<br>          &#123; &quot;to&quot;: <span class=\"hljs-number\">10</span> &#125;,<br>          &#123; &quot;from&quot;: <span class=\"hljs-number\">10</span>, &quot;to&quot;: <span class=\"hljs-number\">100</span> &#125;,<br>          &#123; &quot;from&quot;: <span class=\"hljs-number\">100</span> &#125;<br>        ]<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>文档在写入时可以填充到<code>price_range</code>字段中，使用<code>keyword</code>字段类型：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;price_range&quot;: &#123;<br>        &quot;type&quot;: &quot;keyword&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br><br>PUT index<span class=\"hljs-operator\">/</span>_doc<span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span><br>&#123;<br>  &quot;designation&quot;: &quot;spoon&quot;,<br>  &quot;price&quot;: <span class=\"hljs-number\">13</span>,<br>  &quot;price_range&quot;: &quot;10-100&quot;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>然后在搜索时，可以对新的字段进行聚合来代替对<code>price</code>字段进行聚合：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;aggs&quot;: &#123;<br>    &quot;price_ranges&quot;: &#123;<br>      &quot;terms&quot;: &#123;<br>        &quot;field&quot;: &quot;price_range&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-唯一标记使用-keword字段类型\"><a href=\"#6-唯一标记使用-keword字段类型\" class=\"headerlink\" title=\"6.唯一标记使用 keword字段类型\"></a>6.唯一标记使用 keword字段类型</h3><p>不是所有的数字都应该使用 <code>numeric</code> 字段类型。Elasticsearch对数字类型进行了优化，例如<code>integer</code> 或者 <code>long</code>，在<code>range</code>查询场景下。然而，<code>keyword</code>类型在<code>term</code> 和 <code>term-level</code>查询中表现更好。</p>\n<p>唯一标记，例如ISBN或者产品id，很少使用范围查询，却经常使用<code>term-level</code>查询。</p>\n<p>以下情况可以考虑将数字类型的唯一标记存储为keyword类型：</p>\n<ul>\n<li>唯一标记不会用于范围查询；</li>\n<li>更看重搜索性能。keyword字段类型上的term查询比数字类型要快许多；</li>\n</ul>\n<p>如果你不确定使用哪种方式，可以使用<code>multi-field</code>来同存储keywrod和数字类型。</p>\n<h3 id=\"7-避免使用脚本\"><a href=\"#7-避免使用脚本\" class=\"headerlink\" title=\"7.避免使用脚本\"></a>7.避免使用脚本</h3><p>如果可能，避免使用基于脚本的排序、聚合，以及用脚本计算评分。</p>\n<h3 id=\"8-搜索近似时间\"><a href=\"#8-搜索近似时间\" class=\"headerlink\" title=\"8.搜索近似时间\"></a>8.搜索近似时间</h3><p>使用<code>now</code>条件来搜索时间字段通常没有缓存，因为匹配的条件一直在变化。然而使用近似时间在条件查询中经常上适用的，而且可以更好的利用查询缓存。</p>\n<p>例如下面的查询：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<span class=\"hljs-operator\">/</span>_doc<span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span><br>&#123;<br>  &quot;my_date&quot;: &quot;2016-05-11T16:30:55.328Z&quot;<br>&#125;<br><br><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;constant_score&quot;: &#123;<br>      &quot;filter&quot;: &#123;<br>        &quot;range&quot;: &#123;<br>          &quot;my_date&quot;: &#123;<br>            &quot;gte&quot;: &quot;now-1h&quot;,<br>            &quot;lte&quot;: &quot;now&quot;<br>          &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>可以进行如下替换：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;constant_score&quot;: &#123;<br>      &quot;filter&quot;: &#123;<br>        &quot;range&quot;: &#123;<br>          &quot;my_date&quot;: &#123;<br>            &quot;gte&quot;: &quot;now-1h/m&quot;,<br>            &quot;lte&quot;: &quot;now/m&quot;<br>          &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中我们使用了分钟近似值，如果当前时间是<code>16:31:29</code> ，<code>my_date</code>字段的范围查询将返回所有从<code>15:31:00</code>到<code>16:31:59</code>时间段内的数据。如果同一时间好几个用户的查询条件包含这个范围，查询缓存能够加快查询速度。近似查询的范围越长，缓存的效果越明显，但是需要注意过度的近似值可能会破坏用户体验。</p>\n<h3 id=\"9-强制合并只读索引\"><a href=\"#9-强制合并只读索引\" class=\"headerlink\" title=\"9.强制合并只读索引\"></a>9.强制合并只读索引</h3><p>强制合并为一个段对只读索引来说是有益的。在时间线索引中比较常见的场景：只有当前时间的索引会新增数据，历史索引是只读的。分片被强制合并为一个段，可以让查询更加简单和有效。</p>\n<h3 id=\"10-预热全局序号\"><a href=\"#10-预热全局序号\" class=\"headerlink\" title=\"10.预热全局序号\"></a>10.预热全局序号</h3><p>全局序号是用来优化聚合的一种数据结构。他们作为字段缓存的一部分会在<code>JVM</code>中延迟计算和存储。作为分桶查询中被频繁使用的字段，你可以让<code>Elasticsearch</code>在请求到达前实例化和缓存。这个操作应该谨慎使用，因为他会占用更多内存使得<code>refresh</code>变长。这个选项可以在已经创建的索引上动态设置，通过修改<code>eager global ordinals</code> 参数：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;foo&quot;: &#123;<br>        &quot;type&quot;: &quot;keyword&quot;,<br>        &quot;eager_global_ordinals&quot;: <span class=\"hljs-literal\">true</span><br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"11-预热文件系统缓存\"><a href=\"#11-预热文件系统缓存\" class=\"headerlink\" title=\"11.预热文件系统缓存\"></a>11.预热文件系统缓存</h3><p>如果运行<code>Elasticsearch</code>的机器重启了，文件系统缓存会被清空，因此操作系统需要花费一些时间来加载热点索引缓存数据到内存，以便加快查询速度。你可以明确的告诉操作系统哪些文件需要提前加载到缓存中，通过<code>index.store.preload</code> 参数来进行指定。</p>\n<h3 id=\"12-使用索引排序来加快连接速度\"><a href=\"#12-使用索引排序来加快连接速度\" class=\"headerlink\" title=\"12.使用索引排序来加快连接速度\"></a>12.使用索引排序来加快连接速度</h3><p>索引排序在加快连接速度方面很有效，代价是文档写入会变慢。</p>\n<h3 id=\"13-使用preference来优化缓存使用\"><a href=\"#13-使用preference来优化缓存使用\" class=\"headerlink\" title=\"13.使用preference来优化缓存使用\"></a>13.使用preference来优化缓存使用</h3><p>有多种缓存可以用来加快查询速度，诸如文件系统缓存、请求缓存、查询缓存。这些缓存大多是在节点层面的，意味着如果你连续发起2次相同的请求，有一个或者多个副本而且所有了负载策略，根据默认的路由算法，2次请求会分配到不同的分片节点，节点层面的缓存无法有效利用。</p>\n<p>由于搜索程序的用户会一个接着一个的发起类似的查询请求，比如说为了分析索引索引的子集，使用偏好值来标记当前用户或者请求能够帮助优化缓存的使用。</p>\n<h3 id=\"14-副本或许可以提升吞吐量\"><a href=\"#14-副本或许可以提升吞吐量\" class=\"headerlink\" title=\"14.副本或许可以提升吞吐量\"></a>14.副本或许可以提升吞吐量</h3><p>除了弹性扩展，副本还能提升吞吐量。例如你有一个单一分片索引和三个节点，你需要将副本数量设置为2，这样总共3份副本让每个节点都能充分利用。</p>\n<p>现在假设你有2个分片索引和2个节点。第一种情况，副本数量设置为0，意味着每个节点有一个分片。第二种情况副本数量设置为1，意味着每个节点有2个分片。哪种情况能够有更好的查询性能呢？通常情况下，节点的分片数量越少的方案更优。因为能够给每个分片更多的文件系统缓存，而文件系统缓存可能是<code>Elasticsearch</code>最有效的优化策略。与此同时，需要注意物副本的方案在单节点失败情况下的风险，需要权衡吞吐量和可用性。</p>\n<p>因此分片数量设置为多少比较合适？如果你的集群有<code>num_nodes</code>个节点，总共有<code>num_primaries</code>个主分片，你期望同时可以应对最多<code>max_failures</code>个节点失败的状况，正确的副本数量结算方式为：<code>max(max_failures, ceil(num_nodes / num_primaries) - 1)</code></p>\n<h3 id=\"15-使用Search-Profiler优化查询\"><a href=\"#15-使用Search-Profiler优化查询\" class=\"headerlink\" title=\"15.使用Search Profiler优化查询\"></a>15.使用Search Profiler优化查询</h3><p><code>Profile API</code>提供了查询和聚合在每一步处理耗时的详细信息。</p>\n<p>在<code>Kibana</code>上使用<code> Search Profiler</code>可以清楚直观的看到分析结果，以及如何优化查询和减轻负载压力。</p>\n<p>因为<code>Profile API</code>在查询上增加了大量开销，返回的结果适用于了解各个查询阶段的相对耗时。不代表实际的处理时间。</p>\n<h3 id=\"16-使用index-phrases加快短语查询\"><a href=\"#16-使用index-phrases加快短语查询\" class=\"headerlink\" title=\"16.使用index_phrases加快短语查询\"></a>16.使用index_phrases加快短语查询</h3><p><code>text</code>字段有一个<code>index_phrases</code>选项来索引2-shingles，能够被短语查询自动应用，在没有<code>slop</code>的情况下。如果你的案例中有大量的短语查询，可以显著的加快查询速度。</p>\n<h3 id=\"17-使用index-prefixes来加快前缀查询\"><a href=\"#17-使用index-prefixes来加快前缀查询\" class=\"headerlink\" title=\"17.使用index_prefixes来加快前缀查询\"></a>17.使用index_prefixes来加快前缀查询</h3><p>text字段有一个index_prefixes选项来索引前缀，在前缀查询条件中能够被自动的应用。如果你的案例中有大量的前缀查询，可以显著的加快查询速度。</p>\n<h3 id=\"18-使用constant-keyword来加快过滤速度\"><a href=\"#18-使用constant-keyword来加快过滤速度\" class=\"headerlink\" title=\"18.使用constant_keyword来加快过滤速度\"></a>18.使用constant_keyword来加快过滤速度</h3><p>有一个通用规则，过滤查询的耗时基本上是匹配文档数量的一个函数。假设你有一个包含骑行的索引。有大量的自行车数据，许多查询上基于过滤条件：<code>cycle_type: bicycle</code>。这个常见的过滤会很耗时，因为匹配到了大量的文档。有一个简单的方法来避免运行此类查询，把自行车移动他自己的索引中，查询这个索引来代替过滤查询。</p>\n<p>不幸的是这样会使客户端的逻辑变得复杂，而这正是<code>constant_keyword</code>发挥作用的地方。通过在bicycles索引上将<code>cycle_type</code>字段类型设置为<code>constant_keyword</code>，值设置为<code>bicycle</code>，客户端依然可以运行和之前单片索引上一样的查询语句，Elasticsearch会在bicycles索引上忽略条件为<code>cycle_type</code>并且值为<code>bicycle</code>的过滤条件，返回正确的结果。</p>\n<p>索引结构如下所示：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT bicycles<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;cycle_type&quot;: &#123;<br>        &quot;type&quot;: &quot;constant_keyword&quot;,<br>        &quot;value&quot;: &quot;bicycle&quot;<br>      &#125;,<br>      &quot;name&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br><br>PUT other_cycles<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;cycle_type&quot;: &#123;<br>        &quot;type&quot;: &quot;keyword&quot;<br>      &#125;,<br>      &quot;name&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>我们将索引一分为二，一个仅包含自行车，一辆一个包含其他车辆：独轮车、三轮车等等。在查询时，我们需要查询所有的索引，但是不需要修改查询语句。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> bicycles,other_cycles<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;bool&quot;: &#123;<br>      &quot;must&quot;: &#123;<br>        &quot;match&quot;: &#123;<br>          &quot;description&quot;: &quot;dutch&quot;<br>        &#125;<br>      &#125;,<br>      &quot;filter&quot;: &#123;<br>        &quot;term&quot;: &#123;<br>          &quot;cycle_type&quot;: &quot;bicycle&quot;<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在<code>bicycles</code>索引中，Elasticsearch会忽略<code>cycle_type</code>过滤条件将查询请求重写如下：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> bicycles,other_cycles<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;match&quot;: &#123;<br>      &quot;description&quot;: &quot;dutch&quot;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在<code>other_cycles</code>索引，Elasticsearch会快速的发现在<code>cycle_type</code>中不包含<code>bicycle</code>，返回无匹配结果。</p>\n<p>这是一个非常有效的手段，将通用的查询字符内容放在专属索引里面。这个方法也适用于多字段，例如你需要追踪每个骑行工具的颜色，你的<code>bicycles</code>索引中大部分都是黑色的自行车，你可以将他分为<code>bicycles-black</code>和<code>bicycles-other-colors</code>索引。</p>\n<p><code>constant_keyword</code>不属于严格意义上的索引优化：更像是将客户端的逻辑查询路由到指定的索引上。但是<code>constant_keyword</code>使其透明化，将查询和索引结果解耦来优化性能。</p>\n","excerpt":"","more":"<p>在上一篇文章中翻译了索引写入，接下来看看索引的查询有哪些优化手段。</p>\n<p>原文链接：<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html\">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html</a></p>\n<h3 id=\"1-增加文件系统缓存\"><a href=\"#1-增加文件系统缓存\" class=\"headerlink\" title=\"1.增加文件系统缓存\"></a>1.增加文件系统缓存</h3><p>Elasticsearch严重依赖文件系统缓存来加快查询速度。一般来说，至少需要保留一半的可用内存给文件系统，以便Elasticsearch在物理内存中保留索引热点数据。</p>\n<h3 id=\"2-使用更快的硬件\"><a href=\"#2-使用更快的硬件\" class=\"headerlink\" title=\"2.使用更快的硬件\"></a>2.使用更快的硬件</h3><p>如果搜索遇到了I&#x2F;O瓶颈，考虑增加文件系统缓存或者使用更快的存储设备。每次查询涉及随机读和顺序读的混合操作，跨越多个文件，而且每个分片上可能有多个搜索的并发请求，因SSD磁盘比普通硬盘性能更佳。</p>\n<p>本地磁盘比网络云盘更加高效，因为配置更加简单而且可以避免频繁的网络通信。经过优化配置，网络云盘有时也能达到所期望的性能。通过真实负载下的基准测试，来确定优化参数是否生效。如果不能达到你所期望的效果，可以联系你的存储供应商来解决问题。</p>\n<p>如果你的搜索遇到的是CPU瓶颈，可以考虑增加速度更快的CPU。</p>\n<h3 id=\"3-文档结构化\"><a href=\"#3-文档结构化\" class=\"headerlink\" title=\"3.文档结构化\"></a>3.文档结构化</h3><p>文档结构越简单搜索成本越低。</p>\n<p>在实际使用中，应当避免文档关联。嵌套结构<code>nested</code>可能导致查询速度慢上好几倍，父子文档<code>parent-child</code>关联的查询速度可能要慢几百倍。如果可以使用非规范化文档来规避关联关系，查询速度可以得到显著的提升。</p>\n<h3 id=\"4-只搜索必要的字段\"><a href=\"#4-只搜索必要的字段\" class=\"headerlink\" title=\"4.只搜索必要的字段\"></a>4.只搜索必要的字段</h3><p>当<code>query_string</code> 或者 <code>multi_match</code> 包含的字段越多时，搜索速度就会越慢。改善多字段查询速度的通用技巧，是在写入文档时将多个字段的内容复制到一个字段中，在搜索搜索时只需要查询这个字段。使用文档结构的<code>copy-to</code> 指令就可以自动完成，无需修改源文档。下面的例子关于如何改善电影索引的搜索性能，把需要查询的电影名称、情节都放到<code>name_and_plot</code>字段中。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT movies<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;name_and_plot&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;<br>      &#125;,<br>      &quot;name&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;,<br>        &quot;copy_to&quot;: &quot;name_and_plot&quot;<br>      &#125;,<br>      &quot;plot&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;,<br>        &quot;copy_to&quot;: &quot;name_and_plot&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"5-预索引数据\"><a href=\"#5-预索引数据\" class=\"headerlink\" title=\"5.预索引数据\"></a>5.预索引数据</h3><p>在搜索和数据存储优化方面需要取得一个平衡。比如说，如果你所有的文档都有一个 <code>price</code>字段，大多数查询使用了固定范围内的<code>range</code> 聚合查询，你可以将 <code>terms</code>聚合查询的结果存储到新的索引中，来加快查询效率。</p>\n<p>例如，文档如下所示：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<span class=\"hljs-operator\">/</span>_doc<span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span><br>&#123;<br>  &quot;designation&quot;: &quot;spoon&quot;,<br>  &quot;price&quot;: <span class=\"hljs-number\">13</span><br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>搜索请求：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;aggs&quot;: &#123;<br>    &quot;price_ranges&quot;: &#123;<br>      &quot;range&quot;: &#123;<br>        &quot;field&quot;: &quot;price&quot;,<br>        &quot;ranges&quot;: [<br>          &#123; &quot;to&quot;: <span class=\"hljs-number\">10</span> &#125;,<br>          &#123; &quot;from&quot;: <span class=\"hljs-number\">10</span>, &quot;to&quot;: <span class=\"hljs-number\">100</span> &#125;,<br>          &#123; &quot;from&quot;: <span class=\"hljs-number\">100</span> &#125;<br>        ]<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>文档在写入时可以填充到<code>price_range</code>字段中，使用<code>keyword</code>字段类型：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;price_range&quot;: &#123;<br>        &quot;type&quot;: &quot;keyword&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br><br>PUT index<span class=\"hljs-operator\">/</span>_doc<span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span><br>&#123;<br>  &quot;designation&quot;: &quot;spoon&quot;,<br>  &quot;price&quot;: <span class=\"hljs-number\">13</span>,<br>  &quot;price_range&quot;: &quot;10-100&quot;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>然后在搜索时，可以对新的字段进行聚合来代替对<code>price</code>字段进行聚合：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;aggs&quot;: &#123;<br>    &quot;price_ranges&quot;: &#123;<br>      &quot;terms&quot;: &#123;<br>        &quot;field&quot;: &quot;price_range&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-唯一标记使用-keword字段类型\"><a href=\"#6-唯一标记使用-keword字段类型\" class=\"headerlink\" title=\"6.唯一标记使用 keword字段类型\"></a>6.唯一标记使用 keword字段类型</h3><p>不是所有的数字都应该使用 <code>numeric</code> 字段类型。Elasticsearch对数字类型进行了优化，例如<code>integer</code> 或者 <code>long</code>，在<code>range</code>查询场景下。然而，<code>keyword</code>类型在<code>term</code> 和 <code>term-level</code>查询中表现更好。</p>\n<p>唯一标记，例如ISBN或者产品id，很少使用范围查询，却经常使用<code>term-level</code>查询。</p>\n<p>以下情况可以考虑将数字类型的唯一标记存储为keyword类型：</p>\n<ul>\n<li>唯一标记不会用于范围查询；</li>\n<li>更看重搜索性能。keyword字段类型上的term查询比数字类型要快许多；</li>\n</ul>\n<p>如果你不确定使用哪种方式，可以使用<code>multi-field</code>来同存储keywrod和数字类型。</p>\n<h3 id=\"7-避免使用脚本\"><a href=\"#7-避免使用脚本\" class=\"headerlink\" title=\"7.避免使用脚本\"></a>7.避免使用脚本</h3><p>如果可能，避免使用基于脚本的排序、聚合，以及用脚本计算评分。</p>\n<h3 id=\"8-搜索近似时间\"><a href=\"#8-搜索近似时间\" class=\"headerlink\" title=\"8.搜索近似时间\"></a>8.搜索近似时间</h3><p>使用<code>now</code>条件来搜索时间字段通常没有缓存，因为匹配的条件一直在变化。然而使用近似时间在条件查询中经常上适用的，而且可以更好的利用查询缓存。</p>\n<p>例如下面的查询：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<span class=\"hljs-operator\">/</span>_doc<span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span><br>&#123;<br>  &quot;my_date&quot;: &quot;2016-05-11T16:30:55.328Z&quot;<br>&#125;<br><br><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;constant_score&quot;: &#123;<br>      &quot;filter&quot;: &#123;<br>        &quot;range&quot;: &#123;<br>          &quot;my_date&quot;: &#123;<br>            &quot;gte&quot;: &quot;now-1h&quot;,<br>            &quot;lte&quot;: &quot;now&quot;<br>          &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>可以进行如下替换：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> index<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;constant_score&quot;: &#123;<br>      &quot;filter&quot;: &#123;<br>        &quot;range&quot;: &#123;<br>          &quot;my_date&quot;: &#123;<br>            &quot;gte&quot;: &quot;now-1h/m&quot;,<br>            &quot;lte&quot;: &quot;now/m&quot;<br>          &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中我们使用了分钟近似值，如果当前时间是<code>16:31:29</code> ，<code>my_date</code>字段的范围查询将返回所有从<code>15:31:00</code>到<code>16:31:59</code>时间段内的数据。如果同一时间好几个用户的查询条件包含这个范围，查询缓存能够加快查询速度。近似查询的范围越长，缓存的效果越明显，但是需要注意过度的近似值可能会破坏用户体验。</p>\n<h3 id=\"9-强制合并只读索引\"><a href=\"#9-强制合并只读索引\" class=\"headerlink\" title=\"9.强制合并只读索引\"></a>9.强制合并只读索引</h3><p>强制合并为一个段对只读索引来说是有益的。在时间线索引中比较常见的场景：只有当前时间的索引会新增数据，历史索引是只读的。分片被强制合并为一个段，可以让查询更加简单和有效。</p>\n<h3 id=\"10-预热全局序号\"><a href=\"#10-预热全局序号\" class=\"headerlink\" title=\"10.预热全局序号\"></a>10.预热全局序号</h3><p>全局序号是用来优化聚合的一种数据结构。他们作为字段缓存的一部分会在<code>JVM</code>中延迟计算和存储。作为分桶查询中被频繁使用的字段，你可以让<code>Elasticsearch</code>在请求到达前实例化和缓存。这个操作应该谨慎使用，因为他会占用更多内存使得<code>refresh</code>变长。这个选项可以在已经创建的索引上动态设置，通过修改<code>eager global ordinals</code> 参数：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT index<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;foo&quot;: &#123;<br>        &quot;type&quot;: &quot;keyword&quot;,<br>        &quot;eager_global_ordinals&quot;: <span class=\"hljs-literal\">true</span><br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"11-预热文件系统缓存\"><a href=\"#11-预热文件系统缓存\" class=\"headerlink\" title=\"11.预热文件系统缓存\"></a>11.预热文件系统缓存</h3><p>如果运行<code>Elasticsearch</code>的机器重启了，文件系统缓存会被清空，因此操作系统需要花费一些时间来加载热点索引缓存数据到内存，以便加快查询速度。你可以明确的告诉操作系统哪些文件需要提前加载到缓存中，通过<code>index.store.preload</code> 参数来进行指定。</p>\n<h3 id=\"12-使用索引排序来加快连接速度\"><a href=\"#12-使用索引排序来加快连接速度\" class=\"headerlink\" title=\"12.使用索引排序来加快连接速度\"></a>12.使用索引排序来加快连接速度</h3><p>索引排序在加快连接速度方面很有效，代价是文档写入会变慢。</p>\n<h3 id=\"13-使用preference来优化缓存使用\"><a href=\"#13-使用preference来优化缓存使用\" class=\"headerlink\" title=\"13.使用preference来优化缓存使用\"></a>13.使用preference来优化缓存使用</h3><p>有多种缓存可以用来加快查询速度，诸如文件系统缓存、请求缓存、查询缓存。这些缓存大多是在节点层面的，意味着如果你连续发起2次相同的请求，有一个或者多个副本而且所有了负载策略，根据默认的路由算法，2次请求会分配到不同的分片节点，节点层面的缓存无法有效利用。</p>\n<p>由于搜索程序的用户会一个接着一个的发起类似的查询请求，比如说为了分析索引索引的子集，使用偏好值来标记当前用户或者请求能够帮助优化缓存的使用。</p>\n<h3 id=\"14-副本或许可以提升吞吐量\"><a href=\"#14-副本或许可以提升吞吐量\" class=\"headerlink\" title=\"14.副本或许可以提升吞吐量\"></a>14.副本或许可以提升吞吐量</h3><p>除了弹性扩展，副本还能提升吞吐量。例如你有一个单一分片索引和三个节点，你需要将副本数量设置为2，这样总共3份副本让每个节点都能充分利用。</p>\n<p>现在假设你有2个分片索引和2个节点。第一种情况，副本数量设置为0，意味着每个节点有一个分片。第二种情况副本数量设置为1，意味着每个节点有2个分片。哪种情况能够有更好的查询性能呢？通常情况下，节点的分片数量越少的方案更优。因为能够给每个分片更多的文件系统缓存，而文件系统缓存可能是<code>Elasticsearch</code>最有效的优化策略。与此同时，需要注意物副本的方案在单节点失败情况下的风险，需要权衡吞吐量和可用性。</p>\n<p>因此分片数量设置为多少比较合适？如果你的集群有<code>num_nodes</code>个节点，总共有<code>num_primaries</code>个主分片，你期望同时可以应对最多<code>max_failures</code>个节点失败的状况，正确的副本数量结算方式为：<code>max(max_failures, ceil(num_nodes / num_primaries) - 1)</code></p>\n<h3 id=\"15-使用Search-Profiler优化查询\"><a href=\"#15-使用Search-Profiler优化查询\" class=\"headerlink\" title=\"15.使用Search Profiler优化查询\"></a>15.使用Search Profiler优化查询</h3><p><code>Profile API</code>提供了查询和聚合在每一步处理耗时的详细信息。</p>\n<p>在<code>Kibana</code>上使用<code> Search Profiler</code>可以清楚直观的看到分析结果，以及如何优化查询和减轻负载压力。</p>\n<p>因为<code>Profile API</code>在查询上增加了大量开销，返回的结果适用于了解各个查询阶段的相对耗时。不代表实际的处理时间。</p>\n<h3 id=\"16-使用index-phrases加快短语查询\"><a href=\"#16-使用index-phrases加快短语查询\" class=\"headerlink\" title=\"16.使用index_phrases加快短语查询\"></a>16.使用index_phrases加快短语查询</h3><p><code>text</code>字段有一个<code>index_phrases</code>选项来索引2-shingles，能够被短语查询自动应用，在没有<code>slop</code>的情况下。如果你的案例中有大量的短语查询，可以显著的加快查询速度。</p>\n<h3 id=\"17-使用index-prefixes来加快前缀查询\"><a href=\"#17-使用index-prefixes来加快前缀查询\" class=\"headerlink\" title=\"17.使用index_prefixes来加快前缀查询\"></a>17.使用index_prefixes来加快前缀查询</h3><p>text字段有一个index_prefixes选项来索引前缀，在前缀查询条件中能够被自动的应用。如果你的案例中有大量的前缀查询，可以显著的加快查询速度。</p>\n<h3 id=\"18-使用constant-keyword来加快过滤速度\"><a href=\"#18-使用constant-keyword来加快过滤速度\" class=\"headerlink\" title=\"18.使用constant_keyword来加快过滤速度\"></a>18.使用constant_keyword来加快过滤速度</h3><p>有一个通用规则，过滤查询的耗时基本上是匹配文档数量的一个函数。假设你有一个包含骑行的索引。有大量的自行车数据，许多查询上基于过滤条件：<code>cycle_type: bicycle</code>。这个常见的过滤会很耗时，因为匹配到了大量的文档。有一个简单的方法来避免运行此类查询，把自行车移动他自己的索引中，查询这个索引来代替过滤查询。</p>\n<p>不幸的是这样会使客户端的逻辑变得复杂，而这正是<code>constant_keyword</code>发挥作用的地方。通过在bicycles索引上将<code>cycle_type</code>字段类型设置为<code>constant_keyword</code>，值设置为<code>bicycle</code>，客户端依然可以运行和之前单片索引上一样的查询语句，Elasticsearch会在bicycles索引上忽略条件为<code>cycle_type</code>并且值为<code>bicycle</code>的过滤条件，返回正确的结果。</p>\n<p>索引结构如下所示：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\">PUT bicycles<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;cycle_type&quot;: &#123;<br>        &quot;type&quot;: &quot;constant_keyword&quot;,<br>        &quot;value&quot;: &quot;bicycle&quot;<br>      &#125;,<br>      &quot;name&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br><br>PUT other_cycles<br>&#123;<br>  &quot;mappings&quot;: &#123;<br>    &quot;properties&quot;: &#123;<br>      &quot;cycle_type&quot;: &#123;<br>        &quot;type&quot;: &quot;keyword&quot;<br>      &#125;,<br>      &quot;name&quot;: &#123;<br>        &quot;type&quot;: &quot;text&quot;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>我们将索引一分为二，一个仅包含自行车，一辆一个包含其他车辆：独轮车、三轮车等等。在查询时，我们需要查询所有的索引，但是不需要修改查询语句。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> bicycles,other_cycles<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;bool&quot;: &#123;<br>      &quot;must&quot;: &#123;<br>        &quot;match&quot;: &#123;<br>          &quot;description&quot;: &quot;dutch&quot;<br>        &#125;<br>      &#125;,<br>      &quot;filter&quot;: &#123;<br>        &quot;term&quot;: &#123;<br>          &quot;cycle_type&quot;: &quot;bicycle&quot;<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在<code>bicycles</code>索引中，Elasticsearch会忽略<code>cycle_type</code>过滤条件将查询请求重写如下：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs SQL\"><span class=\"hljs-keyword\">GET</span> bicycles,other_cycles<span class=\"hljs-operator\">/</span>_search<br>&#123;<br>  &quot;query&quot;: &#123;<br>    &quot;match&quot;: &#123;<br>      &quot;description&quot;: &quot;dutch&quot;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在<code>other_cycles</code>索引，Elasticsearch会快速的发现在<code>cycle_type</code>中不包含<code>bicycle</code>，返回无匹配结果。</p>\n<p>这是一个非常有效的手段，将通用的查询字符内容放在专属索引里面。这个方法也适用于多字段，例如你需要追踪每个骑行工具的颜色，你的<code>bicycles</code>索引中大部分都是黑色的自行车，你可以将他分为<code>bicycles-black</code>和<code>bicycles-other-colors</code>索引。</p>\n<p><code>constant_keyword</code>不属于严格意义上的索引优化：更像是将客户端的逻辑查询路由到指定的索引上。但是<code>constant_keyword</code>使其透明化，将查询和索引结果解耦来优化性能。</p>\n"},{"title":"Redis实战之搞懂Redisson分布式锁机制","date":"2024-01-29T16:00:00.000Z","_content":"\n### 一、简介\nRedisson是什么？以下是官网的简介，相信各位彦祖们都能看懂，就不翻译了。\n> Redisson is a Redis Java client with features of In-Memory Data Grid. It provides more convenient and easiest way to work with Redis. Redisson objects provides a separation of concern, which allows you to keep focus on the data modeling and application logic.\n\n作为Redis广受欢迎的客户端，Redisson具有以下特性：\n\n- 线程安全的实现；\n- 支持多种Redis种模式，集群模式、哨兵模式、主从模式、单机模式等；\n- 支持主动重连、失败自动重试；\n- 丰富的数据类型：Object, Binary stream, BitSet, AtomicLong, Bloom filter, Map, Set, List, SortedSet, Queue, Deque等；\n- 多样化的锁结构：Lock, FairLock, MultiLock, RedLock, ReadWriteLock, Semaphore, CountDownLatch等;\n- 异步API实现：Asynchronous、RxJava3、Reactive Streams；\n- Spring生态支持：Spring Cache、Spring Transaction API、Spring Data Redis、Spring Boot Starter、Spring Session；\n\n### 二、使用方式\n#### 1.基本使用\n基本使用方法和API，官方文档有比较详细的描述，就不多加赘述了。\nhttps://github.com/redisson/redisson/wiki/Table-of-Content\n#### 2.与Spring Boot集成\n在实例化Bean的方式上、配置文件格式上有些许区别，文档有具体介绍。\nhttps://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter\n\n### 三、分布式锁\n使用Redis来实现分布式锁，大家所熟知的SET NX命令，存在以下问题：\n1. 不可重入：同一个线程无法多次获取同一把锁；\n2. 不可重试：只能操作获取锁一次，失败无法重试；\n3. 超时释放：如果业务耗时较长，超过失效时间会自动释放锁，此时其他线程可以获取到锁，破坏了唯一性(同一时间，只有一个线程获取到锁)；\n\n从源码的角度，来分析一下Redisson是如何解决这些问题的。\n#### 1.可重入机制\n从 redissonClient的tryLock()方法源码一路跟踪，tryLockInnerAsync()方法的实现代码如下：\n```\n<T> RFuture<T> tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {  \n    return commandExecutor.syncedEval(getRawName(), LongCodec.INSTANCE, command,  \n        \"if ((redis.call('exists', KEYS[1]) == 0) \" +  \n        \"or (redis.call('hexists', KEYS[1], ARGV[2]) == 1)) then \" +  \n        \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" +  \n        \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +  \n        \"return nil; \" +  \n        \"end; \" +  \n        \"return redis.call('pttl', KEYS[1]);\",  \n    Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));  \n}\n\nprotected RFuture<Boolean> unlockInnerAsync(long threadId) {  \n    return evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,  \n        \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" +  \n        \"return nil;\" +  \n        \"end; \" +  \n        \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" +  \n        \"if (counter > 0) then \" +  \n        \"redis.call('pexpire', KEYS[1], ARGV[2]); \" +  \n        \"return 0; \" +  \n        \"else \" +  \n        \"redis.call('del', KEYS[1]); \" +  \n        \"redis.call(ARGV[4], KEYS[2], ARGV[1]); \" +  \n        \"return 1; \" +  \n        \"end; \" +  \n        \"return nil;\",  \n    Arrays.asList(getRawName(), getChannelName()),  \n    LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId), getSubscribeService().getPublishCommand());  \n}\n```\n这里用到了Lua脚本，判断key不存在或者存在且等于当前线程id时，使用了Hash结构来记录重入的次数，实现思路类似于ReentrantLock。而在解锁时，从unlockInnerAsync()方法中可以看到，对重入次数进行了减1操作，并且推送了订阅事件。因此可以得知进行了N次加锁后，需要操作N次解锁，才能释放锁。\n#### 2.失败重试机制\n在tryLock()方法中，返回值ttl为空时说明已经成功获取到锁，失败的情况会先判断是否已经超时，如果没有超时则会通过subscribe()方法进行订阅锁事件，当锁被释放时会再次尝试获取。\n```\n@Override\npublic boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException {\n    long time = unit.toMillis(waitTime);\n    long current = System.currentTimeMillis();\n    long threadId = Thread.currentThread().getId();\n    Long ttl = tryAcquire(waitTime, leaseTime, unit, threadId);\n    // lock acquired\n    if (ttl == null) {\n        return true;\n    }\n    \n    time -= System.currentTimeMillis() - current;\n    if (time <= 0) {\n        acquireFailed(waitTime, unit, threadId);\n        return false;\n    }\n\n    current = System.currentTimeMillis();\n    CompletableFuture<RedissonLockEntry> subscribeFuture = subscribe(threadId);\n    try {\n        subscribeFuture.get(time, TimeUnit.MILLISECONDS);\n    } catch (TimeoutException e) {\n        if (!subscribeFuture.completeExceptionally(new RedisTimeoutException(\n                \"Unable to acquire subscription lock after \" + time + \"ms. \" +\n                        \"Try to increase 'subscriptionsPerConnection' and/or 'subscriptionConnectionPoolSize' parameters.\"))) {\n            subscribeFuture.whenComplete((res, ex) -> {\n                if (ex == null) {\n                    unsubscribe(res, threadId);\n                }\n            });\n        }\n        acquireFailed(waitTime, unit, threadId);\n        return false;\n    } catch (ExecutionException e) {\n        acquireFailed(waitTime, unit, threadId);\n        return false;\n    }\n}    \n```\n#### 3.解决超时释放问题\n在文档的分布式锁章节，每一种类型的锁都有以下描述：\n> If Redisson instance which acquired lock crashes then such lock could hang forever in acquired state. To avoid this Redisson maintains lock watchdog, it prolongs lock expiration while lock holder Redisson instance is alive. By default lock watchdog timeout is 30 seconds and can be changed through [Config.lockWatchdogTimeout](https://github.com/redisson/redisson/wiki/2.-Configuration#lockwatchdogtimeout) setting.\n\nRession引入了wathdog机制，在锁持有者Redisson实例处于活动状态时，延长锁的过期时间，默认情况下，锁定看门狗的超时时间为30s。\n从tryLock()方法的源码追踪，在tryAcquireAsync()方法中进行了定时延长有效期的操作。\n\n```\nprivate RFuture<Long> tryAcquireAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId) {\n    RFuture<Long> ttlRemainingFuture;\n    if (leaseTime > 0) {\n        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);\n    } else {\n        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,\n                TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);\n    }\n    CompletionStage<Long> s = handleNoSync(threadId, ttlRemainingFuture);\n    ttlRemainingFuture = new CompletableFutureWrapper<>(s);\n\n    CompletionStage<Long> f = ttlRemainingFuture.thenApply(ttlRemaining -> {\n        // lock acquired\n        if (ttlRemaining == null) {\n            if (leaseTime > 0) {\n                internalLockLeaseTime = unit.toMillis(leaseTime);\n            } else {\n                scheduleExpirationRenewal(threadId);\n            }\n        }\n        return ttlRemaining;\n    });\n    return new CompletableFutureWrapper<>(f);\n}\n```\n通过scheduleExpirationRenewal()方法设置定时任务，底层是基于Netty的HashedWheelTimer时间轮函数，这里就不展开讨论了，感兴趣的话可以去翻翻源码。\n### 四、总结\nRedisson分布式锁的实现原理：\n- 可重入：记录线程id和重入次数；\n- 可重试：利用订阅功能实现等待、唤醒机制，达到失败重试的目的；\n- 延长有效期：使用watchdog方式，通过定时任务延长有效期。\n\n","source":"_posts/Redis实战之搞懂Redisson分布式锁机制.md","raw":"---\ntitle: Redis实战之搞懂Redisson分布式锁机制\ndate: 2024-01-30\n---\n\n### 一、简介\nRedisson是什么？以下是官网的简介，相信各位彦祖们都能看懂，就不翻译了。\n> Redisson is a Redis Java client with features of In-Memory Data Grid. It provides more convenient and easiest way to work with Redis. Redisson objects provides a separation of concern, which allows you to keep focus on the data modeling and application logic.\n\n作为Redis广受欢迎的客户端，Redisson具有以下特性：\n\n- 线程安全的实现；\n- 支持多种Redis种模式，集群模式、哨兵模式、主从模式、单机模式等；\n- 支持主动重连、失败自动重试；\n- 丰富的数据类型：Object, Binary stream, BitSet, AtomicLong, Bloom filter, Map, Set, List, SortedSet, Queue, Deque等；\n- 多样化的锁结构：Lock, FairLock, MultiLock, RedLock, ReadWriteLock, Semaphore, CountDownLatch等;\n- 异步API实现：Asynchronous、RxJava3、Reactive Streams；\n- Spring生态支持：Spring Cache、Spring Transaction API、Spring Data Redis、Spring Boot Starter、Spring Session；\n\n### 二、使用方式\n#### 1.基本使用\n基本使用方法和API，官方文档有比较详细的描述，就不多加赘述了。\nhttps://github.com/redisson/redisson/wiki/Table-of-Content\n#### 2.与Spring Boot集成\n在实例化Bean的方式上、配置文件格式上有些许区别，文档有具体介绍。\nhttps://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter\n\n### 三、分布式锁\n使用Redis来实现分布式锁，大家所熟知的SET NX命令，存在以下问题：\n1. 不可重入：同一个线程无法多次获取同一把锁；\n2. 不可重试：只能操作获取锁一次，失败无法重试；\n3. 超时释放：如果业务耗时较长，超过失效时间会自动释放锁，此时其他线程可以获取到锁，破坏了唯一性(同一时间，只有一个线程获取到锁)；\n\n从源码的角度，来分析一下Redisson是如何解决这些问题的。\n#### 1.可重入机制\n从 redissonClient的tryLock()方法源码一路跟踪，tryLockInnerAsync()方法的实现代码如下：\n```\n<T> RFuture<T> tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {  \n    return commandExecutor.syncedEval(getRawName(), LongCodec.INSTANCE, command,  \n        \"if ((redis.call('exists', KEYS[1]) == 0) \" +  \n        \"or (redis.call('hexists', KEYS[1], ARGV[2]) == 1)) then \" +  \n        \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" +  \n        \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +  \n        \"return nil; \" +  \n        \"end; \" +  \n        \"return redis.call('pttl', KEYS[1]);\",  \n    Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));  \n}\n\nprotected RFuture<Boolean> unlockInnerAsync(long threadId) {  \n    return evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,  \n        \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" +  \n        \"return nil;\" +  \n        \"end; \" +  \n        \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" +  \n        \"if (counter > 0) then \" +  \n        \"redis.call('pexpire', KEYS[1], ARGV[2]); \" +  \n        \"return 0; \" +  \n        \"else \" +  \n        \"redis.call('del', KEYS[1]); \" +  \n        \"redis.call(ARGV[4], KEYS[2], ARGV[1]); \" +  \n        \"return 1; \" +  \n        \"end; \" +  \n        \"return nil;\",  \n    Arrays.asList(getRawName(), getChannelName()),  \n    LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId), getSubscribeService().getPublishCommand());  \n}\n```\n这里用到了Lua脚本，判断key不存在或者存在且等于当前线程id时，使用了Hash结构来记录重入的次数，实现思路类似于ReentrantLock。而在解锁时，从unlockInnerAsync()方法中可以看到，对重入次数进行了减1操作，并且推送了订阅事件。因此可以得知进行了N次加锁后，需要操作N次解锁，才能释放锁。\n#### 2.失败重试机制\n在tryLock()方法中，返回值ttl为空时说明已经成功获取到锁，失败的情况会先判断是否已经超时，如果没有超时则会通过subscribe()方法进行订阅锁事件，当锁被释放时会再次尝试获取。\n```\n@Override\npublic boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException {\n    long time = unit.toMillis(waitTime);\n    long current = System.currentTimeMillis();\n    long threadId = Thread.currentThread().getId();\n    Long ttl = tryAcquire(waitTime, leaseTime, unit, threadId);\n    // lock acquired\n    if (ttl == null) {\n        return true;\n    }\n    \n    time -= System.currentTimeMillis() - current;\n    if (time <= 0) {\n        acquireFailed(waitTime, unit, threadId);\n        return false;\n    }\n\n    current = System.currentTimeMillis();\n    CompletableFuture<RedissonLockEntry> subscribeFuture = subscribe(threadId);\n    try {\n        subscribeFuture.get(time, TimeUnit.MILLISECONDS);\n    } catch (TimeoutException e) {\n        if (!subscribeFuture.completeExceptionally(new RedisTimeoutException(\n                \"Unable to acquire subscription lock after \" + time + \"ms. \" +\n                        \"Try to increase 'subscriptionsPerConnection' and/or 'subscriptionConnectionPoolSize' parameters.\"))) {\n            subscribeFuture.whenComplete((res, ex) -> {\n                if (ex == null) {\n                    unsubscribe(res, threadId);\n                }\n            });\n        }\n        acquireFailed(waitTime, unit, threadId);\n        return false;\n    } catch (ExecutionException e) {\n        acquireFailed(waitTime, unit, threadId);\n        return false;\n    }\n}    \n```\n#### 3.解决超时释放问题\n在文档的分布式锁章节，每一种类型的锁都有以下描述：\n> If Redisson instance which acquired lock crashes then such lock could hang forever in acquired state. To avoid this Redisson maintains lock watchdog, it prolongs lock expiration while lock holder Redisson instance is alive. By default lock watchdog timeout is 30 seconds and can be changed through [Config.lockWatchdogTimeout](https://github.com/redisson/redisson/wiki/2.-Configuration#lockwatchdogtimeout) setting.\n\nRession引入了wathdog机制，在锁持有者Redisson实例处于活动状态时，延长锁的过期时间，默认情况下，锁定看门狗的超时时间为30s。\n从tryLock()方法的源码追踪，在tryAcquireAsync()方法中进行了定时延长有效期的操作。\n\n```\nprivate RFuture<Long> tryAcquireAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId) {\n    RFuture<Long> ttlRemainingFuture;\n    if (leaseTime > 0) {\n        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);\n    } else {\n        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,\n                TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);\n    }\n    CompletionStage<Long> s = handleNoSync(threadId, ttlRemainingFuture);\n    ttlRemainingFuture = new CompletableFutureWrapper<>(s);\n\n    CompletionStage<Long> f = ttlRemainingFuture.thenApply(ttlRemaining -> {\n        // lock acquired\n        if (ttlRemaining == null) {\n            if (leaseTime > 0) {\n                internalLockLeaseTime = unit.toMillis(leaseTime);\n            } else {\n                scheduleExpirationRenewal(threadId);\n            }\n        }\n        return ttlRemaining;\n    });\n    return new CompletableFutureWrapper<>(f);\n}\n```\n通过scheduleExpirationRenewal()方法设置定时任务，底层是基于Netty的HashedWheelTimer时间轮函数，这里就不展开讨论了，感兴趣的话可以去翻翻源码。\n### 四、总结\nRedisson分布式锁的实现原理：\n- 可重入：记录线程id和重入次数；\n- 可重试：利用订阅功能实现等待、唤醒机制，达到失败重试的目的；\n- 延长有效期：使用watchdog方式，通过定时任务延长有效期。\n\n","slug":"Redis实战之搞懂Redisson分布式锁机制","published":1,"updated":"2024-01-30T10:01:43.309Z","_id":"cls06n7q70005iocqc8ak8mbz","comments":1,"layout":"post","photos":[],"content":"<h3 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h3><p>Redisson是什么？以下是官网的简介，相信各位彦祖们都能看懂，就不翻译了。</p>\n<blockquote>\n<p>Redisson is a Redis Java client with features of In-Memory Data Grid. It provides more convenient and easiest way to work with Redis. Redisson objects provides a separation of concern, which allows you to keep focus on the data modeling and application logic.</p>\n</blockquote>\n<p>作为Redis广受欢迎的客户端，Redisson具有以下特性：</p>\n<ul>\n<li>线程安全的实现；</li>\n<li>支持多种Redis种模式，集群模式、哨兵模式、主从模式、单机模式等；</li>\n<li>支持主动重连、失败自动重试；</li>\n<li>丰富的数据类型：Object, Binary stream, BitSet, AtomicLong, Bloom filter, Map, Set, List, SortedSet, Queue, Deque等；</li>\n<li>多样化的锁结构：Lock, FairLock, MultiLock, RedLock, ReadWriteLock, Semaphore, CountDownLatch等;</li>\n<li>异步API实现：Asynchronous、RxJava3、Reactive Streams；</li>\n<li>Spring生态支持：Spring Cache、Spring Transaction API、Spring Data Redis、Spring Boot Starter、Spring Session；</li>\n</ul>\n<h3 id=\"二、使用方式\"><a href=\"#二、使用方式\" class=\"headerlink\" title=\"二、使用方式\"></a>二、使用方式</h3><h4 id=\"1-基本使用\"><a href=\"#1-基本使用\" class=\"headerlink\" title=\"1.基本使用\"></a>1.基本使用</h4><p>基本使用方法和API，官方文档有比较详细的描述，就不多加赘述了。<br><a href=\"https://github.com/redisson/redisson/wiki/Table-of-Content\">https://github.com/redisson/redisson/wiki/Table-of-Content</a></p>\n<h4 id=\"2-与Spring-Boot集成\"><a href=\"#2-与Spring-Boot集成\" class=\"headerlink\" title=\"2.与Spring Boot集成\"></a>2.与Spring Boot集成</h4><p>在实例化Bean的方式上、配置文件格式上有些许区别，文档有具体介绍。<br><a href=\"https://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter\">https://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter</a></p>\n<h3 id=\"三、分布式锁\"><a href=\"#三、分布式锁\" class=\"headerlink\" title=\"三、分布式锁\"></a>三、分布式锁</h3><p>使用Redis来实现分布式锁，大家所熟知的SET NX命令，存在以下问题：</p>\n<ol>\n<li>不可重入：同一个线程无法多次获取同一把锁；</li>\n<li>不可重试：只能操作获取锁一次，失败无法重试；</li>\n<li>超时释放：如果业务耗时较长，超过失效时间会自动释放锁，此时其他线程可以获取到锁，破坏了唯一性(同一时间，只有一个线程获取到锁)；</li>\n</ol>\n<p>从源码的角度，来分析一下Redisson是如何解决这些问题的。</p>\n<h4 id=\"1-可重入机制\"><a href=\"#1-可重入机制\" class=\"headerlink\" title=\"1.可重入机制\"></a>1.可重入机制</h4><p>从 redissonClient的tryLock()方法源码一路跟踪，tryLockInnerAsync()方法的实现代码如下：</p>\n<figure class=\"highlight scilab\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs scilab\">&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123;  <br>    <span class=\"hljs-keyword\">return</span> commandExecutor.syncedEval(getRawName(), LongCodec.INSTANCE, command,  <br>        <span class=\"hljs-string\">&quot;if ((redis.call(&#x27;</span>exists&#x27;, KEYS[<span class=\"hljs-number\">1</span>]) == <span class=\"hljs-number\">0</span>) <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-built_in\">or</span> (redis.call(<span class=\"hljs-string\">&#x27;hexists&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">2</span>]) == <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">then</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;hincrby&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">2</span>], <span class=\"hljs-number\">1</span>); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;pexpire&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">1</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> nil; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">end</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> redis.call(<span class=\"hljs-string\">&#x27;pttl&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>]);<span class=\"hljs-string\">&quot;,  </span><br><span class=\"hljs-string\">    Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));  </span><br><span class=\"hljs-string\">&#125;</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123;  </span><br><span class=\"hljs-string\">    return evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">if</span> (redis.call(<span class=\"hljs-string\">&#x27;hexists&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">3</span>]) == <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">then</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> nil;<span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">end</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>local counter = redis.call(<span class=\"hljs-string\">&#x27;hincrby&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">3</span>], <span class=\"hljs-number\">-1</span>); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">if</span> (counter &gt; <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">then</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;pexpire&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">2</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;del&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(ARGV[<span class=\"hljs-number\">4</span>], KEYS[<span class=\"hljs-number\">2</span>], ARGV[<span class=\"hljs-number\">1</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">end</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> nil;<span class=\"hljs-string\">&quot;,  </span><br><span class=\"hljs-string\">    Arrays.asList(getRawName(), getChannelName()),  </span><br><span class=\"hljs-string\">    LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId), getSubscribeService().getPublishCommand());  </span><br><span class=\"hljs-string\">&#125;</span><br></code></pre></td></tr></table></figure>\n<p>这里用到了Lua脚本，判断key不存在或者存在且等于当前线程id时，使用了Hash结构来记录重入的次数，实现思路类似于ReentrantLock。而在解锁时，从unlockInnerAsync()方法中可以看到，对重入次数进行了减1操作，并且推送了订阅事件。因此可以得知进行了N次加锁后，需要操作N次解锁，才能释放锁。</p>\n<h4 id=\"2-失败重试机制\"><a href=\"#2-失败重试机制\" class=\"headerlink\" title=\"2.失败重试机制\"></a>2.失败重试机制</h4><p>在tryLock()方法中，返回值ttl为空时说明已经成功获取到锁，失败的情况会先判断是否已经超时，如果没有超时则会通过subscribe()方法进行订阅锁事件，当锁被释放时会再次尝试获取。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-meta\">@Override</span><br><span class=\"hljs-keyword\">public</span> <span class=\"hljs-type\">boolean</span> <span class=\"hljs-title function_\">tryLock</span><span class=\"hljs-params\">(<span class=\"hljs-type\">long</span> waitTime, <span class=\"hljs-type\">long</span> leaseTime, TimeUnit unit)</span> <span class=\"hljs-keyword\">throws</span> InterruptedException &#123;<br>    <span class=\"hljs-type\">long</span> <span class=\"hljs-variable\">time</span> <span class=\"hljs-operator\">=</span> unit.toMillis(waitTime);<br>    <span class=\"hljs-type\">long</span> <span class=\"hljs-variable\">current</span> <span class=\"hljs-operator\">=</span> System.currentTimeMillis();<br>    <span class=\"hljs-type\">long</span> <span class=\"hljs-variable\">threadId</span> <span class=\"hljs-operator\">=</span> Thread.currentThread().getId();<br>    <span class=\"hljs-type\">Long</span> <span class=\"hljs-variable\">ttl</span> <span class=\"hljs-operator\">=</span> tryAcquire(waitTime, leaseTime, unit, threadId);<br>    <span class=\"hljs-comment\">// lock acquired</span><br>    <span class=\"hljs-keyword\">if</span> (ttl == <span class=\"hljs-literal\">null</span>) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>    <br>    time -= System.currentTimeMillis() - current;<br>    <span class=\"hljs-keyword\">if</span> (time &lt;= <span class=\"hljs-number\">0</span>) &#123;<br>        acquireFailed(waitTime, unit, threadId);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125;<br><br>    current = System.currentTimeMillis();<br>    CompletableFuture&lt;RedissonLockEntry&gt; subscribeFuture = subscribe(threadId);<br>    <span class=\"hljs-keyword\">try</span> &#123;<br>        subscribeFuture.get(time, TimeUnit.MILLISECONDS);<br>    &#125; <span class=\"hljs-keyword\">catch</span> (TimeoutException e) &#123;<br>        <span class=\"hljs-keyword\">if</span> (!subscribeFuture.completeExceptionally(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">RedisTimeoutException</span>(<br>                <span class=\"hljs-string\">&quot;Unable to acquire subscription lock after &quot;</span> + time + <span class=\"hljs-string\">&quot;ms. &quot;</span> +<br>                        <span class=\"hljs-string\">&quot;Try to increase &#x27;subscriptionsPerConnection&#x27; and/or &#x27;subscriptionConnectionPoolSize&#x27; parameters.&quot;</span>))) &#123;<br>            subscribeFuture.whenComplete((res, ex) -&gt; &#123;<br>                <span class=\"hljs-keyword\">if</span> (ex == <span class=\"hljs-literal\">null</span>) &#123;<br>                    unsubscribe(res, threadId);<br>                &#125;<br>            &#125;);<br>        &#125;<br>        acquireFailed(waitTime, unit, threadId);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125; <span class=\"hljs-keyword\">catch</span> (ExecutionException e) &#123;<br>        acquireFailed(waitTime, unit, threadId);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125;<br>&#125;    <br></code></pre></td></tr></table></figure>\n<h4 id=\"3-解决超时释放问题\"><a href=\"#3-解决超时释放问题\" class=\"headerlink\" title=\"3.解决超时释放问题\"></a>3.解决超时释放问题</h4><p>在文档的分布式锁章节，每一种类型的锁都有以下描述：</p>\n<blockquote>\n<p>If Redisson instance which acquired lock crashes then such lock could hang forever in acquired state. To avoid this Redisson maintains lock watchdog, it prolongs lock expiration while lock holder Redisson instance is alive. By default lock watchdog timeout is 30 seconds and can be changed through <a href=\"https://github.com/redisson/redisson/wiki/2.-Configuration#lockwatchdogtimeout\">Config.lockWatchdogTimeout</a> setting.</p>\n</blockquote>\n<p>Ression引入了wathdog机制，在锁持有者Redisson实例处于活动状态时，延长锁的过期时间，默认情况下，锁定看门狗的超时时间为30s。<br>从tryLock()方法的源码追踪，在tryAcquireAsync()方法中进行了定时延长有效期的操作。</p>\n<figure class=\"highlight gradle\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gradle\"><span class=\"hljs-keyword\">private</span> RFuture&lt;<span class=\"hljs-keyword\">Long</span>&gt; tryAcquireAsync(<span class=\"hljs-keyword\">long</span> waitTime, <span class=\"hljs-keyword\">long</span> leaseTime, TimeUnit unit, <span class=\"hljs-keyword\">long</span> threadId) &#123;<br>    RFuture&lt;<span class=\"hljs-keyword\">Long</span>&gt; ttlRemainingFuture;<br>    <span class=\"hljs-keyword\">if</span> (leaseTime &gt; <span class=\"hljs-number\">0</span>) &#123;<br>        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);<br>    &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,<br>                TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);<br>    &#125;<br>    CompletionStage&lt;<span class=\"hljs-keyword\">Long</span>&gt; s = handleNoSync(threadId, ttlRemainingFuture);<br>    ttlRemainingFuture = <span class=\"hljs-keyword\">new</span> CompletableFutureWrapper&lt;&gt;(s);<br><br>    CompletionStage&lt;<span class=\"hljs-keyword\">Long</span>&gt; f = ttlRemainingFuture.thenApply(ttlRemaining -&gt; &#123;<br>        <span class=\"hljs-comment\">// lock acquired</span><br>        <span class=\"hljs-keyword\">if</span> (ttlRemaining == <span class=\"hljs-keyword\">null</span>) &#123;<br>            <span class=\"hljs-keyword\">if</span> (leaseTime &gt; <span class=\"hljs-number\">0</span>) &#123;<br>                internalLockLeaseTime = unit.toMillis(leaseTime);<br>            &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>                scheduleExpirationRenewal(threadId);<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> ttlRemaining;<br>    &#125;);<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> CompletableFutureWrapper&lt;&gt;(f);<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>通过scheduleExpirationRenewal()方法设置定时任务，底层是基于Netty的HashedWheelTimer时间轮函数，这里就不展开讨论了，感兴趣的话可以去翻翻源码。</p>\n<h3 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h3><p>Redisson分布式锁的实现原理：</p>\n<ul>\n<li>可重入：记录线程id和重入次数；</li>\n<li>可重试：利用订阅功能实现等待、唤醒机制，达到失败重试的目的；</li>\n<li>延长有效期：使用watchdog方式，通过定时任务延长有效期。</li>\n</ul>\n","excerpt":"","more":"<h3 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h3><p>Redisson是什么？以下是官网的简介，相信各位彦祖们都能看懂，就不翻译了。</p>\n<blockquote>\n<p>Redisson is a Redis Java client with features of In-Memory Data Grid. It provides more convenient and easiest way to work with Redis. Redisson objects provides a separation of concern, which allows you to keep focus on the data modeling and application logic.</p>\n</blockquote>\n<p>作为Redis广受欢迎的客户端，Redisson具有以下特性：</p>\n<ul>\n<li>线程安全的实现；</li>\n<li>支持多种Redis种模式，集群模式、哨兵模式、主从模式、单机模式等；</li>\n<li>支持主动重连、失败自动重试；</li>\n<li>丰富的数据类型：Object, Binary stream, BitSet, AtomicLong, Bloom filter, Map, Set, List, SortedSet, Queue, Deque等；</li>\n<li>多样化的锁结构：Lock, FairLock, MultiLock, RedLock, ReadWriteLock, Semaphore, CountDownLatch等;</li>\n<li>异步API实现：Asynchronous、RxJava3、Reactive Streams；</li>\n<li>Spring生态支持：Spring Cache、Spring Transaction API、Spring Data Redis、Spring Boot Starter、Spring Session；</li>\n</ul>\n<h3 id=\"二、使用方式\"><a href=\"#二、使用方式\" class=\"headerlink\" title=\"二、使用方式\"></a>二、使用方式</h3><h4 id=\"1-基本使用\"><a href=\"#1-基本使用\" class=\"headerlink\" title=\"1.基本使用\"></a>1.基本使用</h4><p>基本使用方法和API，官方文档有比较详细的描述，就不多加赘述了。<br><a href=\"https://github.com/redisson/redisson/wiki/Table-of-Content\">https://github.com/redisson/redisson/wiki/Table-of-Content</a></p>\n<h4 id=\"2-与Spring-Boot集成\"><a href=\"#2-与Spring-Boot集成\" class=\"headerlink\" title=\"2.与Spring Boot集成\"></a>2.与Spring Boot集成</h4><p>在实例化Bean的方式上、配置文件格式上有些许区别，文档有具体介绍。<br><a href=\"https://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter\">https://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter</a></p>\n<h3 id=\"三、分布式锁\"><a href=\"#三、分布式锁\" class=\"headerlink\" title=\"三、分布式锁\"></a>三、分布式锁</h3><p>使用Redis来实现分布式锁，大家所熟知的SET NX命令，存在以下问题：</p>\n<ol>\n<li>不可重入：同一个线程无法多次获取同一把锁；</li>\n<li>不可重试：只能操作获取锁一次，失败无法重试；</li>\n<li>超时释放：如果业务耗时较长，超过失效时间会自动释放锁，此时其他线程可以获取到锁，破坏了唯一性(同一时间，只有一个线程获取到锁)；</li>\n</ol>\n<p>从源码的角度，来分析一下Redisson是如何解决这些问题的。</p>\n<h4 id=\"1-可重入机制\"><a href=\"#1-可重入机制\" class=\"headerlink\" title=\"1.可重入机制\"></a>1.可重入机制</h4><p>从 redissonClient的tryLock()方法源码一路跟踪，tryLockInnerAsync()方法的实现代码如下：</p>\n<figure class=\"highlight scilab\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs scilab\">&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123;  <br>    <span class=\"hljs-keyword\">return</span> commandExecutor.syncedEval(getRawName(), LongCodec.INSTANCE, command,  <br>        <span class=\"hljs-string\">&quot;if ((redis.call(&#x27;</span>exists&#x27;, KEYS[<span class=\"hljs-number\">1</span>]) == <span class=\"hljs-number\">0</span>) <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-built_in\">or</span> (redis.call(<span class=\"hljs-string\">&#x27;hexists&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">2</span>]) == <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">then</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;hincrby&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">2</span>], <span class=\"hljs-number\">1</span>); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;pexpire&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">1</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> nil; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">end</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> redis.call(<span class=\"hljs-string\">&#x27;pttl&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>]);<span class=\"hljs-string\">&quot;,  </span><br><span class=\"hljs-string\">    Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));  </span><br><span class=\"hljs-string\">&#125;</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123;  </span><br><span class=\"hljs-string\">    return evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">if</span> (redis.call(<span class=\"hljs-string\">&#x27;hexists&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">3</span>]) == <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">then</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> nil;<span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">end</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>local counter = redis.call(<span class=\"hljs-string\">&#x27;hincrby&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">3</span>], <span class=\"hljs-number\">-1</span>); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">if</span> (counter &gt; <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">then</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;pexpire&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>], ARGV[<span class=\"hljs-number\">2</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(<span class=\"hljs-string\">&#x27;del&#x27;</span>, KEYS[<span class=\"hljs-number\">1</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span>redis.call(ARGV[<span class=\"hljs-number\">4</span>], KEYS[<span class=\"hljs-number\">2</span>], ARGV[<span class=\"hljs-number\">1</span>]); <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">end</span>; <span class=\"hljs-string\">&quot; +  </span><br><span class=\"hljs-string\">        &quot;</span><span class=\"hljs-keyword\">return</span> nil;<span class=\"hljs-string\">&quot;,  </span><br><span class=\"hljs-string\">    Arrays.asList(getRawName(), getChannelName()),  </span><br><span class=\"hljs-string\">    LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId), getSubscribeService().getPublishCommand());  </span><br><span class=\"hljs-string\">&#125;</span><br></code></pre></td></tr></table></figure>\n<p>这里用到了Lua脚本，判断key不存在或者存在且等于当前线程id时，使用了Hash结构来记录重入的次数，实现思路类似于ReentrantLock。而在解锁时，从unlockInnerAsync()方法中可以看到，对重入次数进行了减1操作，并且推送了订阅事件。因此可以得知进行了N次加锁后，需要操作N次解锁，才能释放锁。</p>\n<h4 id=\"2-失败重试机制\"><a href=\"#2-失败重试机制\" class=\"headerlink\" title=\"2.失败重试机制\"></a>2.失败重试机制</h4><p>在tryLock()方法中，返回值ttl为空时说明已经成功获取到锁，失败的情况会先判断是否已经超时，如果没有超时则会通过subscribe()方法进行订阅锁事件，当锁被释放时会再次尝试获取。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-meta\">@Override</span><br><span class=\"hljs-keyword\">public</span> <span class=\"hljs-type\">boolean</span> <span class=\"hljs-title function_\">tryLock</span><span class=\"hljs-params\">(<span class=\"hljs-type\">long</span> waitTime, <span class=\"hljs-type\">long</span> leaseTime, TimeUnit unit)</span> <span class=\"hljs-keyword\">throws</span> InterruptedException &#123;<br>    <span class=\"hljs-type\">long</span> <span class=\"hljs-variable\">time</span> <span class=\"hljs-operator\">=</span> unit.toMillis(waitTime);<br>    <span class=\"hljs-type\">long</span> <span class=\"hljs-variable\">current</span> <span class=\"hljs-operator\">=</span> System.currentTimeMillis();<br>    <span class=\"hljs-type\">long</span> <span class=\"hljs-variable\">threadId</span> <span class=\"hljs-operator\">=</span> Thread.currentThread().getId();<br>    <span class=\"hljs-type\">Long</span> <span class=\"hljs-variable\">ttl</span> <span class=\"hljs-operator\">=</span> tryAcquire(waitTime, leaseTime, unit, threadId);<br>    <span class=\"hljs-comment\">// lock acquired</span><br>    <span class=\"hljs-keyword\">if</span> (ttl == <span class=\"hljs-literal\">null</span>) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>    <br>    time -= System.currentTimeMillis() - current;<br>    <span class=\"hljs-keyword\">if</span> (time &lt;= <span class=\"hljs-number\">0</span>) &#123;<br>        acquireFailed(waitTime, unit, threadId);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125;<br><br>    current = System.currentTimeMillis();<br>    CompletableFuture&lt;RedissonLockEntry&gt; subscribeFuture = subscribe(threadId);<br>    <span class=\"hljs-keyword\">try</span> &#123;<br>        subscribeFuture.get(time, TimeUnit.MILLISECONDS);<br>    &#125; <span class=\"hljs-keyword\">catch</span> (TimeoutException e) &#123;<br>        <span class=\"hljs-keyword\">if</span> (!subscribeFuture.completeExceptionally(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">RedisTimeoutException</span>(<br>                <span class=\"hljs-string\">&quot;Unable to acquire subscription lock after &quot;</span> + time + <span class=\"hljs-string\">&quot;ms. &quot;</span> +<br>                        <span class=\"hljs-string\">&quot;Try to increase &#x27;subscriptionsPerConnection&#x27; and/or &#x27;subscriptionConnectionPoolSize&#x27; parameters.&quot;</span>))) &#123;<br>            subscribeFuture.whenComplete((res, ex) -&gt; &#123;<br>                <span class=\"hljs-keyword\">if</span> (ex == <span class=\"hljs-literal\">null</span>) &#123;<br>                    unsubscribe(res, threadId);<br>                &#125;<br>            &#125;);<br>        &#125;<br>        acquireFailed(waitTime, unit, threadId);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125; <span class=\"hljs-keyword\">catch</span> (ExecutionException e) &#123;<br>        acquireFailed(waitTime, unit, threadId);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125;<br>&#125;    <br></code></pre></td></tr></table></figure>\n<h4 id=\"3-解决超时释放问题\"><a href=\"#3-解决超时释放问题\" class=\"headerlink\" title=\"3.解决超时释放问题\"></a>3.解决超时释放问题</h4><p>在文档的分布式锁章节，每一种类型的锁都有以下描述：</p>\n<blockquote>\n<p>If Redisson instance which acquired lock crashes then such lock could hang forever in acquired state. To avoid this Redisson maintains lock watchdog, it prolongs lock expiration while lock holder Redisson instance is alive. By default lock watchdog timeout is 30 seconds and can be changed through <a href=\"https://github.com/redisson/redisson/wiki/2.-Configuration#lockwatchdogtimeout\">Config.lockWatchdogTimeout</a> setting.</p>\n</blockquote>\n<p>Ression引入了wathdog机制，在锁持有者Redisson实例处于活动状态时，延长锁的过期时间，默认情况下，锁定看门狗的超时时间为30s。<br>从tryLock()方法的源码追踪，在tryAcquireAsync()方法中进行了定时延长有效期的操作。</p>\n<figure class=\"highlight gradle\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gradle\"><span class=\"hljs-keyword\">private</span> RFuture&lt;<span class=\"hljs-keyword\">Long</span>&gt; tryAcquireAsync(<span class=\"hljs-keyword\">long</span> waitTime, <span class=\"hljs-keyword\">long</span> leaseTime, TimeUnit unit, <span class=\"hljs-keyword\">long</span> threadId) &#123;<br>    RFuture&lt;<span class=\"hljs-keyword\">Long</span>&gt; ttlRemainingFuture;<br>    <span class=\"hljs-keyword\">if</span> (leaseTime &gt; <span class=\"hljs-number\">0</span>) &#123;<br>        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);<br>    &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,<br>                TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);<br>    &#125;<br>    CompletionStage&lt;<span class=\"hljs-keyword\">Long</span>&gt; s = handleNoSync(threadId, ttlRemainingFuture);<br>    ttlRemainingFuture = <span class=\"hljs-keyword\">new</span> CompletableFutureWrapper&lt;&gt;(s);<br><br>    CompletionStage&lt;<span class=\"hljs-keyword\">Long</span>&gt; f = ttlRemainingFuture.thenApply(ttlRemaining -&gt; &#123;<br>        <span class=\"hljs-comment\">// lock acquired</span><br>        <span class=\"hljs-keyword\">if</span> (ttlRemaining == <span class=\"hljs-keyword\">null</span>) &#123;<br>            <span class=\"hljs-keyword\">if</span> (leaseTime &gt; <span class=\"hljs-number\">0</span>) &#123;<br>                internalLockLeaseTime = unit.toMillis(leaseTime);<br>            &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>                scheduleExpirationRenewal(threadId);<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> ttlRemaining;<br>    &#125;);<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> CompletableFutureWrapper&lt;&gt;(f);<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>通过scheduleExpirationRenewal()方法设置定时任务，底层是基于Netty的HashedWheelTimer时间轮函数，这里就不展开讨论了，感兴趣的话可以去翻翻源码。</p>\n<h3 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h3><p>Redisson分布式锁的实现原理：</p>\n<ul>\n<li>可重入：记录线程id和重入次数；</li>\n<li>可重试：利用订阅功能实现等待、唤醒机制，达到失败重试的目的；</li>\n<li>延长有效期：使用watchdog方式，通过定时任务延长有效期。</li>\n</ul>\n"},{"title":"高性能MySQL的实现策略","date":"2023-03-19T16:00:00.000Z","_content":"\n## 1.基础架构\n\n![在这里插入图片描述](/img_convert/1.png)\n\n\n### 1.1.网络连接层\n\n位于最上层的客户端服务，包括连接处理、身份验证等功能，支持多种服务端语言，通过 API 接口与 MySQL 建立连接。\n\n---\n\n### 1.2.数据库服务层\n\nMySQL 的核心功能都在这一层，包括查询解析、分析、优化，以及所有的内置函数(例如:日期、数学函数)，所有跨存储引擎的功能也都在这一层实现：存储过程、触发器、视图等。\n\n**1.2.1.连接管理:**\n\n每个客户端连接都会在服务器进程中拥有一个线程，该连接的查询只会在这个单独的线程中执行，该进程驻留在内核或者 CPU 上。服务器维护了一个缓冲区，作为连接池，存储已就绪的线程。\n\n**1.2.2.优化与执行:**\n\nMySQL 解析查询以创建解析树，然后对其进行各种优化，包括重写查询，决定表的读取顺序，以及选择合适的索引等。\n\n---\n\n### 1.3.存储引擎层\n\n存储引擎负责 MySQL 中数据的存储和提取，服务器通过存储引擎 API 进行通信。这些 API 屏蔽了不同存储引擎之间的差异，使得它们对上面的查询层基本上是透明的。最常用的存储引擎是 InnoDB。\n\n---\n\n### 1.4.系统文件层\n\n**1.4.1.binlog**\n\n- binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用，用于归档；\n- binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”；binlog 是可以追加写入的，不会覆盖之前的日志；\n\n**1.4..2.redo log**\n\n- redo log 是 InnoDB 引擎实现的，用于 Write-Ahead Logging(提升效率)、crash-safe(故障恢复)；\n- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；redo log 是循环写的，空间固定会用完；\n\n**1.4..3.undo log**\n\n- undo log 提供了回滚和多版本控制(MVCC)功能；\n- unlo log 用于存放数据被修改之前的值；\n\n---\n\n## 2.Schema 设计\n\n### 2.1.数据类型选择\n\n- 更小的通常更好：尽可能使用能够正确存储和表示数据的最小数据类型。更小的数据类型通常更快，因为它们占用的磁盘、内存和 CPU 缓存的空间更少，并且处理时需要的 CPU 周期也更少；\n- 简单为好：简单数据类型的操作通常需要更少的 CPU 周期。例如，整型数据比字符型数据的比较操作代价更低（因为字符集和排序规则使得字符型数据的比较更加复杂）；应该将日期和时间存储为 MySQL 的内置类型而非字符串类型；\n- 尽量避免存储 NULL：通常情况下最好指定列为 NOT NULL，除非明确需要存储 NULL 值。因为可为 NULL 的列，对 MySQL 来说更难优化，在索引、索引统计和值比较时都更复杂；在存储时需要特殊处理，会占用更多的存储空间；（在调优时通常没有必要将可为 NULL 的列改成 NOT NULL，带来的性能提升比较小）\n\n---\n\n### 2.2.整数类型\n\n整数的类型有：TINYINT、SMALLINT、MEDIUMINT、INT 和 BIGINT，分别使用 8、16、24、32、和 64 位存储空间，可以存储的值的范围从 -2 的(n-1)次方到 2 的(n-1)次方-1，其中 n 是存储空间的位数。\n\n整数类型有可选的 UNSIGNED 属性，表示不允许负值，大致上可以使正整数的上限提高一倍。\n\nMySQL 可以为整数类型指定宽度，只是规定了 MySQL 的客户端显示字符的个数，不会限制值的合法范围。\n\n---\n\n### 2.3.实数类型\n\n实数是带有小数部分的数字。也可以使用 DECIMAL 存储比 BIGINT 还大的整数，MySQL 既支持精确类型，也支持不精确类型。\n\nFLOAT 和 DOUBLE 类型支持使用标准的浮点运算进行近似计算。FLOAT 列使用 4 字节的存储空间，DOUBLE 占用 8 字节。\n\nDECIMAL 需要额外的存储空间和计算成本，尽量在对小数需要进行精确计算时进行使用，例如：存储财务数据。在一些大容量的场景，可以考虑使用 BIGINT 代替 DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可，可以避免浮点存储计算不精确和 DECIMAL 精确计算代价高的问题。\n\n---\n\n### 2.4.字符串类型\n\n**VARCHAR：**\n\n- 用于存储可变长度的字符串，比固定长度的类型更节省空间，因为它仅使用必要的空间；\n- 但是由于行是可变长度的，在更新时可能会增长，将导致额外的工作；\n- VARCHAR 需要额外使用 1 或者 2 字节记录字符串的长度；\n- 适用场景：字符串的最大长度远大于平均长度；列的更新很少；\n\n**CHAR：**\n\n- CHAR 是固定长度的，非常适合存储较短的字符串，或者所有值的长度都几乎相同的情况；\n- 对于经常修改的数据，CHAR 比 VARCHAR 更好，因为固定长度的行不容易出现碎片；\n\n**BLOB 和 TEXT 类型：**\n\n- BLOB 和 TEXT 类型是为了存储很大的数据而设计的字符串数据类型，分别采用二级制和字符串方式存储；\n- MySQL 将 BOLO 和 TEXT 值当作具有自己标识的对象来处理，内容太多时会使用外部存储区域；\n\n---\n\n### 2.5.日期和时间类型\n\n**DATETIME:**\n\n- 可以保存从 1000 年到 9999 年范围内的数值，精度为 1 微秒；\n- 以 YYYYMMDDHHMMSS 格式存储压缩成整数的日期和时间，与时区无关，需要 8 字节的存储空间；\n\n**TIMESTAMP：**\n\n- 与 UNIX 时间戳相同，存储自 1970 年 1 月 1 日以来经过的秒数，使用 4 字节存储空间，只能表示 1970 年 2038 年范围内的数据；\n- 时间戳显示的值依赖于时区，MySQL 服务器、操作系统和客户端连接都有时区设置；\n\n---\n\n### 2.6.JSON 数据类型\n\n- 相比较于 SQL 列，JSON 列需要占用过多的存储空间，有额外的字符需要存储；\n- 查询速度上，SQL 列也更占优势；是否使用 JSON，取决于在数据库中使用 JSON 的便捷性是否大于性能；\n\n---\n\n### 2.7.其他数据类型\n\n**BIT：**\n\n- 可以使用 BIT 列存储一个或者多个 true/false 值；在存储时不会节省任何存储空间；\n- MySQL 在处理时将 BIT 视为字符串类型，在数字上下文中进行数据比较时会转换为数字，得到非预期结果，使用时需要谨慎；\n- 建议使用 TINYINT 进行代替；\n\n**IP：**\n\n- IP 地址实际上是无符号整数，用小数点分隔只是为了方便阅读，因此应该将 IP 地址存储为无符合整数；\n- MySQL 提供了 INET_ATON()和 INET_NTOA()函数在这两种表达形式之间进行转换；\n\n---\n\n### 2.8.schema 管理\n\n如何在不影响数据库或者依赖它们的服务正常运行的情况下，进行 schema 的变更？\n\n**原生 DDL 语句：**\n\nMySQL 在 5.6 版本中引入了非阻塞的 schema 更改，对原生 DDL 的支持有限，在需要更改的表非常大时，可能会遇到回滚的情况。\n\n**外部的工具：**\n\n主要选择有 Percona 的 pt-online-schema-change 和 Github 的 gh-ost。实现原理是对正在更改的表进行完整的复制，执行完表结构变更，再把源表的全量数据和增量数据同步过去，最后进行表替换。\n\n---\n\n## 3.索引\n\n索引是存储引擎用于快速找到记录的一种数据结构。\n\n### 3.1.索引的类型\n\n**B-tree 索引：**\n\n- 是指使用 B-tree 数据结构来存储数据，在实际实现中，很多存储引擎使用的是 B+ Tree 索引；\n- B-tree 索引能够加快数据访问的速度，因为有了索引，在查询某些条件的数据时，不需要全表扫描；从索引的根节点根据子节点的指针，依次向下层开始查找；\n- B-tree 是按照索引列中的数据大小顺序存储的，非常适合按照范围进行查询；\n\n**自适应哈希索引：**\n\nInnoDB 存储引擎在发现某些索引值访问非常频繁时，会在原有 B-tree 索引之上，在内存中在构建一个哈希索引；\n\n**全文索引：**\n\nFULLTEXT 是一种特殊类型的索引，查找的是文本中的关键字，类似于搜索引擎；\n\n---\n\n### 3.2.B-tree 索引的使用\n\n**适用的查询类型：**\n\n- 全值匹配：和索引中的所有列匹配；\n- 匹配最左前缀：只使用第一列，或者前几列；\n- 匹配列前缀：只匹配某一列的值的开头部分；\n- 匹配范围值；\n- 精准匹配某一列而范围匹配另外一列；\n- 只访问索引的查询：查询只需要访问索引而无须访问数据行，也称之为覆盖索引；\n\n**索引排序：**\n\n- 因为索引树中的节点是有序的，除了按值查找，索引还可以用于查询中的 ORDER BY 操作；\n- 如果 ORDER BY 子句满足索引查询类型，则索引也可以用于这类的排序场景；\n\n**索引的限制：**\n\n- 不是按照索引的最左列开始查找，则无法使用索引；\n- 不能跳过索引中的列；\n- 如果查询中有某列的范围查询，则其右边所有列都无法使用索引优化查询；\n\n---\n\n### 3.3.索引的优点\n\n- 索引大大减少了服务器需要扫描的数据量；\n- 索引可以帮助服务器避免排序和临时表；\n- 索引可以将随机 I/O 变成顺序 I/O；\n\n---\n\n### 3.4.高性能的索引策略\n\n**前缀索引：**\n\n- 为了提升索引性能，节省索引空间，可以只对字段的前一部分字符进行索引；\n- 针对 BLOB、TEXT 或者很长的 VARCHAR 类型的列，只支持使用前缀索引。\n\n**索引的选择性：**\n\n是指不重复的值(也称之为基数)和数据表的总记录数(T)的比值，范围是 1/T 到 1 之间；索引的选择性越高则查询效率越高。\n\n**如何确定前缀索引的长度？**\n\n前缀索引的长度，既要足够长来保证较高的选择性，又不能太长(节省空间)；\n\n可以通过计算不同长度前缀和完整列，与总行数的比率，使用较接近的长度前缀；\n\n**多列索引：**\n\n索引的常见误区是为每列创建独立的索引，或者按照错误的顺序创建多列索引。\n\n**如何选择合适的索引列顺序：**\n\n根据经验法则：将选择性最高的列放到索引的最前列，在大部分场景下是有效的。\n\n但是索引性能不仅仅依赖于选择性，和查询条件的具体值，以及值的分布都有关，此时可以根据运行频率最高的查询来适当调整索引列的顺序。\n\n**聚簇索引：**\n\n聚簇索引是一种数据存储方式，InnoDB 的聚簇索引是在同一个结构中保存了 B-tree 索引和数据行。InnoDB 根据主键聚簇数据，如果没有定义主键，会选择唯一的非空索引代替，次之会隐式定义一个主键。\n\n**按主键顺序插入行：**\n\n如果 InnoDB 表中没有数据需要聚集，可以使用一个代理键来作为主键（例如 AUTO_INCREMENT 自增列），以保证数据行是按顺序写入的，来提升性能。\n\n随机的聚簇索引，例如 UUID 会使得数据没有任何聚集特性，插入也变得完全随机，应该尽量避免。\n\n**覆盖索引：**\n\n如果一个索引包含所有需要查询的字段的值，称之为覆盖索引。不需要回表查询，效率更高。\n\n**使用索引来排序：**\n\n只有当使用的顺序和 ORDER BY 子句的顺序完全一致，并且所有列的排序方向(顺序或者倒序)都一样时，MySQL 才能使用索引对结果进行排序。\n\n在 EXPLAIN 的输出结果中，type 列的值为”index”，说明 MySQL 使用了索引扫描来进行排序。\n\n---\n\n## 4.查询性能优化\n\n查询的生命周期，大致上可以分为：客户端连接到服务端，服务端进行语法解析，生成执行计划，执行，并给客户端返回结果。\n\n其中“执行”阶段是整个生命周期中最重要的阶段，包括大量为了检索数据对存储引擎的调用，以及调用后的数据处理(排序、分组等)。\n\n---\n\n### 4.1.优化数据访问\n\n**查询的数据是否过多：**\n\n- 查询了不需要的记录；\n- 多表连接时返回全部列；\n- 总数取出全部列；\n- 重复查询相同的数据；\n\n**MySQL 是否在扫描额外的记录：**\n\n- 扫描的行数和返回行数之间的比率；\n- 扫描的行数和访问类型：全表扫描、索引扫描、范围扫描、唯一索引查询，常数引用等；\n\n---\n\n### 4.2.重构查询的方式\n\n- 将复杂查询重构为多个简单查询；\n- 切分查询，每次只返回部分查询结果；\n- 分解连接查询；\n\n---\n\n### 4.3.查询状态\n\n- Sleep：线程正在等待客户端发送新的请求；\n- Query：线程正在执行查询或者正在将结果发送给客户端；\n- Locked：在 MySQL 服务器层，线程正在等待表锁；（存储引擎级别实现的锁，例如 InnoDB 的行锁，不会体现在线程状态中）\n- Analying and statistics：线程正在检查存储引擎的统计信息，并优化查询；\n- Copying to tmp table：线程正在执行查询，将结果复制到临时表中；\n- Sorting result：线程正在对结果集进行排序；\n\n---\n\n### 4.4.排序优化\n\n在不能使用索引生成排序结果的时候，MySQL 需要自己继续排序，数据量小则在内存中进行，数据量大则需要使用磁盘，在 MySQL 中统称文件排序。\n\n**排序的具体实现：**\n\n如果需要排序的数据量小于“排序缓存区”，MySQL 使用内存进行快速排序操作，如果内存不够排序，那么 MySQL 会先将数据分块，对每个独立的块使用快速排序，并将各个块的排序结果存放在磁盘上，然后将各个排好序的块进行合并，最后返回排序结果。\n\n在 MySQL 的 EXPLAIN 结果的 Extra 字段可以看到“Using temporary; Using filesort”字样，说明使用了临时表、文件进行排序。\n\n","source":"_posts/高性能MySQL的实现策略.md","raw":"---\ntitle: 高性能MySQL的实现策略 \ndate: 2023-03-20\n---\n\n## 1.基础架构\n\n![在这里插入图片描述](/img_convert/1.png)\n\n\n### 1.1.网络连接层\n\n位于最上层的客户端服务，包括连接处理、身份验证等功能，支持多种服务端语言，通过 API 接口与 MySQL 建立连接。\n\n---\n\n### 1.2.数据库服务层\n\nMySQL 的核心功能都在这一层，包括查询解析、分析、优化，以及所有的内置函数(例如:日期、数学函数)，所有跨存储引擎的功能也都在这一层实现：存储过程、触发器、视图等。\n\n**1.2.1.连接管理:**\n\n每个客户端连接都会在服务器进程中拥有一个线程，该连接的查询只会在这个单独的线程中执行，该进程驻留在内核或者 CPU 上。服务器维护了一个缓冲区，作为连接池，存储已就绪的线程。\n\n**1.2.2.优化与执行:**\n\nMySQL 解析查询以创建解析树，然后对其进行各种优化，包括重写查询，决定表的读取顺序，以及选择合适的索引等。\n\n---\n\n### 1.3.存储引擎层\n\n存储引擎负责 MySQL 中数据的存储和提取，服务器通过存储引擎 API 进行通信。这些 API 屏蔽了不同存储引擎之间的差异，使得它们对上面的查询层基本上是透明的。最常用的存储引擎是 InnoDB。\n\n---\n\n### 1.4.系统文件层\n\n**1.4.1.binlog**\n\n- binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用，用于归档；\n- binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”；binlog 是可以追加写入的，不会覆盖之前的日志；\n\n**1.4..2.redo log**\n\n- redo log 是 InnoDB 引擎实现的，用于 Write-Ahead Logging(提升效率)、crash-safe(故障恢复)；\n- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；redo log 是循环写的，空间固定会用完；\n\n**1.4..3.undo log**\n\n- undo log 提供了回滚和多版本控制(MVCC)功能；\n- unlo log 用于存放数据被修改之前的值；\n\n---\n\n## 2.Schema 设计\n\n### 2.1.数据类型选择\n\n- 更小的通常更好：尽可能使用能够正确存储和表示数据的最小数据类型。更小的数据类型通常更快，因为它们占用的磁盘、内存和 CPU 缓存的空间更少，并且处理时需要的 CPU 周期也更少；\n- 简单为好：简单数据类型的操作通常需要更少的 CPU 周期。例如，整型数据比字符型数据的比较操作代价更低（因为字符集和排序规则使得字符型数据的比较更加复杂）；应该将日期和时间存储为 MySQL 的内置类型而非字符串类型；\n- 尽量避免存储 NULL：通常情况下最好指定列为 NOT NULL，除非明确需要存储 NULL 值。因为可为 NULL 的列，对 MySQL 来说更难优化，在索引、索引统计和值比较时都更复杂；在存储时需要特殊处理，会占用更多的存储空间；（在调优时通常没有必要将可为 NULL 的列改成 NOT NULL，带来的性能提升比较小）\n\n---\n\n### 2.2.整数类型\n\n整数的类型有：TINYINT、SMALLINT、MEDIUMINT、INT 和 BIGINT，分别使用 8、16、24、32、和 64 位存储空间，可以存储的值的范围从 -2 的(n-1)次方到 2 的(n-1)次方-1，其中 n 是存储空间的位数。\n\n整数类型有可选的 UNSIGNED 属性，表示不允许负值，大致上可以使正整数的上限提高一倍。\n\nMySQL 可以为整数类型指定宽度，只是规定了 MySQL 的客户端显示字符的个数，不会限制值的合法范围。\n\n---\n\n### 2.3.实数类型\n\n实数是带有小数部分的数字。也可以使用 DECIMAL 存储比 BIGINT 还大的整数，MySQL 既支持精确类型，也支持不精确类型。\n\nFLOAT 和 DOUBLE 类型支持使用标准的浮点运算进行近似计算。FLOAT 列使用 4 字节的存储空间，DOUBLE 占用 8 字节。\n\nDECIMAL 需要额外的存储空间和计算成本，尽量在对小数需要进行精确计算时进行使用，例如：存储财务数据。在一些大容量的场景，可以考虑使用 BIGINT 代替 DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可，可以避免浮点存储计算不精确和 DECIMAL 精确计算代价高的问题。\n\n---\n\n### 2.4.字符串类型\n\n**VARCHAR：**\n\n- 用于存储可变长度的字符串，比固定长度的类型更节省空间，因为它仅使用必要的空间；\n- 但是由于行是可变长度的，在更新时可能会增长，将导致额外的工作；\n- VARCHAR 需要额外使用 1 或者 2 字节记录字符串的长度；\n- 适用场景：字符串的最大长度远大于平均长度；列的更新很少；\n\n**CHAR：**\n\n- CHAR 是固定长度的，非常适合存储较短的字符串，或者所有值的长度都几乎相同的情况；\n- 对于经常修改的数据，CHAR 比 VARCHAR 更好，因为固定长度的行不容易出现碎片；\n\n**BLOB 和 TEXT 类型：**\n\n- BLOB 和 TEXT 类型是为了存储很大的数据而设计的字符串数据类型，分别采用二级制和字符串方式存储；\n- MySQL 将 BOLO 和 TEXT 值当作具有自己标识的对象来处理，内容太多时会使用外部存储区域；\n\n---\n\n### 2.5.日期和时间类型\n\n**DATETIME:**\n\n- 可以保存从 1000 年到 9999 年范围内的数值，精度为 1 微秒；\n- 以 YYYYMMDDHHMMSS 格式存储压缩成整数的日期和时间，与时区无关，需要 8 字节的存储空间；\n\n**TIMESTAMP：**\n\n- 与 UNIX 时间戳相同，存储自 1970 年 1 月 1 日以来经过的秒数，使用 4 字节存储空间，只能表示 1970 年 2038 年范围内的数据；\n- 时间戳显示的值依赖于时区，MySQL 服务器、操作系统和客户端连接都有时区设置；\n\n---\n\n### 2.6.JSON 数据类型\n\n- 相比较于 SQL 列，JSON 列需要占用过多的存储空间，有额外的字符需要存储；\n- 查询速度上，SQL 列也更占优势；是否使用 JSON，取决于在数据库中使用 JSON 的便捷性是否大于性能；\n\n---\n\n### 2.7.其他数据类型\n\n**BIT：**\n\n- 可以使用 BIT 列存储一个或者多个 true/false 值；在存储时不会节省任何存储空间；\n- MySQL 在处理时将 BIT 视为字符串类型，在数字上下文中进行数据比较时会转换为数字，得到非预期结果，使用时需要谨慎；\n- 建议使用 TINYINT 进行代替；\n\n**IP：**\n\n- IP 地址实际上是无符号整数，用小数点分隔只是为了方便阅读，因此应该将 IP 地址存储为无符合整数；\n- MySQL 提供了 INET_ATON()和 INET_NTOA()函数在这两种表达形式之间进行转换；\n\n---\n\n### 2.8.schema 管理\n\n如何在不影响数据库或者依赖它们的服务正常运行的情况下，进行 schema 的变更？\n\n**原生 DDL 语句：**\n\nMySQL 在 5.6 版本中引入了非阻塞的 schema 更改，对原生 DDL 的支持有限，在需要更改的表非常大时，可能会遇到回滚的情况。\n\n**外部的工具：**\n\n主要选择有 Percona 的 pt-online-schema-change 和 Github 的 gh-ost。实现原理是对正在更改的表进行完整的复制，执行完表结构变更，再把源表的全量数据和增量数据同步过去，最后进行表替换。\n\n---\n\n## 3.索引\n\n索引是存储引擎用于快速找到记录的一种数据结构。\n\n### 3.1.索引的类型\n\n**B-tree 索引：**\n\n- 是指使用 B-tree 数据结构来存储数据，在实际实现中，很多存储引擎使用的是 B+ Tree 索引；\n- B-tree 索引能够加快数据访问的速度，因为有了索引，在查询某些条件的数据时，不需要全表扫描；从索引的根节点根据子节点的指针，依次向下层开始查找；\n- B-tree 是按照索引列中的数据大小顺序存储的，非常适合按照范围进行查询；\n\n**自适应哈希索引：**\n\nInnoDB 存储引擎在发现某些索引值访问非常频繁时，会在原有 B-tree 索引之上，在内存中在构建一个哈希索引；\n\n**全文索引：**\n\nFULLTEXT 是一种特殊类型的索引，查找的是文本中的关键字，类似于搜索引擎；\n\n---\n\n### 3.2.B-tree 索引的使用\n\n**适用的查询类型：**\n\n- 全值匹配：和索引中的所有列匹配；\n- 匹配最左前缀：只使用第一列，或者前几列；\n- 匹配列前缀：只匹配某一列的值的开头部分；\n- 匹配范围值；\n- 精准匹配某一列而范围匹配另外一列；\n- 只访问索引的查询：查询只需要访问索引而无须访问数据行，也称之为覆盖索引；\n\n**索引排序：**\n\n- 因为索引树中的节点是有序的，除了按值查找，索引还可以用于查询中的 ORDER BY 操作；\n- 如果 ORDER BY 子句满足索引查询类型，则索引也可以用于这类的排序场景；\n\n**索引的限制：**\n\n- 不是按照索引的最左列开始查找，则无法使用索引；\n- 不能跳过索引中的列；\n- 如果查询中有某列的范围查询，则其右边所有列都无法使用索引优化查询；\n\n---\n\n### 3.3.索引的优点\n\n- 索引大大减少了服务器需要扫描的数据量；\n- 索引可以帮助服务器避免排序和临时表；\n- 索引可以将随机 I/O 变成顺序 I/O；\n\n---\n\n### 3.4.高性能的索引策略\n\n**前缀索引：**\n\n- 为了提升索引性能，节省索引空间，可以只对字段的前一部分字符进行索引；\n- 针对 BLOB、TEXT 或者很长的 VARCHAR 类型的列，只支持使用前缀索引。\n\n**索引的选择性：**\n\n是指不重复的值(也称之为基数)和数据表的总记录数(T)的比值，范围是 1/T 到 1 之间；索引的选择性越高则查询效率越高。\n\n**如何确定前缀索引的长度？**\n\n前缀索引的长度，既要足够长来保证较高的选择性，又不能太长(节省空间)；\n\n可以通过计算不同长度前缀和完整列，与总行数的比率，使用较接近的长度前缀；\n\n**多列索引：**\n\n索引的常见误区是为每列创建独立的索引，或者按照错误的顺序创建多列索引。\n\n**如何选择合适的索引列顺序：**\n\n根据经验法则：将选择性最高的列放到索引的最前列，在大部分场景下是有效的。\n\n但是索引性能不仅仅依赖于选择性，和查询条件的具体值，以及值的分布都有关，此时可以根据运行频率最高的查询来适当调整索引列的顺序。\n\n**聚簇索引：**\n\n聚簇索引是一种数据存储方式，InnoDB 的聚簇索引是在同一个结构中保存了 B-tree 索引和数据行。InnoDB 根据主键聚簇数据，如果没有定义主键，会选择唯一的非空索引代替，次之会隐式定义一个主键。\n\n**按主键顺序插入行：**\n\n如果 InnoDB 表中没有数据需要聚集，可以使用一个代理键来作为主键（例如 AUTO_INCREMENT 自增列），以保证数据行是按顺序写入的，来提升性能。\n\n随机的聚簇索引，例如 UUID 会使得数据没有任何聚集特性，插入也变得完全随机，应该尽量避免。\n\n**覆盖索引：**\n\n如果一个索引包含所有需要查询的字段的值，称之为覆盖索引。不需要回表查询，效率更高。\n\n**使用索引来排序：**\n\n只有当使用的顺序和 ORDER BY 子句的顺序完全一致，并且所有列的排序方向(顺序或者倒序)都一样时，MySQL 才能使用索引对结果进行排序。\n\n在 EXPLAIN 的输出结果中，type 列的值为”index”，说明 MySQL 使用了索引扫描来进行排序。\n\n---\n\n## 4.查询性能优化\n\n查询的生命周期，大致上可以分为：客户端连接到服务端，服务端进行语法解析，生成执行计划，执行，并给客户端返回结果。\n\n其中“执行”阶段是整个生命周期中最重要的阶段，包括大量为了检索数据对存储引擎的调用，以及调用后的数据处理(排序、分组等)。\n\n---\n\n### 4.1.优化数据访问\n\n**查询的数据是否过多：**\n\n- 查询了不需要的记录；\n- 多表连接时返回全部列；\n- 总数取出全部列；\n- 重复查询相同的数据；\n\n**MySQL 是否在扫描额外的记录：**\n\n- 扫描的行数和返回行数之间的比率；\n- 扫描的行数和访问类型：全表扫描、索引扫描、范围扫描、唯一索引查询，常数引用等；\n\n---\n\n### 4.2.重构查询的方式\n\n- 将复杂查询重构为多个简单查询；\n- 切分查询，每次只返回部分查询结果；\n- 分解连接查询；\n\n---\n\n### 4.3.查询状态\n\n- Sleep：线程正在等待客户端发送新的请求；\n- Query：线程正在执行查询或者正在将结果发送给客户端；\n- Locked：在 MySQL 服务器层，线程正在等待表锁；（存储引擎级别实现的锁，例如 InnoDB 的行锁，不会体现在线程状态中）\n- Analying and statistics：线程正在检查存储引擎的统计信息，并优化查询；\n- Copying to tmp table：线程正在执行查询，将结果复制到临时表中；\n- Sorting result：线程正在对结果集进行排序；\n\n---\n\n### 4.4.排序优化\n\n在不能使用索引生成排序结果的时候，MySQL 需要自己继续排序，数据量小则在内存中进行，数据量大则需要使用磁盘，在 MySQL 中统称文件排序。\n\n**排序的具体实现：**\n\n如果需要排序的数据量小于“排序缓存区”，MySQL 使用内存进行快速排序操作，如果内存不够排序，那么 MySQL 会先将数据分块，对每个独立的块使用快速排序，并将各个块的排序结果存放在磁盘上，然后将各个排好序的块进行合并，最后返回排序结果。\n\n在 MySQL 的 EXPLAIN 结果的 Extra 字段可以看到“Using temporary; Using filesort”字样，说明使用了临时表、文件进行排序。\n\n","slug":"高性能MySQL的实现策略","published":1,"updated":"2024-01-30T10:02:22.414Z","_id":"cls06n7qf000diocq8flq8y5z","comments":1,"layout":"post","photos":[],"content":"<h2 id=\"1-基础架构\"><a href=\"#1-基础架构\" class=\"headerlink\" title=\"1.基础架构\"></a>1.基础架构</h2><p><img src=\"/img_convert/1.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"1-1-网络连接层\"><a href=\"#1-1-网络连接层\" class=\"headerlink\" title=\"1.1.网络连接层\"></a>1.1.网络连接层</h3><p>位于最上层的客户端服务，包括连接处理、身份验证等功能，支持多种服务端语言，通过 API 接口与 MySQL 建立连接。</p>\n<hr>\n<h3 id=\"1-2-数据库服务层\"><a href=\"#1-2-数据库服务层\" class=\"headerlink\" title=\"1.2.数据库服务层\"></a>1.2.数据库服务层</h3><p>MySQL 的核心功能都在这一层，包括查询解析、分析、优化，以及所有的内置函数(例如:日期、数学函数)，所有跨存储引擎的功能也都在这一层实现：存储过程、触发器、视图等。</p>\n<p><strong>1.2.1.连接管理:</strong></p>\n<p>每个客户端连接都会在服务器进程中拥有一个线程，该连接的查询只会在这个单独的线程中执行，该进程驻留在内核或者 CPU 上。服务器维护了一个缓冲区，作为连接池，存储已就绪的线程。</p>\n<p><strong>1.2.2.优化与执行:</strong></p>\n<p>MySQL 解析查询以创建解析树，然后对其进行各种优化，包括重写查询，决定表的读取顺序，以及选择合适的索引等。</p>\n<hr>\n<h3 id=\"1-3-存储引擎层\"><a href=\"#1-3-存储引擎层\" class=\"headerlink\" title=\"1.3.存储引擎层\"></a>1.3.存储引擎层</h3><p>存储引擎负责 MySQL 中数据的存储和提取，服务器通过存储引擎 API 进行通信。这些 API 屏蔽了不同存储引擎之间的差异，使得它们对上面的查询层基本上是透明的。最常用的存储引擎是 InnoDB。</p>\n<hr>\n<h3 id=\"1-4-系统文件层\"><a href=\"#1-4-系统文件层\" class=\"headerlink\" title=\"1.4.系统文件层\"></a>1.4.系统文件层</h3><p><strong>1.4.1.binlog</strong></p>\n<ul>\n<li>binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用，用于归档；</li>\n<li>binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”；binlog 是可以追加写入的，不会覆盖之前的日志；</li>\n</ul>\n<p><strong>1.4..2.redo log</strong></p>\n<ul>\n<li>redo log 是 InnoDB 引擎实现的，用于 Write-Ahead Logging(提升效率)、crash-safe(故障恢复)；</li>\n<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；redo log 是循环写的，空间固定会用完；</li>\n</ul>\n<p><strong>1.4..3.undo log</strong></p>\n<ul>\n<li>undo log 提供了回滚和多版本控制(MVCC)功能；</li>\n<li>unlo log 用于存放数据被修改之前的值；</li>\n</ul>\n<hr>\n<h2 id=\"2-Schema-设计\"><a href=\"#2-Schema-设计\" class=\"headerlink\" title=\"2.Schema 设计\"></a>2.Schema 设计</h2><h3 id=\"2-1-数据类型选择\"><a href=\"#2-1-数据类型选择\" class=\"headerlink\" title=\"2.1.数据类型选择\"></a>2.1.数据类型选择</h3><ul>\n<li>更小的通常更好：尽可能使用能够正确存储和表示数据的最小数据类型。更小的数据类型通常更快，因为它们占用的磁盘、内存和 CPU 缓存的空间更少，并且处理时需要的 CPU 周期也更少；</li>\n<li>简单为好：简单数据类型的操作通常需要更少的 CPU 周期。例如，整型数据比字符型数据的比较操作代价更低（因为字符集和排序规则使得字符型数据的比较更加复杂）；应该将日期和时间存储为 MySQL 的内置类型而非字符串类型；</li>\n<li>尽量避免存储 NULL：通常情况下最好指定列为 NOT NULL，除非明确需要存储 NULL 值。因为可为 NULL 的列，对 MySQL 来说更难优化，在索引、索引统计和值比较时都更复杂；在存储时需要特殊处理，会占用更多的存储空间；（在调优时通常没有必要将可为 NULL 的列改成 NOT NULL，带来的性能提升比较小）</li>\n</ul>\n<hr>\n<h3 id=\"2-2-整数类型\"><a href=\"#2-2-整数类型\" class=\"headerlink\" title=\"2.2.整数类型\"></a>2.2.整数类型</h3><p>整数的类型有：TINYINT、SMALLINT、MEDIUMINT、INT 和 BIGINT，分别使用 8、16、24、32、和 64 位存储空间，可以存储的值的范围从 -2 的(n-1)次方到 2 的(n-1)次方-1，其中 n 是存储空间的位数。</p>\n<p>整数类型有可选的 UNSIGNED 属性，表示不允许负值，大致上可以使正整数的上限提高一倍。</p>\n<p>MySQL 可以为整数类型指定宽度，只是规定了 MySQL 的客户端显示字符的个数，不会限制值的合法范围。</p>\n<hr>\n<h3 id=\"2-3-实数类型\"><a href=\"#2-3-实数类型\" class=\"headerlink\" title=\"2.3.实数类型\"></a>2.3.实数类型</h3><p>实数是带有小数部分的数字。也可以使用 DECIMAL 存储比 BIGINT 还大的整数，MySQL 既支持精确类型，也支持不精确类型。</p>\n<p>FLOAT 和 DOUBLE 类型支持使用标准的浮点运算进行近似计算。FLOAT 列使用 4 字节的存储空间，DOUBLE 占用 8 字节。</p>\n<p>DECIMAL 需要额外的存储空间和计算成本，尽量在对小数需要进行精确计算时进行使用，例如：存储财务数据。在一些大容量的场景，可以考虑使用 BIGINT 代替 DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可，可以避免浮点存储计算不精确和 DECIMAL 精确计算代价高的问题。</p>\n<hr>\n<h3 id=\"2-4-字符串类型\"><a href=\"#2-4-字符串类型\" class=\"headerlink\" title=\"2.4.字符串类型\"></a>2.4.字符串类型</h3><p><strong>VARCHAR：</strong></p>\n<ul>\n<li>用于存储可变长度的字符串，比固定长度的类型更节省空间，因为它仅使用必要的空间；</li>\n<li>但是由于行是可变长度的，在更新时可能会增长，将导致额外的工作；</li>\n<li>VARCHAR 需要额外使用 1 或者 2 字节记录字符串的长度；</li>\n<li>适用场景：字符串的最大长度远大于平均长度；列的更新很少；</li>\n</ul>\n<p><strong>CHAR：</strong></p>\n<ul>\n<li>CHAR 是固定长度的，非常适合存储较短的字符串，或者所有值的长度都几乎相同的情况；</li>\n<li>对于经常修改的数据，CHAR 比 VARCHAR 更好，因为固定长度的行不容易出现碎片；</li>\n</ul>\n<p><strong>BLOB 和 TEXT 类型：</strong></p>\n<ul>\n<li>BLOB 和 TEXT 类型是为了存储很大的数据而设计的字符串数据类型，分别采用二级制和字符串方式存储；</li>\n<li>MySQL 将 BOLO 和 TEXT 值当作具有自己标识的对象来处理，内容太多时会使用外部存储区域；</li>\n</ul>\n<hr>\n<h3 id=\"2-5-日期和时间类型\"><a href=\"#2-5-日期和时间类型\" class=\"headerlink\" title=\"2.5.日期和时间类型\"></a>2.5.日期和时间类型</h3><p><strong>DATETIME:</strong></p>\n<ul>\n<li>可以保存从 1000 年到 9999 年范围内的数值，精度为 1 微秒；</li>\n<li>以 YYYYMMDDHHMMSS 格式存储压缩成整数的日期和时间，与时区无关，需要 8 字节的存储空间；</li>\n</ul>\n<p><strong>TIMESTAMP：</strong></p>\n<ul>\n<li>与 UNIX 时间戳相同，存储自 1970 年 1 月 1 日以来经过的秒数，使用 4 字节存储空间，只能表示 1970 年 2038 年范围内的数据；</li>\n<li>时间戳显示的值依赖于时区，MySQL 服务器、操作系统和客户端连接都有时区设置；</li>\n</ul>\n<hr>\n<h3 id=\"2-6-JSON-数据类型\"><a href=\"#2-6-JSON-数据类型\" class=\"headerlink\" title=\"2.6.JSON 数据类型\"></a>2.6.JSON 数据类型</h3><ul>\n<li>相比较于 SQL 列，JSON 列需要占用过多的存储空间，有额外的字符需要存储；</li>\n<li>查询速度上，SQL 列也更占优势；是否使用 JSON，取决于在数据库中使用 JSON 的便捷性是否大于性能；</li>\n</ul>\n<hr>\n<h3 id=\"2-7-其他数据类型\"><a href=\"#2-7-其他数据类型\" class=\"headerlink\" title=\"2.7.其他数据类型\"></a>2.7.其他数据类型</h3><p><strong>BIT：</strong></p>\n<ul>\n<li>可以使用 BIT 列存储一个或者多个 true&#x2F;false 值；在存储时不会节省任何存储空间；</li>\n<li>MySQL 在处理时将 BIT 视为字符串类型，在数字上下文中进行数据比较时会转换为数字，得到非预期结果，使用时需要谨慎；</li>\n<li>建议使用 TINYINT 进行代替；</li>\n</ul>\n<p><strong>IP：</strong></p>\n<ul>\n<li>IP 地址实际上是无符号整数，用小数点分隔只是为了方便阅读，因此应该将 IP 地址存储为无符合整数；</li>\n<li>MySQL 提供了 INET_ATON()和 INET_NTOA()函数在这两种表达形式之间进行转换；</li>\n</ul>\n<hr>\n<h3 id=\"2-8-schema-管理\"><a href=\"#2-8-schema-管理\" class=\"headerlink\" title=\"2.8.schema 管理\"></a>2.8.schema 管理</h3><p>如何在不影响数据库或者依赖它们的服务正常运行的情况下，进行 schema 的变更？</p>\n<p><strong>原生 DDL 语句：</strong></p>\n<p>MySQL 在 5.6 版本中引入了非阻塞的 schema 更改，对原生 DDL 的支持有限，在需要更改的表非常大时，可能会遇到回滚的情况。</p>\n<p><strong>外部的工具：</strong></p>\n<p>主要选择有 Percona 的 pt-online-schema-change 和 Github 的 gh-ost。实现原理是对正在更改的表进行完整的复制，执行完表结构变更，再把源表的全量数据和增量数据同步过去，最后进行表替换。</p>\n<hr>\n<h2 id=\"3-索引\"><a href=\"#3-索引\" class=\"headerlink\" title=\"3.索引\"></a>3.索引</h2><p>索引是存储引擎用于快速找到记录的一种数据结构。</p>\n<h3 id=\"3-1-索引的类型\"><a href=\"#3-1-索引的类型\" class=\"headerlink\" title=\"3.1.索引的类型\"></a>3.1.索引的类型</h3><p><strong>B-tree 索引：</strong></p>\n<ul>\n<li>是指使用 B-tree 数据结构来存储数据，在实际实现中，很多存储引擎使用的是 B+ Tree 索引；</li>\n<li>B-tree 索引能够加快数据访问的速度，因为有了索引，在查询某些条件的数据时，不需要全表扫描；从索引的根节点根据子节点的指针，依次向下层开始查找；</li>\n<li>B-tree 是按照索引列中的数据大小顺序存储的，非常适合按照范围进行查询；</li>\n</ul>\n<p><strong>自适应哈希索引：</strong></p>\n<p>InnoDB 存储引擎在发现某些索引值访问非常频繁时，会在原有 B-tree 索引之上，在内存中在构建一个哈希索引；</p>\n<p><strong>全文索引：</strong></p>\n<p>FULLTEXT 是一种特殊类型的索引，查找的是文本中的关键字，类似于搜索引擎；</p>\n<hr>\n<h3 id=\"3-2-B-tree-索引的使用\"><a href=\"#3-2-B-tree-索引的使用\" class=\"headerlink\" title=\"3.2.B-tree 索引的使用\"></a>3.2.B-tree 索引的使用</h3><p><strong>适用的查询类型：</strong></p>\n<ul>\n<li>全值匹配：和索引中的所有列匹配；</li>\n<li>匹配最左前缀：只使用第一列，或者前几列；</li>\n<li>匹配列前缀：只匹配某一列的值的开头部分；</li>\n<li>匹配范围值；</li>\n<li>精准匹配某一列而范围匹配另外一列；</li>\n<li>只访问索引的查询：查询只需要访问索引而无须访问数据行，也称之为覆盖索引；</li>\n</ul>\n<p><strong>索引排序：</strong></p>\n<ul>\n<li>因为索引树中的节点是有序的，除了按值查找，索引还可以用于查询中的 ORDER BY 操作；</li>\n<li>如果 ORDER BY 子句满足索引查询类型，则索引也可以用于这类的排序场景；</li>\n</ul>\n<p><strong>索引的限制：</strong></p>\n<ul>\n<li>不是按照索引的最左列开始查找，则无法使用索引；</li>\n<li>不能跳过索引中的列；</li>\n<li>如果查询中有某列的范围查询，则其右边所有列都无法使用索引优化查询；</li>\n</ul>\n<hr>\n<h3 id=\"3-3-索引的优点\"><a href=\"#3-3-索引的优点\" class=\"headerlink\" title=\"3.3.索引的优点\"></a>3.3.索引的优点</h3><ul>\n<li>索引大大减少了服务器需要扫描的数据量；</li>\n<li>索引可以帮助服务器避免排序和临时表；</li>\n<li>索引可以将随机 I&#x2F;O 变成顺序 I&#x2F;O；</li>\n</ul>\n<hr>\n<h3 id=\"3-4-高性能的索引策略\"><a href=\"#3-4-高性能的索引策略\" class=\"headerlink\" title=\"3.4.高性能的索引策略\"></a>3.4.高性能的索引策略</h3><p><strong>前缀索引：</strong></p>\n<ul>\n<li>为了提升索引性能，节省索引空间，可以只对字段的前一部分字符进行索引；</li>\n<li>针对 BLOB、TEXT 或者很长的 VARCHAR 类型的列，只支持使用前缀索引。</li>\n</ul>\n<p><strong>索引的选择性：</strong></p>\n<p>是指不重复的值(也称之为基数)和数据表的总记录数(T)的比值，范围是 1&#x2F;T 到 1 之间；索引的选择性越高则查询效率越高。</p>\n<p><strong>如何确定前缀索引的长度？</strong></p>\n<p>前缀索引的长度，既要足够长来保证较高的选择性，又不能太长(节省空间)；</p>\n<p>可以通过计算不同长度前缀和完整列，与总行数的比率，使用较接近的长度前缀；</p>\n<p><strong>多列索引：</strong></p>\n<p>索引的常见误区是为每列创建独立的索引，或者按照错误的顺序创建多列索引。</p>\n<p><strong>如何选择合适的索引列顺序：</strong></p>\n<p>根据经验法则：将选择性最高的列放到索引的最前列，在大部分场景下是有效的。</p>\n<p>但是索引性能不仅仅依赖于选择性，和查询条件的具体值，以及值的分布都有关，此时可以根据运行频率最高的查询来适当调整索引列的顺序。</p>\n<p><strong>聚簇索引：</strong></p>\n<p>聚簇索引是一种数据存储方式，InnoDB 的聚簇索引是在同一个结构中保存了 B-tree 索引和数据行。InnoDB 根据主键聚簇数据，如果没有定义主键，会选择唯一的非空索引代替，次之会隐式定义一个主键。</p>\n<p><strong>按主键顺序插入行：</strong></p>\n<p>如果 InnoDB 表中没有数据需要聚集，可以使用一个代理键来作为主键（例如 AUTO_INCREMENT 自增列），以保证数据行是按顺序写入的，来提升性能。</p>\n<p>随机的聚簇索引，例如 UUID 会使得数据没有任何聚集特性，插入也变得完全随机，应该尽量避免。</p>\n<p><strong>覆盖索引：</strong></p>\n<p>如果一个索引包含所有需要查询的字段的值，称之为覆盖索引。不需要回表查询，效率更高。</p>\n<p><strong>使用索引来排序：</strong></p>\n<p>只有当使用的顺序和 ORDER BY 子句的顺序完全一致，并且所有列的排序方向(顺序或者倒序)都一样时，MySQL 才能使用索引对结果进行排序。</p>\n<p>在 EXPLAIN 的输出结果中，type 列的值为”index”，说明 MySQL 使用了索引扫描来进行排序。</p>\n<hr>\n<h2 id=\"4-查询性能优化\"><a href=\"#4-查询性能优化\" class=\"headerlink\" title=\"4.查询性能优化\"></a>4.查询性能优化</h2><p>查询的生命周期，大致上可以分为：客户端连接到服务端，服务端进行语法解析，生成执行计划，执行，并给客户端返回结果。</p>\n<p>其中“执行”阶段是整个生命周期中最重要的阶段，包括大量为了检索数据对存储引擎的调用，以及调用后的数据处理(排序、分组等)。</p>\n<hr>\n<h3 id=\"4-1-优化数据访问\"><a href=\"#4-1-优化数据访问\" class=\"headerlink\" title=\"4.1.优化数据访问\"></a>4.1.优化数据访问</h3><p><strong>查询的数据是否过多：</strong></p>\n<ul>\n<li>查询了不需要的记录；</li>\n<li>多表连接时返回全部列；</li>\n<li>总数取出全部列；</li>\n<li>重复查询相同的数据；</li>\n</ul>\n<p><strong>MySQL 是否在扫描额外的记录：</strong></p>\n<ul>\n<li>扫描的行数和返回行数之间的比率；</li>\n<li>扫描的行数和访问类型：全表扫描、索引扫描、范围扫描、唯一索引查询，常数引用等；</li>\n</ul>\n<hr>\n<h3 id=\"4-2-重构查询的方式\"><a href=\"#4-2-重构查询的方式\" class=\"headerlink\" title=\"4.2.重构查询的方式\"></a>4.2.重构查询的方式</h3><ul>\n<li>将复杂查询重构为多个简单查询；</li>\n<li>切分查询，每次只返回部分查询结果；</li>\n<li>分解连接查询；</li>\n</ul>\n<hr>\n<h3 id=\"4-3-查询状态\"><a href=\"#4-3-查询状态\" class=\"headerlink\" title=\"4.3.查询状态\"></a>4.3.查询状态</h3><ul>\n<li>Sleep：线程正在等待客户端发送新的请求；</li>\n<li>Query：线程正在执行查询或者正在将结果发送给客户端；</li>\n<li>Locked：在 MySQL 服务器层，线程正在等待表锁；（存储引擎级别实现的锁，例如 InnoDB 的行锁，不会体现在线程状态中）</li>\n<li>Analying and statistics：线程正在检查存储引擎的统计信息，并优化查询；</li>\n<li>Copying to tmp table：线程正在执行查询，将结果复制到临时表中；</li>\n<li>Sorting result：线程正在对结果集进行排序；</li>\n</ul>\n<hr>\n<h3 id=\"4-4-排序优化\"><a href=\"#4-4-排序优化\" class=\"headerlink\" title=\"4.4.排序优化\"></a>4.4.排序优化</h3><p>在不能使用索引生成排序结果的时候，MySQL 需要自己继续排序，数据量小则在内存中进行，数据量大则需要使用磁盘，在 MySQL 中统称文件排序。</p>\n<p><strong>排序的具体实现：</strong></p>\n<p>如果需要排序的数据量小于“排序缓存区”，MySQL 使用内存进行快速排序操作，如果内存不够排序，那么 MySQL 会先将数据分块，对每个独立的块使用快速排序，并将各个块的排序结果存放在磁盘上，然后将各个排好序的块进行合并，最后返回排序结果。</p>\n<p>在 MySQL 的 EXPLAIN 结果的 Extra 字段可以看到“Using temporary; Using filesort”字样，说明使用了临时表、文件进行排序。</p>\n","excerpt":"","more":"<h2 id=\"1-基础架构\"><a href=\"#1-基础架构\" class=\"headerlink\" title=\"1.基础架构\"></a>1.基础架构</h2><p><img src=\"/img_convert/1.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"1-1-网络连接层\"><a href=\"#1-1-网络连接层\" class=\"headerlink\" title=\"1.1.网络连接层\"></a>1.1.网络连接层</h3><p>位于最上层的客户端服务，包括连接处理、身份验证等功能，支持多种服务端语言，通过 API 接口与 MySQL 建立连接。</p>\n<hr>\n<h3 id=\"1-2-数据库服务层\"><a href=\"#1-2-数据库服务层\" class=\"headerlink\" title=\"1.2.数据库服务层\"></a>1.2.数据库服务层</h3><p>MySQL 的核心功能都在这一层，包括查询解析、分析、优化，以及所有的内置函数(例如:日期、数学函数)，所有跨存储引擎的功能也都在这一层实现：存储过程、触发器、视图等。</p>\n<p><strong>1.2.1.连接管理:</strong></p>\n<p>每个客户端连接都会在服务器进程中拥有一个线程，该连接的查询只会在这个单独的线程中执行，该进程驻留在内核或者 CPU 上。服务器维护了一个缓冲区，作为连接池，存储已就绪的线程。</p>\n<p><strong>1.2.2.优化与执行:</strong></p>\n<p>MySQL 解析查询以创建解析树，然后对其进行各种优化，包括重写查询，决定表的读取顺序，以及选择合适的索引等。</p>\n<hr>\n<h3 id=\"1-3-存储引擎层\"><a href=\"#1-3-存储引擎层\" class=\"headerlink\" title=\"1.3.存储引擎层\"></a>1.3.存储引擎层</h3><p>存储引擎负责 MySQL 中数据的存储和提取，服务器通过存储引擎 API 进行通信。这些 API 屏蔽了不同存储引擎之间的差异，使得它们对上面的查询层基本上是透明的。最常用的存储引擎是 InnoDB。</p>\n<hr>\n<h3 id=\"1-4-系统文件层\"><a href=\"#1-4-系统文件层\" class=\"headerlink\" title=\"1.4.系统文件层\"></a>1.4.系统文件层</h3><p><strong>1.4.1.binlog</strong></p>\n<ul>\n<li>binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用，用于归档；</li>\n<li>binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”；binlog 是可以追加写入的，不会覆盖之前的日志；</li>\n</ul>\n<p><strong>1.4..2.redo log</strong></p>\n<ul>\n<li>redo log 是 InnoDB 引擎实现的，用于 Write-Ahead Logging(提升效率)、crash-safe(故障恢复)；</li>\n<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；redo log 是循环写的，空间固定会用完；</li>\n</ul>\n<p><strong>1.4..3.undo log</strong></p>\n<ul>\n<li>undo log 提供了回滚和多版本控制(MVCC)功能；</li>\n<li>unlo log 用于存放数据被修改之前的值；</li>\n</ul>\n<hr>\n<h2 id=\"2-Schema-设计\"><a href=\"#2-Schema-设计\" class=\"headerlink\" title=\"2.Schema 设计\"></a>2.Schema 设计</h2><h3 id=\"2-1-数据类型选择\"><a href=\"#2-1-数据类型选择\" class=\"headerlink\" title=\"2.1.数据类型选择\"></a>2.1.数据类型选择</h3><ul>\n<li>更小的通常更好：尽可能使用能够正确存储和表示数据的最小数据类型。更小的数据类型通常更快，因为它们占用的磁盘、内存和 CPU 缓存的空间更少，并且处理时需要的 CPU 周期也更少；</li>\n<li>简单为好：简单数据类型的操作通常需要更少的 CPU 周期。例如，整型数据比字符型数据的比较操作代价更低（因为字符集和排序规则使得字符型数据的比较更加复杂）；应该将日期和时间存储为 MySQL 的内置类型而非字符串类型；</li>\n<li>尽量避免存储 NULL：通常情况下最好指定列为 NOT NULL，除非明确需要存储 NULL 值。因为可为 NULL 的列，对 MySQL 来说更难优化，在索引、索引统计和值比较时都更复杂；在存储时需要特殊处理，会占用更多的存储空间；（在调优时通常没有必要将可为 NULL 的列改成 NOT NULL，带来的性能提升比较小）</li>\n</ul>\n<hr>\n<h3 id=\"2-2-整数类型\"><a href=\"#2-2-整数类型\" class=\"headerlink\" title=\"2.2.整数类型\"></a>2.2.整数类型</h3><p>整数的类型有：TINYINT、SMALLINT、MEDIUMINT、INT 和 BIGINT，分别使用 8、16、24、32、和 64 位存储空间，可以存储的值的范围从 -2 的(n-1)次方到 2 的(n-1)次方-1，其中 n 是存储空间的位数。</p>\n<p>整数类型有可选的 UNSIGNED 属性，表示不允许负值，大致上可以使正整数的上限提高一倍。</p>\n<p>MySQL 可以为整数类型指定宽度，只是规定了 MySQL 的客户端显示字符的个数，不会限制值的合法范围。</p>\n<hr>\n<h3 id=\"2-3-实数类型\"><a href=\"#2-3-实数类型\" class=\"headerlink\" title=\"2.3.实数类型\"></a>2.3.实数类型</h3><p>实数是带有小数部分的数字。也可以使用 DECIMAL 存储比 BIGINT 还大的整数，MySQL 既支持精确类型，也支持不精确类型。</p>\n<p>FLOAT 和 DOUBLE 类型支持使用标准的浮点运算进行近似计算。FLOAT 列使用 4 字节的存储空间，DOUBLE 占用 8 字节。</p>\n<p>DECIMAL 需要额外的存储空间和计算成本，尽量在对小数需要进行精确计算时进行使用，例如：存储财务数据。在一些大容量的场景，可以考虑使用 BIGINT 代替 DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可，可以避免浮点存储计算不精确和 DECIMAL 精确计算代价高的问题。</p>\n<hr>\n<h3 id=\"2-4-字符串类型\"><a href=\"#2-4-字符串类型\" class=\"headerlink\" title=\"2.4.字符串类型\"></a>2.4.字符串类型</h3><p><strong>VARCHAR：</strong></p>\n<ul>\n<li>用于存储可变长度的字符串，比固定长度的类型更节省空间，因为它仅使用必要的空间；</li>\n<li>但是由于行是可变长度的，在更新时可能会增长，将导致额外的工作；</li>\n<li>VARCHAR 需要额外使用 1 或者 2 字节记录字符串的长度；</li>\n<li>适用场景：字符串的最大长度远大于平均长度；列的更新很少；</li>\n</ul>\n<p><strong>CHAR：</strong></p>\n<ul>\n<li>CHAR 是固定长度的，非常适合存储较短的字符串，或者所有值的长度都几乎相同的情况；</li>\n<li>对于经常修改的数据，CHAR 比 VARCHAR 更好，因为固定长度的行不容易出现碎片；</li>\n</ul>\n<p><strong>BLOB 和 TEXT 类型：</strong></p>\n<ul>\n<li>BLOB 和 TEXT 类型是为了存储很大的数据而设计的字符串数据类型，分别采用二级制和字符串方式存储；</li>\n<li>MySQL 将 BOLO 和 TEXT 值当作具有自己标识的对象来处理，内容太多时会使用外部存储区域；</li>\n</ul>\n<hr>\n<h3 id=\"2-5-日期和时间类型\"><a href=\"#2-5-日期和时间类型\" class=\"headerlink\" title=\"2.5.日期和时间类型\"></a>2.5.日期和时间类型</h3><p><strong>DATETIME:</strong></p>\n<ul>\n<li>可以保存从 1000 年到 9999 年范围内的数值，精度为 1 微秒；</li>\n<li>以 YYYYMMDDHHMMSS 格式存储压缩成整数的日期和时间，与时区无关，需要 8 字节的存储空间；</li>\n</ul>\n<p><strong>TIMESTAMP：</strong></p>\n<ul>\n<li>与 UNIX 时间戳相同，存储自 1970 年 1 月 1 日以来经过的秒数，使用 4 字节存储空间，只能表示 1970 年 2038 年范围内的数据；</li>\n<li>时间戳显示的值依赖于时区，MySQL 服务器、操作系统和客户端连接都有时区设置；</li>\n</ul>\n<hr>\n<h3 id=\"2-6-JSON-数据类型\"><a href=\"#2-6-JSON-数据类型\" class=\"headerlink\" title=\"2.6.JSON 数据类型\"></a>2.6.JSON 数据类型</h3><ul>\n<li>相比较于 SQL 列，JSON 列需要占用过多的存储空间，有额外的字符需要存储；</li>\n<li>查询速度上，SQL 列也更占优势；是否使用 JSON，取决于在数据库中使用 JSON 的便捷性是否大于性能；</li>\n</ul>\n<hr>\n<h3 id=\"2-7-其他数据类型\"><a href=\"#2-7-其他数据类型\" class=\"headerlink\" title=\"2.7.其他数据类型\"></a>2.7.其他数据类型</h3><p><strong>BIT：</strong></p>\n<ul>\n<li>可以使用 BIT 列存储一个或者多个 true&#x2F;false 值；在存储时不会节省任何存储空间；</li>\n<li>MySQL 在处理时将 BIT 视为字符串类型，在数字上下文中进行数据比较时会转换为数字，得到非预期结果，使用时需要谨慎；</li>\n<li>建议使用 TINYINT 进行代替；</li>\n</ul>\n<p><strong>IP：</strong></p>\n<ul>\n<li>IP 地址实际上是无符号整数，用小数点分隔只是为了方便阅读，因此应该将 IP 地址存储为无符合整数；</li>\n<li>MySQL 提供了 INET_ATON()和 INET_NTOA()函数在这两种表达形式之间进行转换；</li>\n</ul>\n<hr>\n<h3 id=\"2-8-schema-管理\"><a href=\"#2-8-schema-管理\" class=\"headerlink\" title=\"2.8.schema 管理\"></a>2.8.schema 管理</h3><p>如何在不影响数据库或者依赖它们的服务正常运行的情况下，进行 schema 的变更？</p>\n<p><strong>原生 DDL 语句：</strong></p>\n<p>MySQL 在 5.6 版本中引入了非阻塞的 schema 更改，对原生 DDL 的支持有限，在需要更改的表非常大时，可能会遇到回滚的情况。</p>\n<p><strong>外部的工具：</strong></p>\n<p>主要选择有 Percona 的 pt-online-schema-change 和 Github 的 gh-ost。实现原理是对正在更改的表进行完整的复制，执行完表结构变更，再把源表的全量数据和增量数据同步过去，最后进行表替换。</p>\n<hr>\n<h2 id=\"3-索引\"><a href=\"#3-索引\" class=\"headerlink\" title=\"3.索引\"></a>3.索引</h2><p>索引是存储引擎用于快速找到记录的一种数据结构。</p>\n<h3 id=\"3-1-索引的类型\"><a href=\"#3-1-索引的类型\" class=\"headerlink\" title=\"3.1.索引的类型\"></a>3.1.索引的类型</h3><p><strong>B-tree 索引：</strong></p>\n<ul>\n<li>是指使用 B-tree 数据结构来存储数据，在实际实现中，很多存储引擎使用的是 B+ Tree 索引；</li>\n<li>B-tree 索引能够加快数据访问的速度，因为有了索引，在查询某些条件的数据时，不需要全表扫描；从索引的根节点根据子节点的指针，依次向下层开始查找；</li>\n<li>B-tree 是按照索引列中的数据大小顺序存储的，非常适合按照范围进行查询；</li>\n</ul>\n<p><strong>自适应哈希索引：</strong></p>\n<p>InnoDB 存储引擎在发现某些索引值访问非常频繁时，会在原有 B-tree 索引之上，在内存中在构建一个哈希索引；</p>\n<p><strong>全文索引：</strong></p>\n<p>FULLTEXT 是一种特殊类型的索引，查找的是文本中的关键字，类似于搜索引擎；</p>\n<hr>\n<h3 id=\"3-2-B-tree-索引的使用\"><a href=\"#3-2-B-tree-索引的使用\" class=\"headerlink\" title=\"3.2.B-tree 索引的使用\"></a>3.2.B-tree 索引的使用</h3><p><strong>适用的查询类型：</strong></p>\n<ul>\n<li>全值匹配：和索引中的所有列匹配；</li>\n<li>匹配最左前缀：只使用第一列，或者前几列；</li>\n<li>匹配列前缀：只匹配某一列的值的开头部分；</li>\n<li>匹配范围值；</li>\n<li>精准匹配某一列而范围匹配另外一列；</li>\n<li>只访问索引的查询：查询只需要访问索引而无须访问数据行，也称之为覆盖索引；</li>\n</ul>\n<p><strong>索引排序：</strong></p>\n<ul>\n<li>因为索引树中的节点是有序的，除了按值查找，索引还可以用于查询中的 ORDER BY 操作；</li>\n<li>如果 ORDER BY 子句满足索引查询类型，则索引也可以用于这类的排序场景；</li>\n</ul>\n<p><strong>索引的限制：</strong></p>\n<ul>\n<li>不是按照索引的最左列开始查找，则无法使用索引；</li>\n<li>不能跳过索引中的列；</li>\n<li>如果查询中有某列的范围查询，则其右边所有列都无法使用索引优化查询；</li>\n</ul>\n<hr>\n<h3 id=\"3-3-索引的优点\"><a href=\"#3-3-索引的优点\" class=\"headerlink\" title=\"3.3.索引的优点\"></a>3.3.索引的优点</h3><ul>\n<li>索引大大减少了服务器需要扫描的数据量；</li>\n<li>索引可以帮助服务器避免排序和临时表；</li>\n<li>索引可以将随机 I&#x2F;O 变成顺序 I&#x2F;O；</li>\n</ul>\n<hr>\n<h3 id=\"3-4-高性能的索引策略\"><a href=\"#3-4-高性能的索引策略\" class=\"headerlink\" title=\"3.4.高性能的索引策略\"></a>3.4.高性能的索引策略</h3><p><strong>前缀索引：</strong></p>\n<ul>\n<li>为了提升索引性能，节省索引空间，可以只对字段的前一部分字符进行索引；</li>\n<li>针对 BLOB、TEXT 或者很长的 VARCHAR 类型的列，只支持使用前缀索引。</li>\n</ul>\n<p><strong>索引的选择性：</strong></p>\n<p>是指不重复的值(也称之为基数)和数据表的总记录数(T)的比值，范围是 1&#x2F;T 到 1 之间；索引的选择性越高则查询效率越高。</p>\n<p><strong>如何确定前缀索引的长度？</strong></p>\n<p>前缀索引的长度，既要足够长来保证较高的选择性，又不能太长(节省空间)；</p>\n<p>可以通过计算不同长度前缀和完整列，与总行数的比率，使用较接近的长度前缀；</p>\n<p><strong>多列索引：</strong></p>\n<p>索引的常见误区是为每列创建独立的索引，或者按照错误的顺序创建多列索引。</p>\n<p><strong>如何选择合适的索引列顺序：</strong></p>\n<p>根据经验法则：将选择性最高的列放到索引的最前列，在大部分场景下是有效的。</p>\n<p>但是索引性能不仅仅依赖于选择性，和查询条件的具体值，以及值的分布都有关，此时可以根据运行频率最高的查询来适当调整索引列的顺序。</p>\n<p><strong>聚簇索引：</strong></p>\n<p>聚簇索引是一种数据存储方式，InnoDB 的聚簇索引是在同一个结构中保存了 B-tree 索引和数据行。InnoDB 根据主键聚簇数据，如果没有定义主键，会选择唯一的非空索引代替，次之会隐式定义一个主键。</p>\n<p><strong>按主键顺序插入行：</strong></p>\n<p>如果 InnoDB 表中没有数据需要聚集，可以使用一个代理键来作为主键（例如 AUTO_INCREMENT 自增列），以保证数据行是按顺序写入的，来提升性能。</p>\n<p>随机的聚簇索引，例如 UUID 会使得数据没有任何聚集特性，插入也变得完全随机，应该尽量避免。</p>\n<p><strong>覆盖索引：</strong></p>\n<p>如果一个索引包含所有需要查询的字段的值，称之为覆盖索引。不需要回表查询，效率更高。</p>\n<p><strong>使用索引来排序：</strong></p>\n<p>只有当使用的顺序和 ORDER BY 子句的顺序完全一致，并且所有列的排序方向(顺序或者倒序)都一样时，MySQL 才能使用索引对结果进行排序。</p>\n<p>在 EXPLAIN 的输出结果中，type 列的值为”index”，说明 MySQL 使用了索引扫描来进行排序。</p>\n<hr>\n<h2 id=\"4-查询性能优化\"><a href=\"#4-查询性能优化\" class=\"headerlink\" title=\"4.查询性能优化\"></a>4.查询性能优化</h2><p>查询的生命周期，大致上可以分为：客户端连接到服务端，服务端进行语法解析，生成执行计划，执行，并给客户端返回结果。</p>\n<p>其中“执行”阶段是整个生命周期中最重要的阶段，包括大量为了检索数据对存储引擎的调用，以及调用后的数据处理(排序、分组等)。</p>\n<hr>\n<h3 id=\"4-1-优化数据访问\"><a href=\"#4-1-优化数据访问\" class=\"headerlink\" title=\"4.1.优化数据访问\"></a>4.1.优化数据访问</h3><p><strong>查询的数据是否过多：</strong></p>\n<ul>\n<li>查询了不需要的记录；</li>\n<li>多表连接时返回全部列；</li>\n<li>总数取出全部列；</li>\n<li>重复查询相同的数据；</li>\n</ul>\n<p><strong>MySQL 是否在扫描额外的记录：</strong></p>\n<ul>\n<li>扫描的行数和返回行数之间的比率；</li>\n<li>扫描的行数和访问类型：全表扫描、索引扫描、范围扫描、唯一索引查询，常数引用等；</li>\n</ul>\n<hr>\n<h3 id=\"4-2-重构查询的方式\"><a href=\"#4-2-重构查询的方式\" class=\"headerlink\" title=\"4.2.重构查询的方式\"></a>4.2.重构查询的方式</h3><ul>\n<li>将复杂查询重构为多个简单查询；</li>\n<li>切分查询，每次只返回部分查询结果；</li>\n<li>分解连接查询；</li>\n</ul>\n<hr>\n<h3 id=\"4-3-查询状态\"><a href=\"#4-3-查询状态\" class=\"headerlink\" title=\"4.3.查询状态\"></a>4.3.查询状态</h3><ul>\n<li>Sleep：线程正在等待客户端发送新的请求；</li>\n<li>Query：线程正在执行查询或者正在将结果发送给客户端；</li>\n<li>Locked：在 MySQL 服务器层，线程正在等待表锁；（存储引擎级别实现的锁，例如 InnoDB 的行锁，不会体现在线程状态中）</li>\n<li>Analying and statistics：线程正在检查存储引擎的统计信息，并优化查询；</li>\n<li>Copying to tmp table：线程正在执行查询，将结果复制到临时表中；</li>\n<li>Sorting result：线程正在对结果集进行排序；</li>\n</ul>\n<hr>\n<h3 id=\"4-4-排序优化\"><a href=\"#4-4-排序优化\" class=\"headerlink\" title=\"4.4.排序优化\"></a>4.4.排序优化</h3><p>在不能使用索引生成排序结果的时候，MySQL 需要自己继续排序，数据量小则在内存中进行，数据量大则需要使用磁盘，在 MySQL 中统称文件排序。</p>\n<p><strong>排序的具体实现：</strong></p>\n<p>如果需要排序的数据量小于“排序缓存区”，MySQL 使用内存进行快速排序操作，如果内存不够排序，那么 MySQL 会先将数据分块，对每个独立的块使用快速排序，并将各个块的排序结果存放在磁盘上，然后将各个排好序的块进行合并，最后返回排序结果。</p>\n<p>在 MySQL 的 EXPLAIN 结果的 Extra 字段可以看到“Using temporary; Using filesort”字样，说明使用了临时表、文件进行排序。</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}